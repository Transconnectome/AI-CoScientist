<!DOCTYPE html><html  lang="en" data-capo=""><head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Frontiers | Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding</title>
<link rel="stylesheet" href="/ap-2024/_nuxt/entry.DQYypDUM.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/vue-core.Fp3hcEis.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/explainer.CMppEa5M.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/ArticleDetails.mD5mgYDd.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/ArticleLayoutHeader.D9gZ2sBt.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/AnnouncementCard.Db7nmstV.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/FloatingButtons.xuP8gC33.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/ArticleEvent.D0PaxIW7.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/SimilarArticles.BMee4Fk4.css">
<link rel="stylesheet" href="/ap-2024/_nuxt/ArticleTemplateBanner.CXmOJ7NH.css">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/BXwRzDm6.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/B674Mi_H.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/BXedFy5e.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/eQMj-Fph.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/wtPE5RM2.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/BUyL5Z_3.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/CxAFdcXK.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/DHv8pTSw.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/BHPWSuhB.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/x5HZk7Le.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/CNJXQ6ZR.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/Dss5ciUI.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/g1oT8bcl.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/CPRHjy1u.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/DDayk0N_.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/BlKsMhAy.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/Ttmv6dO3.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/v_uhO3_6.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/CDht2Axh.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/VtxHbjd2.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/Df210yKO.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/L0bfV2sU.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/D01RgZAA.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/DrK18lk-.js">
<link rel="modulepreload" as="script" crossorigin href="/ap-2024/_nuxt/Cno1pHUS.js">
<link rel="prefetch" as="script" crossorigin href="/ap-2024/_nuxt/Dlz5g2Id.js">
<link rel="prefetch" as="style" crossorigin href="/ap-2024/_nuxt/ArticleHubLayout.q6CU8_bN.css">
<link rel="prefetch" as="script" crossorigin href="/ap-2024/_nuxt/GtA5jEuR.js">
<link rel="prefetch" as="script" crossorigin href="/ap-2024/_nuxt/D1ZTLht9.js">
<link rel="prefetch" as="script" crossorigin href="/ap-2024/_nuxt/GWtHKqLR.js">
<link rel="prefetch" as="script" crossorigin href="/ap-2024/_nuxt/Bfcx7IzU.js">
<meta name="theme-color" content="#0C4DED">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" data-hid="4cd079c">window.NREUM||(NREUM={});NREUM.info = {"agent":"","beacon":"bam.nr-data.net","errorBeacon":"bam.nr-data.net","licenseKey":"598a124f17","applicationID":"586843029","agentToken":null,"applicationTime":3.885178,"transactionName":"MQcDMkECCkNSW0YMWghNLwlBDgVcWkJXAWAUC04MXBYWXlJUQUpbAxcTCUAADVVdW1dKVBQWCAVfBhcfGRdUC1wIEU9UA1JTHgMIAlMHSQQUCl8=","queueTime":0,"ttGuid":"9eb66e422fee85db"}; (window.NREUM||(NREUM={})).init={privacy:{cookies_enabled:true},ajax:{deny_list:["bam.nr-data.net"]},distributed_tracing:{enabled:true}};(window.NREUM||(NREUM={})).loader_config={agentID:"594460232",accountID:"230385",trustKey:"230385",xpid:"VgUHUl5WGwYIUllWBAEFXw==",licenseKey:"598a124f17",applicationID:"586843029"};;/*! For license information please see nr-loader-spa-1.298.0.min.js.LICENSE.txt */
(()=>{var e,t,r={8122:(e,t,r)=>{"use strict";r.d(t,{a:()=>i});var n=r(944);function i(e,t){try{if(!e||"object"!=typeof e)return(0,n.R)(3);if(!t||"object"!=typeof t)return(0,n.R)(4);const r=Object.create(Object.getPrototypeOf(t),Object.getOwnPropertyDescriptors(t)),o=0===Object.keys(r).length?e:r;for(let a in o)if(void 0!==e[a])try{if(null===e[a]){r[a]=null;continue}Array.isArray(e[a])&&Array.isArray(t[a])?r[a]=Array.from(new Set([...e[a],...t[a]])):"object"==typeof e[a]&&"object"==typeof t[a]?r[a]=i(e[a],t[a]):r[a]=e[a]}catch(e){r[a]||(0,n.R)(1,e)}return r}catch(e){(0,n.R)(2,e)}}},2555:(e,t,r)=>{"use strict";r.d(t,{D:()=>s,f:()=>a});var n=r(384),i=r(8122);const o={beacon:n.NT.beacon,errorBeacon:n.NT.errorBeacon,licenseKey:void 0,applicationID:void 0,sa:void 0,queueTime:void 0,applicationTime:void 0,ttGuid:void 0,user:void 0,account:void 0,product:void 0,extra:void 0,jsAttributes:{},userAttributes:void 0,atts:void 0,transactionName:void 0,tNamePlain:void 0};function a(e){try{return!!e.licenseKey&&!!e.errorBeacon&&!!e.applicationID}catch(e){return!1}}const s=e=>(0,i.a)(e,o)},7699:(e,t,r)=>{"use strict";r.d(t,{It:()=>i,No:()=>n,qh:()=>a,uh:()=>o});const n=16e3,i=1e6,o="NR_CONTAINER_AGENT",a="SESSION_ERROR"},9324:(e,t,r)=>{"use strict";r.d(t,{F3:()=>i,Xs:()=>o,Yq:()=>a,xv:()=>n});const n="1.298.0",i="PROD",o="CDN",a="^2.0.0-alpha.18"},6154:(e,t,r)=>{"use strict";r.d(t,{A4:()=>s,OF:()=>d,RI:()=>i,WN:()=>h,bv:()=>o,gm:()=>a,lR:()=>f,m:()=>u,mw:()=>c,sb:()=>l});var n=r(1863);const i="undefined"!=typeof window&&!!window.document,o="undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self.navigator instanceof WorkerNavigator||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis.navigator instanceof WorkerNavigator),a=i?window:"undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis),s="complete"===a?.document?.readyState,c=Boolean("hidden"===a?.document?.visibilityState),u=""+a?.location,d=/iPad|iPhone|iPod/.test(a.navigator?.userAgent),l=d&&"undefined"==typeof SharedWorker,f=(()=>{const e=a.navigator?.userAgent?.match(/Firefox[/\s](\d+\.\d+)/);return Array.isArray(e)&&e.length>=2?+e[1]:0})(),h=Date.now()-(0,n.t)()},7295:(e,t,r)=>{"use strict";r.d(t,{Xv:()=>a,gX:()=>i,iW:()=>o});var n=[];function i(e){if(!e||o(e))return!1;if(0===n.length)return!0;for(var t=0;t<n.length;t++){var r=n[t];if("*"===r.hostname)return!1;if(s(r.hostname,e.hostname)&&c(r.pathname,e.pathname))return!1}return!0}function o(e){return void 0===e.hostname}function a(e){if(n=[],e&&e.length)for(var t=0;t<e.length;t++){let r=e[t];if(!r)continue;0===r.indexOf("http://")?r=r.substring(7):0===r.indexOf("https://")&&(r=r.substring(8));const i=r.indexOf("/");let o,a;i>0?(o=r.substring(0,i),a=r.substring(i)):(o=r,a="");let[s]=o.split(":");n.push({hostname:s,pathname:a})}}function s(e,t){return!(e.length>t.length)&&t.indexOf(e)===t.length-e.length}function c(e,t){return 0===e.indexOf("/")&&(e=e.substring(1)),0===t.indexOf("/")&&(t=t.substring(1)),""===e||e===t}},3241:(e,t,r)=>{"use strict";r.d(t,{W:()=>o});var n=r(6154);const i="newrelic";function o(e={}){try{n.gm.dispatchEvent(new CustomEvent(i,{detail:e}))}catch(e){}}},1687:(e,t,r)=>{"use strict";r.d(t,{Ak:()=>u,Ze:()=>f,x3:()=>d});var n=r(3241),i=r(7836),o=r(3606),a=r(860),s=r(2646);const c={};function u(e,t){const r={staged:!1,priority:a.P3[t]||0};l(e),c[e].get(t)||c[e].set(t,r)}function d(e,t){e&&c[e]&&(c[e].get(t)&&c[e].delete(t),p(e,t,!1),c[e].size&&h(e))}function l(e){if(!e)throw new Error("agentIdentifier required");c[e]||(c[e]=new Map)}function f(e="",t="feature",r=!1){if(l(e),!e||!c[e].get(t)||r)return p(e,t);c[e].get(t).staged=!0,h(e)}function h(e){const t=Array.from(c[e]);t.every((([e,t])=>t.staged))&&(t.sort(((e,t)=>e[1].priority-t[1].priority)),t.forEach((([t])=>{c[e].delete(t),p(e,t)})))}function p(e,t,r=!0){const a=e?i.ee.get(e):i.ee,c=o.i.handlers;if(!a.aborted&&a.backlog&&c){if((0,n.W)({agentIdentifier:e,type:"lifecycle",name:"drain",feature:t}),r){const e=a.backlog[t],r=c[t];if(r){for(let t=0;e&&t<e.length;++t)g(e[t],r);Object.entries(r).forEach((([e,t])=>{Object.values(t||{}).forEach((t=>{t[0]?.on&&t[0]?.context()instanceof s.y&&t[0].on(e,t[1])}))}))}}a.isolatedBacklog||delete c[t],a.backlog[t]=null,a.emit("drain-"+t,[])}}function g(e,t){var r=e[1];Object.values(t[r]||{}).forEach((t=>{var r=e[0];if(t[0]===r){var n=t[1],i=e[3],o=e[2];n.apply(i,o)}}))}},7836:(e,t,r)=>{"use strict";r.d(t,{P:()=>s,ee:()=>c});var n=r(384),i=r(8990),o=r(2646),a=r(5607);const s="nr@context:".concat(a.W),c=function e(t,r){var n={},a={},d={},l=!1;try{l=16===r.length&&u.initializedAgents?.[r]?.runtime.isolatedBacklog}catch(e){}var f={on:p,addEventListener:p,removeEventListener:function(e,t){var r=n[e];if(!r)return;for(var i=0;i<r.length;i++)r[i]===t&&r.splice(i,1)},emit:function(e,r,n,i,o){!1!==o&&(o=!0);if(c.aborted&&!i)return;t&&o&&t.emit(e,r,n);var s=h(n);g(e).forEach((e=>{e.apply(s,r)}));var u=v()[a[e]];u&&u.push([f,e,r,s]);return s},get:m,listeners:g,context:h,buffer:function(e,t){const r=v();if(t=t||"feature",f.aborted)return;Object.entries(e||{}).forEach((([e,n])=>{a[n]=t,t in r||(r[t]=[])}))},abort:function(){f._aborted=!0,Object.keys(f.backlog).forEach((e=>{delete f.backlog[e]}))},isBuffering:function(e){return!!v()[a[e]]},debugId:r,backlog:l?{}:t&&"object"==typeof t.backlog?t.backlog:{},isolatedBacklog:l};return Object.defineProperty(f,"aborted",{get:()=>{let e=f._aborted||!1;return e||(t&&(e=t.aborted),e)}}),f;function h(e){return e&&e instanceof o.y?e:e?(0,i.I)(e,s,(()=>new o.y(s))):new o.y(s)}function p(e,t){n[e]=g(e).concat(t)}function g(e){return n[e]||[]}function m(t){return d[t]=d[t]||e(f,t)}function v(){return f.backlog}}(void 0,"globalEE"),u=(0,n.Zm)();u.ee||(u.ee=c)},2646:(e,t,r)=>{"use strict";r.d(t,{y:()=>n});class n{constructor(e){this.contextId=e}}},9908:(e,t,r)=>{"use strict";r.d(t,{d:()=>n,p:()=>i});var n=r(7836).ee.get("handle");function i(e,t,r,i,o){o?(o.buffer([e],i),o.emit(e,t,r)):(n.buffer([e],i),n.emit(e,t,r))}},3606:(e,t,r)=>{"use strict";r.d(t,{i:()=>o});var n=r(9908);o.on=a;var i=o.handlers={};function o(e,t,r,o){a(o||n.d,i,e,t,r)}function a(e,t,r,i,o){o||(o="feature"),e||(e=n.d);var a=t[o]=t[o]||{};(a[r]=a[r]||[]).push([e,i])}},3878:(e,t,r)=>{"use strict";function n(e,t){return{capture:e,passive:!1,signal:t}}function i(e,t,r=!1,i){window.addEventListener(e,t,n(r,i))}function o(e,t,r=!1,i){document.addEventListener(e,t,n(r,i))}r.d(t,{DD:()=>o,jT:()=>n,sp:()=>i})},5607:(e,t,r)=>{"use strict";r.d(t,{W:()=>n});const n=(0,r(9566).bz)()},9566:(e,t,r)=>{"use strict";r.d(t,{LA:()=>s,ZF:()=>c,bz:()=>a,el:()=>u});var n=r(6154);const i="xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";function o(e,t){return e?15&e[t]:16*Math.random()|0}function a(){const e=n.gm?.crypto||n.gm?.msCrypto;let t,r=0;return e&&e.getRandomValues&&(t=e.getRandomValues(new Uint8Array(30))),i.split("").map((e=>"x"===e?o(t,r++).toString(16):"y"===e?(3&o()|8).toString(16):e)).join("")}function s(e){const t=n.gm?.crypto||n.gm?.msCrypto;let r,i=0;t&&t.getRandomValues&&(r=t.getRandomValues(new Uint8Array(e)));const a=[];for(var s=0;s<e;s++)a.push(o(r,i++).toString(16));return a.join("")}function c(){return s(16)}function u(){return s(32)}},2614:(e,t,r)=>{"use strict";r.d(t,{BB:()=>a,H3:()=>n,g:()=>u,iL:()=>c,tS:()=>s,uh:()=>i,wk:()=>o});const n="NRBA",i="SESSION",o=144e5,a=18e5,s={STARTED:"session-started",PAUSE:"session-pause",RESET:"session-reset",RESUME:"session-resume",UPDATE:"session-update"},c={SAME_TAB:"same-tab",CROSS_TAB:"cross-tab"},u={OFF:0,FULL:1,ERROR:2}},1863:(e,t,r)=>{"use strict";function n(){return Math.floor(performance.now())}r.d(t,{t:()=>n})},7485:(e,t,r)=>{"use strict";r.d(t,{D:()=>i});var n=r(6154);function i(e){if(0===(e||"").indexOf("data:"))return{protocol:"data"};try{const t=new URL(e,location.href),r={port:t.port,hostname:t.hostname,pathname:t.pathname,search:t.search,protocol:t.protocol.slice(0,t.protocol.indexOf(":")),sameOrigin:t.protocol===n.gm?.location?.protocol&&t.host===n.gm?.location?.host};return r.port&&""!==r.port||("http:"===t.protocol&&(r.port="80"),"https:"===t.protocol&&(r.port="443")),r.pathname&&""!==r.pathname?r.pathname.startsWith("/")||(r.pathname="/".concat(r.pathname)):r.pathname="/",r}catch(e){return{}}}},944:(e,t,r)=>{"use strict";r.d(t,{R:()=>i});var n=r(3241);function i(e,t){"function"==typeof console.debug&&(console.debug("New Relic Warning: https://github.com/newrelic/newrelic-browser-agent/blob/main/docs/warning-codes.md#".concat(e),t),(0,n.W)({agentIdentifier:null,drained:null,type:"data",name:"warn",feature:"warn",data:{code:e,secondary:t}}))}},5701:(e,t,r)=>{"use strict";r.d(t,{B:()=>o,t:()=>a});var n=r(3241);const i=new Set,o={};function a(e,t){const r=t.agentIdentifier;o[r]??={},e&&"object"==typeof e&&(i.has(r)||(t.ee.emit("rumresp",[e]),o[r]=e,i.add(r),(0,n.W)({agentIdentifier:r,loaded:!0,drained:!0,type:"lifecycle",name:"load",feature:void 0,data:e})))}},8990:(e,t,r)=>{"use strict";r.d(t,{I:()=>i});var n=Object.prototype.hasOwnProperty;function i(e,t,r){if(n.call(e,t))return e[t];var i=r();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,t,{value:i,writable:!0,enumerable:!1}),i}catch(e){}return e[t]=i,i}},6389:(e,t,r)=>{"use strict";function n(e,t=500,r={}){const n=r?.leading||!1;let i;return(...r)=>{n&&void 0===i&&(e.apply(this,r),i=setTimeout((()=>{i=clearTimeout(i)}),t)),n||(clearTimeout(i),i=setTimeout((()=>{e.apply(this,r)}),t))}}function i(e){let t=!1;return(...r)=>{t||(t=!0,e.apply(this,r))}}r.d(t,{J:()=>i,s:()=>n})},1910:(e,t,r)=>{"use strict";r.d(t,{i:()=>o});var n=r(944);const i=new Map;function o(...e){return e.every((e=>{if(i.has(e))return i.get(e);const t="function"==typeof e&&e.toString().includes("[native code]");return t||(0,n.R)(64,e?.name||e?.toString()),i.set(e,t),t}))}},3304:(e,t,r)=>{"use strict";r.d(t,{A:()=>o});var n=r(7836);const i=()=>{const e=new WeakSet;return(t,r)=>{if("object"==typeof r&&null!==r){if(e.has(r))return;e.add(r)}return r}};function o(e){try{return JSON.stringify(e,i())??""}catch(e){try{n.ee.emit("internal-error",[e])}catch(e){}return""}}},3496:(e,t,r)=>{"use strict";function n(e){return!e||!(!e.licenseKey||!e.applicationID)}function i(e,t){return!e||e.licenseKey===t.info.licenseKey&&e.applicationID===t.info.applicationID}r.d(t,{A:()=>i,I:()=>n})},5289:(e,t,r)=>{"use strict";r.d(t,{GG:()=>o,Qr:()=>s,sB:()=>a});var n=r(3878);function i(){return"undefined"==typeof document||"complete"===document.readyState}function o(e,t){if(i())return e();(0,n.sp)("load",e,t)}function a(e){if(i())return e();(0,n.DD)("DOMContentLoaded",e)}function s(e){if(i())return e();(0,n.sp)("popstate",e)}},384:(e,t,r)=>{"use strict";r.d(t,{NT:()=>a,US:()=>d,Zm:()=>s,bQ:()=>u,dV:()=>c,pV:()=>l});var n=r(6154),i=r(1863),o=r(1910);const a={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net"};function s(){return n.gm.NREUM||(n.gm.NREUM={}),void 0===n.gm.newrelic&&(n.gm.newrelic=n.gm.NREUM),n.gm.NREUM}function c(){let e=s();return e.o||(e.o={ST:n.gm.setTimeout,SI:n.gm.setImmediate||n.gm.setInterval,CT:n.gm.clearTimeout,XHR:n.gm.XMLHttpRequest,REQ:n.gm.Request,EV:n.gm.Event,PR:n.gm.Promise,MO:n.gm.MutationObserver,FETCH:n.gm.fetch,WS:n.gm.WebSocket},(0,o.i)(...Object.values(e.o))),e}function u(e,t){let r=s();r.initializedAgents??={},t.initializedAt={ms:(0,i.t)(),date:new Date},r.initializedAgents[e]=t}function d(e,t){s()[e]=t}function l(){return function(){let e=s();const t=e.info||{};e.info={beacon:a.beacon,errorBeacon:a.errorBeacon,...t}}(),function(){let e=s();const t=e.init||{};e.init={...t}}(),c(),function(){let e=s();const t=e.loader_config||{};e.loader_config={...t}}(),s()}},2843:(e,t,r)=>{"use strict";r.d(t,{u:()=>i});var n=r(3878);function i(e,t=!1,r,i){(0,n.DD)("visibilitychange",(function(){if(t)return void("hidden"===document.visibilityState&&e());e(document.visibilityState)}),r,i)}},8139:(e,t,r)=>{"use strict";r.d(t,{u:()=>f});var n=r(7836),i=r(3434),o=r(8990),a=r(6154);const s={},c=a.gm.XMLHttpRequest,u="addEventListener",d="removeEventListener",l="nr@wrapped:".concat(n.P);function f(e){var t=function(e){return(e||n.ee).get("events")}(e);if(s[t.debugId]++)return t;s[t.debugId]=1;var r=(0,i.YM)(t,!0);function f(e){r.inPlace(e,[u,d],"-",p)}function p(e,t){return e[1]}return"getPrototypeOf"in Object&&(a.RI&&h(document,f),c&&h(c.prototype,f),h(a.gm,f)),t.on(u+"-start",(function(e,t){var n=e[1];if(null!==n&&("function"==typeof n||"object"==typeof n)&&"newrelic"!==e[0]){var i=(0,o.I)(n,l,(function(){var e={object:function(){if("function"!=typeof n.handleEvent)return;return n.handleEvent.apply(n,arguments)},function:n}[typeof n];return e?r(e,"fn-",null,e.name||"anonymous"):n}));this.wrapped=e[1]=i}})),t.on(d+"-start",(function(e){e[1]=this.wrapped||e[1]})),t}function h(e,t,...r){let n=e;for(;"object"==typeof n&&!Object.prototype.hasOwnProperty.call(n,u);)n=Object.getPrototypeOf(n);n&&t(n,...r)}},3434:(e,t,r)=>{"use strict";r.d(t,{Jt:()=>o,YM:()=>u});var n=r(7836),i=r(5607);const o="nr@original:".concat(i.W),a=50;var s=Object.prototype.hasOwnProperty,c=!1;function u(e,t){return e||(e=n.ee),r.inPlace=function(e,t,n,i,o){n||(n="");const a="-"===n.charAt(0);for(let s=0;s<t.length;s++){const c=t[s],u=e[c];l(u)||(e[c]=r(u,a?c+n:n,i,c,o))}},r.flag=o,r;function r(t,r,n,c,u){return l(t)?t:(r||(r=""),nrWrapper[o]=t,function(e,t,r){if(Object.defineProperty&&Object.keys)try{return Object.keys(e).forEach((function(r){Object.defineProperty(t,r,{get:function(){return e[r]},set:function(t){return e[r]=t,t}})})),t}catch(e){d([e],r)}for(var n in e)s.call(e,n)&&(t[n]=e[n])}(t,nrWrapper,e),nrWrapper);function nrWrapper(){var o,s,l,f;let h;try{s=this,o=[...arguments],l="function"==typeof n?n(o,s):n||{}}catch(t){d([t,"",[o,s,c],l],e)}i(r+"start",[o,s,c],l,u);const p=performance.now();let g;try{return f=t.apply(s,o),g=performance.now(),f}catch(e){throw g=performance.now(),i(r+"err",[o,s,e],l,u),h=e,h}finally{const e=g-p,t={start:p,end:g,duration:e,isLongTask:e>=a,methodName:c,thrownError:h};t.isLongTask&&i("long-task",[t,s],l,u),i(r+"end",[o,s,f],l,u)}}}function i(r,n,i,o){if(!c||t){var a=c;c=!0;try{e.emit(r,n,i,t,o)}catch(t){d([t,r,n,i],e)}c=a}}}function d(e,t){t||(t=n.ee);try{t.emit("internal-error",e)}catch(e){}}function l(e){return!(e&&"function"==typeof e&&e.apply&&!e[o])}},9300:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.ajax},3333:(e,t,r)=>{"use strict";r.d(t,{$v:()=>u,TZ:()=>n,Zp:()=>i,kd:()=>c,mq:()=>s,nf:()=>a,qN:()=>o});const n=r(860).K7.genericEvents,i=["auxclick","click","copy","keydown","paste","scrollend"],o=["focus","blur"],a=4,s=1e3,c=["PageAction","UserAction","BrowserPerformance"],u={MARKS:"experimental.marks",MEASURES:"experimental.measures",RESOURCES:"experimental.resources"}},6774:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.jserrors},993:(e,t,r)=>{"use strict";r.d(t,{A$:()=>o,ET:()=>a,TZ:()=>s,p_:()=>i});var n=r(860);const i={ERROR:"ERROR",WARN:"WARN",INFO:"INFO",DEBUG:"DEBUG",TRACE:"TRACE"},o={OFF:0,ERROR:1,WARN:2,INFO:3,DEBUG:4,TRACE:5},a="log",s=n.K7.logging},3785:(e,t,r)=>{"use strict";r.d(t,{R:()=>c,b:()=>u});var n=r(9908),i=r(1863),o=r(860),a=r(8154),s=r(993);function c(e,t,r={},c=s.p_.INFO,u,d=(0,i.t)()){(0,n.p)(a.xV,["API/logging/".concat(c.toLowerCase(),"/called")],void 0,o.K7.metrics,e),(0,n.p)(s.ET,[d,t,r,c,u],void 0,o.K7.logging,e)}function u(e){return"string"==typeof e&&Object.values(s.p_).some((t=>t===e.toUpperCase().trim()))}},8154:(e,t,r)=>{"use strict";r.d(t,{z_:()=>o,XG:()=>s,TZ:()=>n,rs:()=>i,xV:()=>a});r(6154),r(9566),r(384);const n=r(860).K7.metrics,i="sm",o="cm",a="storeSupportabilityMetrics",s="storeEventMetrics"},6630:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.pageViewEvent},782:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.pageViewTiming},6344:(e,t,r)=>{"use strict";r.d(t,{BB:()=>d,G4:()=>o,Qb:()=>l,TZ:()=>i,Ug:()=>a,_s:()=>s,bc:()=>u,yP:()=>c});var n=r(2614);const i=r(860).K7.sessionReplay,o={RECORD:"recordReplay",PAUSE:"pauseReplay",ERROR_DURING_REPLAY:"errorDuringReplay"},a=.12,s={DomContentLoaded:0,Load:1,FullSnapshot:2,IncrementalSnapshot:3,Meta:4,Custom:5},c={[n.g.ERROR]:15e3,[n.g.FULL]:3e5,[n.g.OFF]:0},u={RESET:{message:"Session was reset",sm:"Reset"},IMPORT:{message:"Recorder failed to import",sm:"Import"},TOO_MANY:{message:"429: Too Many Requests",sm:"Too-Many"},TOO_BIG:{message:"Payload was too large",sm:"Too-Big"},CROSS_TAB:{message:"Session Entity was set to OFF on another tab",sm:"Cross-Tab"},ENTITLEMENTS:{message:"Session Replay is not allowed and will not be started",sm:"Entitlement"}},d=5e3,l={API:"api",RESUME:"resume",SWITCH_TO_FULL:"switchToFull",INITIALIZE:"initialize",PRELOAD:"preload"}},5270:(e,t,r)=>{"use strict";r.d(t,{Aw:()=>a,SR:()=>o,rF:()=>s});var n=r(384),i=r(7767);function o(e){return!!(0,n.dV)().o.MO&&(0,i.V)(e)&&!0===e?.session_trace.enabled}function a(e){return!0===e?.session_replay.preload&&o(e)}function s(e,t){try{if("string"==typeof t?.type){if("password"===t.type.toLowerCase())return"*".repeat(e?.length||0);if(void 0!==t?.dataset?.nrUnmask||t?.classList?.contains("nr-unmask"))return e}}catch(e){}return"string"==typeof e?e.replace(/[\S]/g,"*"):"*".repeat(e?.length||0)}},3738:(e,t,r)=>{"use strict";r.d(t,{He:()=>i,Kp:()=>s,Lc:()=>u,Rz:()=>d,TZ:()=>n,bD:()=>o,d3:()=>a,jx:()=>l,sl:()=>f,uP:()=>c});const n=r(860).K7.sessionTrace,i="bstResource",o="resource",a="-start",s="-end",c="fn"+a,u="fn"+s,d="pushState",l=1e3,f=3e4},3962:(e,t,r)=>{"use strict";r.d(t,{AM:()=>a,O2:()=>l,OV:()=>o,Qu:()=>f,TZ:()=>c,ih:()=>h,pP:()=>s,t1:()=>d,tC:()=>i,wD:()=>u});var n=r(860);const i=["click","keydown","submit"],o="popstate",a="api",s="initialPageLoad",c=n.K7.softNav,u=5e3,d=500,l={INITIAL_PAGE_LOAD:"",ROUTE_CHANGE:1,UNSPECIFIED:2},f={INTERACTION:1,AJAX:2,CUSTOM_END:3,CUSTOM_TRACER:4},h={IP:"in progress",PF:"pending finish",FIN:"finished",CAN:"cancelled"}},7378:(e,t,r)=>{"use strict";r.d(t,{$p:()=>x,BR:()=>b,Kp:()=>R,L3:()=>y,Lc:()=>c,NC:()=>o,SG:()=>d,TZ:()=>i,U6:()=>p,UT:()=>m,d3:()=>w,dT:()=>f,e5:()=>E,gx:()=>v,l9:()=>l,oW:()=>h,op:()=>g,rw:()=>u,tH:()=>A,uP:()=>s,wW:()=>T,xq:()=>a});var n=r(384);const i=r(860).K7.spa,o=["click","submit","keypress","keydown","keyup","change"],a=999,s="fn-start",c="fn-end",u="cb-start",d="api-ixn-",l="remaining",f="interaction",h="spaNode",p="jsonpNode",g="fetch-start",m="fetch-done",v="fetch-body-",b="jsonp-end",y=(0,n.dV)().o.ST,w="-start",R="-end",x="-body",T="cb"+R,E="jsTime",A="fetch"},4234:(e,t,r)=>{"use strict";r.d(t,{W:()=>o});var n=r(7836),i=r(1687);class o{constructor(e,t){this.agentIdentifier=e,this.ee=n.ee.get(e),this.featureName=t,this.blocked=!1}deregisterDrain(){(0,i.x3)(this.agentIdentifier,this.featureName)}}},7767:(e,t,r)=>{"use strict";r.d(t,{V:()=>i});var n=r(6154);const i=e=>n.RI&&!0===e?.privacy.cookies_enabled},1741:(e,t,r)=>{"use strict";r.d(t,{W:()=>o});var n=r(944),i=r(4261);class o{#e(e,...t){if(this[e]!==o.prototype[e])return this[e](...t);(0,n.R)(35,e)}addPageAction(e,t){return this.#e(i.hG,e,t)}register(e){return this.#e(i.eY,e)}recordCustomEvent(e,t){return this.#e(i.fF,e,t)}setPageViewName(e,t){return this.#e(i.Fw,e,t)}setCustomAttribute(e,t,r){return this.#e(i.cD,e,t,r)}noticeError(e,t){return this.#e(i.o5,e,t)}setUserId(e){return this.#e(i.Dl,e)}setApplicationVersion(e){return this.#e(i.nb,e)}setErrorHandler(e){return this.#e(i.bt,e)}addRelease(e,t){return this.#e(i.k6,e,t)}log(e,t){return this.#e(i.$9,e,t)}start(){return this.#e(i.d3)}finished(e){return this.#e(i.BL,e)}recordReplay(){return this.#e(i.CH)}pauseReplay(){return this.#e(i.Tb)}addToTrace(e){return this.#e(i.U2,e)}setCurrentRouteName(e){return this.#e(i.PA,e)}interaction(){return this.#e(i.dT)}wrapLogger(e,t,r){return this.#e(i.Wb,e,t,r)}measure(e,t){return this.#e(i.V1,e,t)}}},4261:(e,t,r)=>{"use strict";r.d(t,{$9:()=>d,BL:()=>c,CH:()=>p,Dl:()=>R,Fw:()=>w,PA:()=>v,Pl:()=>n,Tb:()=>f,U2:()=>a,V1:()=>E,Wb:()=>T,bt:()=>y,cD:()=>b,d3:()=>x,dT:()=>u,eY:()=>g,fF:()=>h,hG:()=>o,hw:()=>i,k6:()=>s,nb:()=>m,o5:()=>l});const n="api-",i=n+"ixn-",o="addPageAction",a="addToTrace",s="addRelease",c="finished",u="interaction",d="log",l="noticeError",f="pauseReplay",h="recordCustomEvent",p="recordReplay",g="register",m="setApplicationVersion",v="setCurrentRouteName",b="setCustomAttribute",y="setErrorHandler",w="setPageViewName",R="setUserId",x="start",T="wrapLogger",E="measure"},5205:(e,t,r)=>{"use strict";r.d(t,{j:()=>S});var n=r(384),i=r(1741);var o=r(2555),a=r(3333);const s=e=>{if(!e||"string"!=typeof e)return!1;try{document.createDocumentFragment().querySelector(e)}catch{return!1}return!0};var c=r(2614),u=r(944),d=r(8122);const l="[data-nr-mask]",f=e=>(0,d.a)(e,(()=>{const e={feature_flags:[],experimental:{marks:!1,measures:!1,resources:!1},mask_selector:"*",block_selector:"[data-nr-block]",mask_input_options:{color:!1,date:!1,"datetime-local":!1,email:!1,month:!1,number:!1,range:!1,search:!1,tel:!1,text:!1,time:!1,url:!1,week:!1,textarea:!1,select:!1,password:!0}};return{ajax:{deny_list:void 0,block_internal:!0,enabled:!0,autoStart:!0},api:{allow_registered_children:!0,duplicate_registered_data:!1},distributed_tracing:{enabled:void 0,exclude_newrelic_header:void 0,cors_use_newrelic_header:void 0,cors_use_tracecontext_headers:void 0,allowed_origins:void 0},get feature_flags(){return e.feature_flags},set feature_flags(t){e.feature_flags=t},generic_events:{enabled:!0,autoStart:!0},harvest:{interval:30},jserrors:{enabled:!0,autoStart:!0},logging:{enabled:!0,autoStart:!0},metrics:{enabled:!0,autoStart:!0},obfuscate:void 0,page_action:{enabled:!0},page_view_event:{enabled:!0,autoStart:!0},page_view_timing:{enabled:!0,autoStart:!0},performance:{get capture_marks(){return e.feature_flags.includes(a.$v.MARKS)||e.experimental.marks},set capture_marks(t){e.experimental.marks=t},get capture_measures(){return e.feature_flags.includes(a.$v.MEASURES)||e.experimental.measures},set capture_measures(t){e.experimental.measures=t},capture_detail:!0,resources:{get enabled(){return e.feature_flags.includes(a.$v.RESOURCES)||e.experimental.resources},set enabled(t){e.experimental.resources=t},asset_types:[],first_party_domains:[],ignore_newrelic:!0}},privacy:{cookies_enabled:!0},proxy:{assets:void 0,beacon:void 0},session:{expiresMs:c.wk,inactiveMs:c.BB},session_replay:{autoStart:!0,enabled:!1,preload:!1,sampling_rate:10,error_sampling_rate:100,collect_fonts:!1,inline_images:!1,fix_stylesheets:!0,mask_all_inputs:!0,get mask_text_selector(){return e.mask_selector},set mask_text_selector(t){s(t)?e.mask_selector="".concat(t,",").concat(l):""===t||null===t?e.mask_selector=l:(0,u.R)(5,t)},get block_class(){return"nr-block"},get ignore_class(){return"nr-ignore"},get mask_text_class(){return"nr-mask"},get block_selector(){return e.block_selector},set block_selector(t){s(t)?e.block_selector+=",".concat(t):""!==t&&(0,u.R)(6,t)},get mask_input_options(){return e.mask_input_options},set mask_input_options(t){t&&"object"==typeof t?e.mask_input_options={...t,password:!0}:(0,u.R)(7,t)}},session_trace:{enabled:!0,autoStart:!0},soft_navigations:{enabled:!0,autoStart:!0},spa:{enabled:!0,autoStart:!0},ssl:void 0,user_actions:{enabled:!0,elementAttributes:["id","className","tagName","type"]}}})());var h=r(6154),p=r(9324);let g=0;const m={buildEnv:p.F3,distMethod:p.Xs,version:p.xv,originTime:h.WN},v={appMetadata:{},customTransaction:void 0,denyList:void 0,disabled:!1,entityManager:void 0,harvester:void 0,isolatedBacklog:!1,isRecording:!1,loaderType:void 0,maxBytes:3e4,obfuscator:void 0,onerror:void 0,ptid:void 0,releaseIds:{},session:void 0,timeKeeper:void 0,jsAttributesMetadata:{bytes:0},get harvestCount(){return++g}},b=e=>{const t=(0,d.a)(e,v),r=Object.keys(m).reduce(((e,t)=>(e[t]={value:m[t],writable:!1,configurable:!0,enumerable:!0},e)),{});return Object.defineProperties(t,r)};var y=r(5701);const w=e=>{const t=e.startsWith("http");e+="/",r.p=t?e:"https://"+e};var R=r(7836),x=r(3241);const T={accountID:void 0,trustKey:void 0,agentID:void 0,licenseKey:void 0,applicationID:void 0,xpid:void 0},E=e=>(0,d.a)(e,T),A=new Set;function S(e,t={},r,a){let{init:s,info:c,loader_config:u,runtime:d={},exposed:l=!0}=t;if(!c){const e=(0,n.pV)();s=e.init,c=e.info,u=e.loader_config}e.init=f(s||{}),e.loader_config=E(u||{}),c.jsAttributes??={},h.bv&&(c.jsAttributes.isWorker=!0),e.info=(0,o.D)(c);const p=e.init,g=[c.beacon,c.errorBeacon];A.has(e.agentIdentifier)||(p.proxy.assets&&(w(p.proxy.assets),g.push(p.proxy.assets)),p.proxy.beacon&&g.push(p.proxy.beacon),function(e){const t=(0,n.pV)();Object.getOwnPropertyNames(i.W.prototype).forEach((r=>{const n=i.W.prototype[r];if("function"!=typeof n||"constructor"===n)return;let o=t[r];e[r]&&!1!==e.exposed&&"micro-agent"!==e.runtime?.loaderType&&(t[r]=(...t)=>{const n=e[r](...t);return o?o(...t):n})}))}(e),(0,n.US)("activatedFeatures",y.B),e.runSoftNavOverSpa&&=!0===p.soft_navigations.enabled&&p.feature_flags.includes("soft_nav")),d.denyList=[...p.ajax.deny_list||[],...p.ajax.block_internal?g:[]],d.ptid=e.agentIdentifier,d.loaderType=r,e.runtime=b(d),A.has(e.agentIdentifier)||(e.ee=R.ee.get(e.agentIdentifier),e.exposed=l,(0,x.W)({agentIdentifier:e.agentIdentifier,drained:!!y.B?.[e.agentIdentifier],type:"lifecycle",name:"initialize",feature:void 0,data:e.config})),A.add(e.agentIdentifier)}},8374:(e,t,r)=>{r.nc=(()=>{try{return document?.currentScript?.nonce}catch(e){}return""})()},860:(e,t,r)=>{"use strict";r.d(t,{$J:()=>d,K7:()=>c,P3:()=>u,XX:()=>i,Yy:()=>s,df:()=>o,qY:()=>n,v4:()=>a});const n="events",i="jserrors",o="browser/blobs",a="rum",s="browser/logs",c={ajax:"ajax",genericEvents:"generic_events",jserrors:i,logging:"logging",metrics:"metrics",pageAction:"page_action",pageViewEvent:"page_view_event",pageViewTiming:"page_view_timing",sessionReplay:"session_replay",sessionTrace:"session_trace",softNav:"soft_navigations",spa:"spa"},u={[c.pageViewEvent]:1,[c.pageViewTiming]:2,[c.metrics]:3,[c.jserrors]:4,[c.spa]:5,[c.ajax]:6,[c.sessionTrace]:7,[c.softNav]:8,[c.sessionReplay]:9,[c.logging]:10,[c.genericEvents]:11},d={[c.pageViewEvent]:a,[c.pageViewTiming]:n,[c.ajax]:n,[c.spa]:n,[c.softNav]:n,[c.metrics]:i,[c.jserrors]:i,[c.sessionTrace]:o,[c.sessionReplay]:o,[c.logging]:s,[c.genericEvents]:"ins"}}},n={};function i(e){var t=n[e];if(void 0!==t)return t.exports;var o=n[e]={exports:{}};return r[e](o,o.exports,i),o.exports}i.m=r,i.d=(e,t)=>{for(var r in t)i.o(t,r)&&!i.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},i.f={},i.e=e=>Promise.all(Object.keys(i.f).reduce(((t,r)=>(i.f[r](e,t),t)),[])),i.u=e=>({212:"nr-spa-compressor",249:"nr-spa-recorder",478:"nr-spa"}[e]+"-1.298.0.min.js"),i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),e={},t="NRBA-1.298.0.PROD:",i.l=(r,n,o,a)=>{if(e[r])e[r].push(n);else{var s,c;if(void 0!==o)for(var u=document.getElementsByTagName("script"),d=0;d<u.length;d++){var l=u[d];if(l.getAttribute("src")==r||l.getAttribute("data-webpack")==t+o){s=l;break}}if(!s){c=!0;var f={478:"sha512-HSzyNKgJkuD44GAhaqv0J6DKcfr1w2jxbMOXpVRlEPzOJ5GjWJWQZIdOL87SoGmx16NaL73pHxiN9KyHn0UrgA==",249:"sha512-xTIxx7hc1QvTaXfB6dqbBMAiZHtwW1OwcFbBfxC79mvUj0Pv1mHSmucWTWPFxLHkrm634DEJq3+YEWA3rMzWbQ==",212:"sha512-SsdMj4Co3WAfG+frLMYFYoHlVeE1k16lyb/G4bKQ2fIFXjgqC9R56ukLcI2p2IitTkwwpEAJ9qMssxBjVA/D3Q=="};(s=document.createElement("script")).charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.setAttribute("data-webpack",t+o),s.src=r,0!==s.src.indexOf(window.location.origin+"/")&&(s.crossOrigin="anonymous"),f[a]&&(s.integrity=f[a])}e[r]=[n];var h=(t,n)=>{s.onerror=s.onload=null,clearTimeout(p);var i=e[r];if(delete e[r],s.parentNode&&s.parentNode.removeChild(s),i&&i.forEach((e=>e(n))),t)return t(n)},p=setTimeout(h.bind(null,void 0,{type:"timeout",target:s}),12e4);s.onerror=h.bind(null,s.onerror),s.onload=h.bind(null,s.onload),c&&document.head.appendChild(s)}},i.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.p="https://js-agent.newrelic.com/",(()=>{var e={38:0,788:0};i.f.j=(t,r)=>{var n=i.o(e,t)?e[t]:void 0;if(0!==n)if(n)r.push(n[2]);else{var o=new Promise(((r,i)=>n=e[t]=[r,i]));r.push(n[2]=o);var a=i.p+i.u(t),s=new Error;i.l(a,(r=>{if(i.o(e,t)&&(0!==(n=e[t])&&(e[t]=void 0),n)){var o=r&&("load"===r.type?"missing":r.type),a=r&&r.target&&r.target.src;s.message="Loading chunk "+t+" failed.\n("+o+": "+a+")",s.name="ChunkLoadError",s.type=o,s.request=a,n[1](s)}}),"chunk-"+t,t)}};var t=(t,r)=>{var n,o,[a,s,c]=r,u=0;if(a.some((t=>0!==e[t]))){for(n in s)i.o(s,n)&&(i.m[n]=s[n]);if(c)c(i)}for(t&&t(r);u<a.length;u++)o=a[u],i.o(e,o)&&e[o]&&e[o][0](),e[o]=0},r=self["webpackChunk:NRBA-1.298.0.PROD"]=self["webpackChunk:NRBA-1.298.0.PROD"]||[];r.forEach(t.bind(null,0)),r.push=t.bind(null,r.push.bind(r))})(),(()=>{"use strict";i(8374);var e=i(9566),t=i(1741);class r extends t.W{agentIdentifier=(0,e.LA)(16)}var n=i(860);const o=Object.values(n.K7);var a=i(5205);var s=i(9908),c=i(1863),u=i(4261),d=i(3241),l=i(944),f=i(5701),h=i(8154);function p(e,t,i,o){const a=o||i;!a||a[e]&&a[e]!==r.prototype[e]||(a[e]=function(){(0,s.p)(h.xV,["API/"+e+"/called"],void 0,n.K7.metrics,i.ee),(0,d.W)({agentIdentifier:i.agentIdentifier,drained:!!f.B?.[i.agentIdentifier],type:"data",name:"api",feature:u.Pl+e,data:{}});try{return t.apply(this,arguments)}catch(e){(0,l.R)(23,e)}})}function g(e,t,r,n,i){const o=e.info;null===r?delete o.jsAttributes[t]:o.jsAttributes[t]=r,(i||null===r)&&(0,s.p)(u.Pl+n,[(0,c.t)(),t,r],void 0,"session",e.ee)}var m=i(1687),v=i(4234),b=i(5289),y=i(6154),w=i(5270),R=i(7767),x=i(6389),T=i(7699);class E extends v.W{constructor(e,t){super(e.agentIdentifier,t),this.agentRef=e,this.abortHandler=void 0,this.featAggregate=void 0,this.onAggregateImported=void 0,this.deferred=Promise.resolve(),!1===e.init[this.featureName].autoStart?this.deferred=new Promise(((t,r)=>{this.ee.on("manual-start-all",(0,x.J)((()=>{(0,m.Ak)(e.agentIdentifier,this.featureName),t()})))})):(0,m.Ak)(e.agentIdentifier,t)}importAggregator(e,t,r={}){if(this.featAggregate)return;let n;this.onAggregateImported=new Promise((e=>{n=e}));const o=async()=>{let o;await this.deferred;try{if((0,R.V)(e.init)){const{setupAgentSession:t}=await i.e(478).then(i.bind(i,2955));o=t(e)}}catch(e){(0,l.R)(20,e),this.ee.emit("internal-error",[e]),(0,s.p)(T.qh,[e],void 0,this.featureName,this.ee)}try{if(!this.#t(this.featureName,o,e.init))return(0,m.Ze)(this.agentIdentifier,this.featureName),void n(!1);const{Aggregate:i}=await t();this.featAggregate=new i(e,r),e.runtime.harvester.initializedAggregates.push(this.featAggregate),n(!0)}catch(e){(0,l.R)(34,e),this.abortHandler?.(),(0,m.Ze)(this.agentIdentifier,this.featureName,!0),n(!1),this.ee&&this.ee.abort()}};y.RI?(0,b.GG)((()=>o()),!0):o()}#t(e,t,r){if(this.blocked)return!1;switch(e){case n.K7.sessionReplay:return(0,w.SR)(r)&&!!t;case n.K7.sessionTrace:return!!t;default:return!0}}}var A=i(6630),S=i(2614);class _ extends E{static featureName=A.T;constructor(e){var t;super(e,A.T),this.setupInspectionEvents(e.agentIdentifier),t=e,p(u.Fw,(function(e,r){"string"==typeof e&&("/"!==e.charAt(0)&&(e="/"+e),t.runtime.customTransaction=(r||"http://custom.transaction")+e,(0,s.p)(u.Pl+u.Fw,[(0,c.t)()],void 0,void 0,t.ee))}),t),this.ee.on("api-send-rum",((e,t)=>(0,s.p)("send-rum",[e,t],void 0,this.featureName,this.ee))),this.importAggregator(e,(()=>i.e(478).then(i.bind(i,1983))))}setupInspectionEvents(e){const t=(t,r)=>{t&&(0,d.W)({agentIdentifier:e,timeStamp:t.timeStamp,loaded:"complete"===t.target.readyState,type:"window",name:r,data:t.target.location+""})};(0,b.sB)((e=>{t(e,"DOMContentLoaded")})),(0,b.GG)((e=>{t(e,"load")})),(0,b.Qr)((e=>{t(e,"navigate")})),this.ee.on(S.tS.UPDATE,((t,r)=>{(0,d.W)({agentIdentifier:e,type:"lifecycle",name:"session",data:r})}))}}var N=i(384);var O=i(2843),I=i(3878),P=i(782);class j extends E{static featureName=P.T;constructor(e){super(e,P.T),y.RI&&((0,O.u)((()=>(0,s.p)("docHidden",[(0,c.t)()],void 0,P.T,this.ee)),!0),(0,I.sp)("pagehide",(()=>(0,s.p)("winPagehide",[(0,c.t)()],void 0,P.T,this.ee))),this.importAggregator(e,(()=>i.e(478).then(i.bind(i,9917)))))}}class k extends E{static featureName=h.TZ;constructor(e){super(e,h.TZ),y.RI&&document.addEventListener("securitypolicyviolation",(e=>{(0,s.p)(h.xV,["Generic/CSPViolation/Detected"],void 0,this.featureName,this.ee)})),this.importAggregator(e,(()=>i.e(478).then(i.bind(i,8351))))}}var C=i(6774),L=i(3304);class M{constructor(e,t,r,n,i){this.name="UncaughtError",this.message="string"==typeof e?e:(0,L.A)(e),this.sourceURL=t,this.line=r,this.column=n,this.__newrelic=i}}function H(e){return U(e)?e:new M(void 0!==e?.message?e.message:e,e?.filename||e?.sourceURL,e?.lineno||e?.line,e?.colno||e?.col,e?.__newrelic,e?.cause)}function D(e){const t="Unhandled Promise Rejection: ";if(!e?.reason)return;if(U(e.reason)){try{e.reason.message.startsWith(t)||(e.reason.message=t+e.reason.message)}catch(e){}return H(e.reason)}const r=H(e.reason);return(r.message||"").startsWith(t)||(r.message=t+r.message),r}function K(e){if(e.error instanceof SyntaxError&&!/:\d+$/.test(e.error.stack?.trim())){const t=new M(e.message,e.filename,e.lineno,e.colno,e.error.__newrelic,e.cause);return t.name=SyntaxError.name,t}return U(e.error)?e.error:H(e)}function U(e){return e instanceof Error&&!!e.stack}function F(e,t,r,i,o=(0,c.t)()){"string"==typeof e&&(e=new Error(e)),(0,s.p)("err",[e,o,!1,t,r.runtime.isRecording,void 0,i],void 0,n.K7.jserrors,r.ee)}var W=i(3496),B=i(993),G=i(3785);function V(e,{customAttributes:t={},level:r=B.p_.INFO}={},n,i,o=(0,c.t)()){(0,G.R)(n.ee,e,t,r,i,o)}function z(e,t,r,i,o=(0,c.t)()){(0,s.p)(u.Pl+u.hG,[o,e,t,i],void 0,n.K7.genericEvents,r.ee)}function Z(e){p(u.eY,(function(t){return function(e,t){const r={};let i,o;(0,l.R)(54,"newrelic.register"),e.init.api.allow_registered_children||(i=()=>(0,l.R)(55));t&&(0,W.I)(t)||(i=()=>(0,l.R)(48,t));const a={addPageAction:(n,i={})=>{u(z,[n,{...r,...i},e],t)},log:(n,i={})=>{u(V,[n,{...i,customAttributes:{...r,...i.customAttributes||{}}},e],t)},noticeError:(n,i={})=>{u(F,[n,{...r,...i},e],t)},setApplicationVersion:e=>{r["application.version"]=e},setCustomAttribute:(e,t)=>{r[e]=t},setUserId:e=>{r["enduser.id"]=e},metadata:{customAttributes:r,target:t,get connected(){return o||Promise.reject(new Error("Failed to connect"))}}};i?i():o=new Promise(((n,i)=>{try{const o=e.runtime?.entityManager;let s=!!o?.get().entityGuid,c=o?.getEntityGuidFor(t.licenseKey,t.applicationID),u=!!c;if(s&&u)t.entityGuid=c,n(a);else{const d=setTimeout((()=>i(new Error("Failed to connect - Timeout"))),15e3);function l(r){(0,W.A)(r,e)?s||=!0:t.licenseKey===r.licenseKey&&t.applicationID===r.applicationID&&(u=!0,t.entityGuid=r.entityGuid),s&&u&&(clearTimeout(d),e.ee.removeEventListener("entity-added",l),n(a))}e.ee.emit("api-send-rum",[r,t]),e.ee.on("entity-added",l)}}catch(f){i(f)}}));const u=async(t,r,a)=>{if(i)return i();const u=(0,c.t)();(0,s.p)(h.xV,["API/register/".concat(t.name,"/called")],void 0,n.K7.metrics,e.ee);try{await o;const n=e.init.api.duplicate_registered_data;(!0===n||Array.isArray(n)&&n.includes(a.entityGuid))&&t(...r,void 0,u),t(...r,a.entityGuid,u)}catch(e){(0,l.R)(50,e)}};return a}(e,t)}),e)}class q extends E{static featureName=C.T;constructor(e){var t;super(e,C.T),t=e,p(u.o5,((e,r)=>F(e,r,t)),t),function(e){p(u.bt,(function(t){e.runtime.onerror=t}),e)}(e),function(e){let t=0;p(u.k6,(function(e,r){++t>10||(this.runtime.releaseIds[e.slice(-200)]=(""+r).slice(-200))}),e)}(e),Z(e);try{this.removeOnAbort=new AbortController}catch(e){}this.ee.on("internal-error",((t,r)=>{this.abortHandler&&(0,s.p)("ierr",[H(t),(0,c.t)(),!0,{},e.runtime.isRecording,r],void 0,this.featureName,this.ee)})),y.gm.addEventListener("unhandledrejection",(t=>{this.abortHandler&&(0,s.p)("err",[D(t),(0,c.t)(),!1,{unhandledPromiseRejection:1},e.runtime.isRecording],void 0,this.featureName,this.ee)}),(0,I.jT)(!1,this.removeOnAbort?.signal)),y.gm.addEventListener("error",(t=>{this.abortHandler&&(0,s.p)("err",[K(t),(0,c.t)(),!1,{},e.runtime.isRecording],void 0,this.featureName,this.ee)}),(0,I.jT)(!1,this.removeOnAbort?.signal)),this.abortHandler=this.#r,this.importAggregator(e,(()=>i.e(478).then(i.bind(i,2176))))}#r(){this.removeOnAbort?.abort(),this.abortHandler=void 0}}var X=i(8990);let Y=1;function Q(e){const t=typeof e;return!e||"object"!==t&&"function"!==t?-1:e===y.gm?0:(0,X.I)(e,"nr@id",(function(){return Y++}))}function J(e){if("string"==typeof e&&e.length)return e.length;if("object"==typeof e){if("undefined"!=typeof ArrayBuffer&&e instanceof ArrayBuffer&&e.byteLength)return e.byteLength;if("undefined"!=typeof Blob&&e instanceof Blob&&e.size)return e.size;if(!("undefined"!=typeof FormData&&e instanceof FormData))try{return(0,L.A)(e).length}catch(e){return}}}var ee=i(8139),te=i(7836),re=i(3434);const ne={},ie=["open","send"];function oe(e){var t=e||te.ee;const r=function(e){return(e||te.ee).get("xhr")}(t);if(void 0===y.gm.XMLHttpRequest)return r;if(ne[r.debugId]++)return r;ne[r.debugId]=1,(0,ee.u)(t);var n=(0,re.YM)(r),i=y.gm.XMLHttpRequest,o=y.gm.MutationObserver,a=y.gm.Promise,s=y.gm.setInterval,c="readystatechange",u=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],d=[],f=y.gm.XMLHttpRequest=function(e){const t=new i(e),o=r.context(t);try{r.emit("new-xhr",[t],o),t.addEventListener(c,(a=o,function(){var e=this;e.readyState>3&&!a.resolved&&(a.resolved=!0,r.emit("xhr-resolved",[],e)),n.inPlace(e,u,"fn-",b)}),(0,I.jT)(!1))}catch(e){(0,l.R)(15,e);try{r.emit("internal-error",[e])}catch(e){}}var a;return t};function h(e,t){n.inPlace(t,["onreadystatechange"],"fn-",b)}if(function(e,t){for(var r in e)t[r]=e[r]}(i,f),f.prototype=i.prototype,n.inPlace(f.prototype,ie,"-xhr-",b),r.on("send-xhr-start",(function(e,t){h(e,t),function(e){d.push(e),o&&(p?p.then(v):s?s(v):(g=-g,m.data=g))}(t)})),r.on("open-xhr-start",h),o){var p=a&&a.resolve();if(!s&&!a){var g=1,m=document.createTextNode(g);new o(v).observe(m,{characterData:!0})}}else t.on("fn-end",(function(e){e[0]&&e[0].type===c||v()}));function v(){for(var e=0;e<d.length;e++)h(0,d[e]);d.length&&(d=[])}function b(e,t){return t}return r}var ae="fetch-",se=ae+"body-",ce=["arrayBuffer","blob","json","text","formData"],ue=y.gm.Request,de=y.gm.Response,le="prototype";const fe={};function he(e){const t=function(e){return(e||te.ee).get("fetch")}(e);if(!(ue&&de&&y.gm.fetch))return t;if(fe[t.debugId]++)return t;function r(e,r,n){var i=e[r];"function"==typeof i&&(e[r]=function(){var e,r=[...arguments],o={};t.emit(n+"before-start",[r],o),o[te.P]&&o[te.P].dt&&(e=o[te.P].dt);var a=i.apply(this,r);return t.emit(n+"start",[r,e],a),a.then((function(e){return t.emit(n+"end",[null,e],a),e}),(function(e){throw t.emit(n+"end",[e],a),e}))})}return fe[t.debugId]=1,ce.forEach((e=>{r(ue[le],e,se),r(de[le],e,se)})),r(y.gm,"fetch",ae),t.on(ae+"end",(function(e,r){var n=this;if(r){var i=r.headers.get("content-length");null!==i&&(n.rxSize=i),t.emit(ae+"done",[null,r],n)}else t.emit(ae+"done",[e],n)})),t}var pe=i(7485);class ge{constructor(e){this.agentRef=e}generateTracePayload(t){const r=this.agentRef.loader_config;if(!this.shouldGenerateTrace(t)||!r)return null;var n=(r.accountID||"").toString()||null,i=(r.agentID||"").toString()||null,o=(r.trustKey||"").toString()||null;if(!n||!i)return null;var a=(0,e.ZF)(),s=(0,e.el)(),c=Date.now(),u={spanId:a,traceId:s,timestamp:c};return(t.sameOrigin||this.isAllowedOrigin(t)&&this.useTraceContextHeadersForCors())&&(u.traceContextParentHeader=this.generateTraceContextParentHeader(a,s),u.traceContextStateHeader=this.generateTraceContextStateHeader(a,c,n,i,o)),(t.sameOrigin&&!this.excludeNewrelicHeader()||!t.sameOrigin&&this.isAllowedOrigin(t)&&this.useNewrelicHeaderForCors())&&(u.newrelicHeader=this.generateTraceHeader(a,s,c,n,i,o)),u}generateTraceContextParentHeader(e,t){return"00-"+t+"-"+e+"-01"}generateTraceContextStateHeader(e,t,r,n,i){return i+"@nr=0-1-"+r+"-"+n+"-"+e+"----"+t}generateTraceHeader(e,t,r,n,i,o){if(!("function"==typeof y.gm?.btoa))return null;var a={v:[0,1],d:{ty:"Browser",ac:n,ap:i,id:e,tr:t,ti:r}};return o&&n!==o&&(a.d.tk=o),btoa((0,L.A)(a))}shouldGenerateTrace(e){return this.agentRef.init?.distributed_tracing?.enabled&&this.isAllowedOrigin(e)}isAllowedOrigin(e){var t=!1;const r=this.agentRef.init?.distributed_tracing;if(e.sameOrigin)t=!0;else if(r?.allowed_origins instanceof Array)for(var n=0;n<r.allowed_origins.length;n++){var i=(0,pe.D)(r.allowed_origins[n]);if(e.hostname===i.hostname&&e.protocol===i.protocol&&e.port===i.port){t=!0;break}}return t}excludeNewrelicHeader(){var e=this.agentRef.init?.distributed_tracing;return!!e&&!!e.exclude_newrelic_header}useNewrelicHeaderForCors(){var e=this.agentRef.init?.distributed_tracing;return!!e&&!1!==e.cors_use_newrelic_header}useTraceContextHeadersForCors(){var e=this.agentRef.init?.distributed_tracing;return!!e&&!!e.cors_use_tracecontext_headers}}var me=i(9300),ve=i(7295),be=["load","error","abort","timeout"],ye=be.length,we=(0,N.dV)().o.REQ,Re=(0,N.dV)().o.XHR;const xe="X-NewRelic-App-Data";class Te extends E{static featureName=me.T;constructor(e){super(e,me.T),this.dt=new ge(e),this.handler=(e,t,r,n)=>(0,s.p)(e,t,r,n,this.ee);try{const e={xmlhttprequest:"xhr",fetch:"fetch",beacon:"beacon"};y.gm?.performance?.getEntriesByType("resource").forEach((t=>{if(t.initiatorType in e&&0!==t.responseStatus){const r={status:t.responseStatus},i={rxSize:t.transferSize,duration:Math.floor(t.duration),cbTime:0};Ee(r,t.name),this.handler("xhr",[r,i,t.startTime,t.responseEnd,e[t.initiatorType]],void 0,n.K7.ajax)}}))}catch(e){}he(this.ee),oe(this.ee),function(e,t,r,i){function o(e){var t=this;t.totalCbs=0,t.called=0,t.cbTime=0,t.end=E,t.ended=!1,t.xhrGuids={},t.lastSize=null,t.loadCaptureCalled=!1,t.params=this.params||{},t.metrics=this.metrics||{},t.latestLongtaskEnd=0,e.addEventListener("load",(function(r){A(t,e)}),(0,I.jT)(!1)),y.lR||e.addEventListener("progress",(function(e){t.lastSize=e.loaded}),(0,I.jT)(!1))}function a(e){this.params={method:e[0]},Ee(this,e[1]),this.metrics={}}function u(t,r){e.loader_config.xpid&&this.sameOrigin&&r.setRequestHeader("X-NewRelic-ID",e.loader_config.xpid);var n=i.generateTracePayload(this.parsedOrigin);if(n){var o=!1;n.newrelicHeader&&(r.setRequestHeader("newrelic",n.newrelicHeader),o=!0),n.traceContextParentHeader&&(r.setRequestHeader("traceparent",n.traceContextParentHeader),n.traceContextStateHeader&&r.setRequestHeader("tracestate",n.traceContextStateHeader),o=!0),o&&(this.dt=n)}}function d(e,r){var n=this.metrics,i=e[0],o=this;if(n&&i){var a=J(i);a&&(n.txSize=a)}this.startTime=(0,c.t)(),this.body=i,this.listener=function(e){try{"abort"!==e.type||o.loadCaptureCalled||(o.params.aborted=!0),("load"!==e.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof r.onload)&&"function"==typeof o.end)&&o.end(r)}catch(e){try{t.emit("internal-error",[e])}catch(e){}}};for(var s=0;s<ye;s++)r.addEventListener(be[s],this.listener,(0,I.jT)(!1))}function l(e,t,r){this.cbTime+=e,t?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof r.onload||"function"!=typeof this.end||this.end(r)}function f(e,t){var r=""+Q(e)+!!t;this.xhrGuids&&!this.xhrGuids[r]&&(this.xhrGuids[r]=!0,this.totalCbs+=1)}function p(e,t){var r=""+Q(e)+!!t;this.xhrGuids&&this.xhrGuids[r]&&(delete this.xhrGuids[r],this.totalCbs-=1)}function g(){this.endTime=(0,c.t)()}function m(e,r){r instanceof Re&&"load"===e[0]&&t.emit("xhr-load-added",[e[1],e[2]],r)}function v(e,r){r instanceof Re&&"load"===e[0]&&t.emit("xhr-load-removed",[e[1],e[2]],r)}function b(e,t,r){t instanceof Re&&("onload"===r&&(this.onload=!0),("load"===(e[0]&&e[0].type)||this.onload)&&(this.xhrCbStart=(0,c.t)()))}function w(e,r){this.xhrCbStart&&t.emit("xhr-cb-time",[(0,c.t)()-this.xhrCbStart,this.onload,r],r)}function R(e){var t,r=e[1]||{};if("string"==typeof e[0]?0===(t=e[0]).length&&y.RI&&(t=""+y.gm.location.href):e[0]&&e[0].url?t=e[0].url:y.gm?.URL&&e[0]&&e[0]instanceof URL?t=e[0].href:"function"==typeof e[0].toString&&(t=e[0].toString()),"string"==typeof t&&0!==t.length){t&&(this.parsedOrigin=(0,pe.D)(t),this.sameOrigin=this.parsedOrigin.sameOrigin);var n=i.generateTracePayload(this.parsedOrigin);if(n&&(n.newrelicHeader||n.traceContextParentHeader))if(e[0]&&e[0].headers)s(e[0].headers,n)&&(this.dt=n);else{var o={};for(var a in r)o[a]=r[a];o.headers=new Headers(r.headers||{}),s(o.headers,n)&&(this.dt=n),e.length>1?e[1]=o:e.push(o)}}function s(e,t){var r=!1;return t.newrelicHeader&&(e.set("newrelic",t.newrelicHeader),r=!0),t.traceContextParentHeader&&(e.set("traceparent",t.traceContextParentHeader),t.traceContextStateHeader&&e.set("tracestate",t.traceContextStateHeader),r=!0),r}}function x(e,t){this.params={},this.metrics={},this.startTime=(0,c.t)(),this.dt=t,e.length>=1&&(this.target=e[0]),e.length>=2&&(this.opts=e[1]);var r,n=this.opts||{},i=this.target;"string"==typeof i?r=i:"object"==typeof i&&i instanceof we?r=i.url:y.gm?.URL&&"object"==typeof i&&i instanceof URL&&(r=i.href),Ee(this,r);var o=(""+(i&&i instanceof we&&i.method||n.method||"GET")).toUpperCase();this.params.method=o,this.body=n.body,this.txSize=J(n.body)||0}function T(e,t){if(this.endTime=(0,c.t)(),this.params||(this.params={}),(0,ve.iW)(this.params))return;let i;this.params.status=t?t.status:0,"string"==typeof this.rxSize&&this.rxSize.length>0&&(i=+this.rxSize);const o={txSize:this.txSize,rxSize:i,duration:(0,c.t)()-this.startTime};r("xhr",[this.params,o,this.startTime,this.endTime,"fetch"],this,n.K7.ajax)}function E(e){const t=this.params,i=this.metrics;if(!this.ended){this.ended=!0;for(let t=0;t<ye;t++)e.removeEventListener(be[t],this.listener,!1);t.aborted||(0,ve.iW)(t)||(i.duration=(0,c.t)()-this.startTime,this.loadCaptureCalled||4!==e.readyState?null==t.status&&(t.status=0):A(this,e),i.cbTime=this.cbTime,r("xhr",[t,i,this.startTime,this.endTime,"xhr"],this,n.K7.ajax))}}function A(e,r){e.params.status=r.status;var i=function(e,t){var r=e.responseType;return"json"===r&&null!==t?t:"arraybuffer"===r||"blob"===r||"json"===r?J(e.response):"text"===r||""===r||void 0===r?J(e.responseText):void 0}(r,e.lastSize);if(i&&(e.metrics.rxSize=i),e.sameOrigin&&r.getAllResponseHeaders().indexOf(xe)>=0){var o=r.getResponseHeader(xe);o&&((0,s.p)(h.rs,["Ajax/CrossApplicationTracing/Header/Seen"],void 0,n.K7.metrics,t),e.params.cat=o.split(", ").pop())}e.loadCaptureCalled=!0}t.on("new-xhr",o),t.on("open-xhr-start",a),t.on("open-xhr-end",u),t.on("send-xhr-start",d),t.on("xhr-cb-time",l),t.on("xhr-load-added",f),t.on("xhr-load-removed",p),t.on("xhr-resolved",g),t.on("addEventListener-end",m),t.on("removeEventListener-end",v),t.on("fn-end",w),t.on("fetch-before-start",R),t.on("fetch-start",x),t.on("fn-start",b),t.on("fetch-done",T)}(e,this.ee,this.handler,this.dt),this.importAggregator(e,(()=>i.e(478).then(i.bind(i,3845))))}}function Ee(e,t){var r=(0,pe.D)(t),n=e.params||e;n.hostname=r.hostname,n.port=r.port,n.protocol=r.protocol,n.host=r.hostname+":"+r.port,n.pathname=r.pathname,e.parsedOrigin=r,e.sameOrigin=r.sameOrigin}const Ae={},Se=["pushState","replaceState"];function _e(e){const t=function(e){return(e||te.ee).get("history")}(e);return!y.RI||Ae[t.debugId]++||(Ae[t.debugId]=1,(0,re.YM)(t).inPlace(window.history,Se,"-")),t}var Ne=i(3738);function Oe(e){p(u.BL,(function(t=Date.now()){const r=t-y.WN;r<0&&(0,l.R)(62,t),(0,s.p)(h.XG,[u.BL,{time:r}],void 0,n.K7.metrics,e.ee),e.addToTrace({name:u.BL,start:t,origin:"nr"}),(0,s.p)(u.Pl+u.hG,[r,u.BL],void 0,n.K7.genericEvents,e.ee)}),e)}const{He:Ie,bD:Pe,d3:je,Kp:ke,TZ:Ce,Lc:Le,uP:Me,Rz:He}=Ne;class De extends E{static featureName=Ce;constructor(e){var t;super(e,Ce),t=e,p(u.U2,(function(e){if(!(e&&"object"==typeof e&&e.name&&e.start))return;const r={n:e.name,s:e.start-y.WN,e:(e.end||e.start)-y.WN,o:e.origin||"",t:"api"};r.s<0||r.e<0||r.e<r.s?(0,l.R)(61,{start:r.s,end:r.e}):(0,s.p)("bstApi",[r],void 0,n.K7.sessionTrace,t.ee)}),t),Oe(e);if(!(0,R.V)(e.init))return void this.deregisterDrain();const r=this.ee;let o;_e(r),this.eventsEE=(0,ee.u)(r),this.eventsEE.on(Me,(function(e,t){this.bstStart=(0,c.t)()})),this.eventsEE.on(Le,(function(e,t){(0,s.p)("bst",[e[0],t,this.bstStart,(0,c.t)()],void 0,n.K7.sessionTrace,r)})),r.on(He+je,(function(e){this.time=(0,c.t)(),this.startPath=location.pathname+location.hash})),r.on(He+ke,(function(e){(0,s.p)("bstHist",[location.pathname+location.hash,this.startPath,this.time],void 0,n.K7.sessionTrace,r)}));try{o=new PerformanceObserver((e=>{const t=e.getEntries();(0,s.p)(Ie,[t],void 0,n.K7.sessionTrace,r)})),o.observe({type:Pe,buffered:!0})}catch(e){}this.importAggregator(e,(()=>i.e(478).then(i.bind(i,6974))),{resourceObserver:o})}}var Ke=i(6344);class Ue extends E{static featureName=Ke.TZ;#n;recorder;constructor(e){var t;let r;super(e,Ke.TZ),t=e,p(u.CH,(function(){(0,s.p)(u.CH,[],void 0,n.K7.sessionReplay,t.ee)}),t),function(e){p(u.Tb,(function(){(0,s.p)(u.Tb,[],void 0,n.K7.sessionReplay,e.ee)}),e)}(e);try{r=JSON.parse(localStorage.getItem("".concat(S.H3,"_").concat(S.uh)))}catch(e){}(0,w.SR)(e.init)&&this.ee.on(Ke.G4.RECORD,(()=>this.#i())),this.#o(r)&&this.importRecorder().then((e=>{e.startRecording(Ke.Qb.PRELOAD,r?.sessionReplayMode)})),this.importAggregator(this.agentRef,(()=>i.e(478).then(i.bind(i,6167))),this),this.ee.on("err",(e=>{this.blocked||this.agentRef.runtime.isRecording&&(this.errorNoticed=!0,(0,s.p)(Ke.G4.ERROR_DURING_REPLAY,[e],void 0,this.featureName,this.ee))}))}#o(e){return e&&(e.sessionReplayMode===S.g.FULL||e.sessionReplayMode===S.g.ERROR)||(0,w.Aw)(this.agentRef.init)}importRecorder(){return this.recorder?Promise.resolve(this.recorder):(this.#n??=Promise.all([i.e(478),i.e(249)]).then(i.bind(i,8589)).then((({Recorder:e})=>(this.recorder=new e(this),this.recorder))).catch((e=>{throw this.ee.emit("internal-error",[e]),this.blocked=!0,e})),this.#n)}#i(){this.blocked||(this.featAggregate?this.featAggregate.mode!==S.g.FULL&&this.featAggregate.initializeRecording(S.g.FULL,!0,Ke.Qb.API):this.importRecorder().then((()=>{this.recorder.startRecording(Ke.Qb.API,S.g.FULL)})))}}var Fe=i(3962);function We(e){const t=e.ee.get("tracer");function r(){}p(u.dT,(function(e){return(new r).get("object"==typeof e?e:{})}),e);const i=r.prototype={createTracer:function(r,i){var o={},a=this,d="function"==typeof i;return(0,s.p)(h.xV,["API/createTracer/called"],void 0,n.K7.metrics,e.ee),e.runSoftNavOverSpa||(0,s.p)(u.hw+"tracer",[(0,c.t)(),r,o],a,n.K7.spa,e.ee),function(){if(t.emit((d?"":"no-")+"fn-start",[(0,c.t)(),a,d],o),d)try{return i.apply(this,arguments)}catch(e){const r="string"==typeof e?new Error(e):e;throw t.emit("fn-err",[arguments,this,r],o),r}finally{t.emit("fn-end",[(0,c.t)()],o)}}}};["actionText","setName","setAttribute","save","ignore","onEnd","getContext","end","get"].forEach((t=>{p.apply(this,[t,function(){return(0,s.p)(u.hw+t,[(0,c.t)(),...arguments],this,e.runSoftNavOverSpa?n.K7.softNav:n.K7.spa,e.ee),this},e,i])})),p(u.PA,(function(){e.runSoftNavOverSpa?(0,s.p)(u.hw+"routeName",[performance.now(),...arguments],void 0,n.K7.softNav,e.ee):(0,s.p)(u.Pl+"routeName",[(0,c.t)(),...arguments],this,n.K7.spa,e.ee)}),e)}class Be extends E{static featureName=Fe.TZ;constructor(e){if(super(e,Fe.TZ),We(e),!y.RI||!(0,N.dV)().o.MO)return;const t=_e(this.ee);try{this.removeOnAbort=new AbortController}catch(e){}Fe.tC.forEach((e=>{(0,I.sp)(e,(e=>{a(e)}),!0,this.removeOnAbort?.signal)}));const r=()=>(0,s.p)("newURL",[(0,c.t)(),""+window.location],void 0,this.featureName,this.ee);t.on("pushState-end",r),t.on("replaceState-end",r),(0,I.sp)(Fe.OV,(e=>{a(e),(0,s.p)("newURL",[e.timeStamp,""+window.location],void 0,this.featureName,this.ee)}),!0,this.removeOnAbort?.signal);let n=!1;const o=new((0,N.dV)().o.MO)(((e,t)=>{n||(n=!0,requestAnimationFrame((()=>{(0,s.p)("newDom",[(0,c.t)()],void 0,this.featureName,this.ee),n=!1})))})),a=(0,x.s)((e=>{(0,s.p)("newUIEvent",[e],void 0,this.featureName,this.ee),o.observe(document.body,{attributes:!0,childList:!0,subtree:!0,characterData:!0})}),100,{leading:!0});this.abortHandler=function(){this.removeOnAbort?.abort(),o.disconnect(),this.abortHandler=void 0},this.importAggregator(e,(()=>i.e(478).then(i.bind(i,4393))),{domObserver:o})}}var Ge=i(7378);const Ve={},ze=["appendChild","insertBefore","replaceChild"];function Ze(e){const t=function(e){return(e||te.ee).get("jsonp")}(e);if(!y.RI||Ve[t.debugId])return t;Ve[t.debugId]=!0;var r=(0,re.YM)(t),n=/[?&](?:callback|cb)=([^&#]+)/,i=/(.*)\.([^.]+)/,o=/^(\w+)(\.|$)(.*)$/;function a(e,t){if(!e)return t;const r=e.match(o),n=r[1];return a(r[3],t[n])}return r.inPlace(Node.prototype,ze,"dom-"),t.on("dom-start",(function(e){!function(e){if(!e||"string"!=typeof e.nodeName||"script"!==e.nodeName.toLowerCase())return;if("function"!=typeof e.addEventListener)return;var o=(s=e.src,c=s.match(n),c?c[1]:null);var s,c;if(!o)return;var u=function(e){var t=e.match(i);if(t&&t.length>=3)return{key:t[2],parent:a(t[1],window)};return{key:e,parent:window}}(o);if("function"!=typeof u.parent[u.key])return;var d={};function l(){t.emit("jsonp-end",[],d),e.removeEventListener("load",l,(0,I.jT)(!1)),e.removeEventListener("error",f,(0,I.jT)(!1))}function f(){t.emit("jsonp-error",[],d),t.emit("jsonp-end",[],d),e.removeEventListener("load",l,(0,I.jT)(!1)),e.removeEventListener("error",f,(0,I.jT)(!1))}r.inPlace(u.parent,[u.key],"cb-",d),e.addEventListener("load",l,(0,I.jT)(!1)),e.addEventListener("error",f,(0,I.jT)(!1)),t.emit("new-jsonp",[e.src],d)}(e[0])})),t}const qe={};function Xe(e){const t=function(e){return(e||te.ee).get("promise")}(e);if(qe[t.debugId])return t;qe[t.debugId]=!0;var r=t.context,n=(0,re.YM)(t),i=y.gm.Promise;return i&&function(){function e(r){var o=t.context(),a=n(r,"executor-",o,null,!1);const s=Reflect.construct(i,[a],e);return t.context(s).getCtx=function(){return o},s}y.gm.Promise=e,Object.defineProperty(e,"name",{value:"Promise"}),e.toString=function(){return i.toString()},Object.setPrototypeOf(e,i),["all","race"].forEach((function(r){const n=i[r];e[r]=function(e){let i=!1;[...e||[]].forEach((e=>{this.resolve(e).then(a("all"===r),a(!1))}));const o=n.apply(this,arguments);return o;function a(e){return function(){t.emit("propagate",[null,!i],o,!1,!1),i=i||!e}}}})),["resolve","reject"].forEach((function(r){const n=i[r];e[r]=function(e){const r=n.apply(this,arguments);return e!==r&&t.emit("propagate",[e,!0],r,!1,!1),r}})),e.prototype=i.prototype;const o=i.prototype.then;i.prototype.then=function(...e){var i=this,a=r(i);a.promise=i,e[0]=n(e[0],"cb-",a,null,!1),e[1]=n(e[1],"cb-",a,null,!1);const s=o.apply(this,e);return a.nextPromise=s,t.emit("propagate",[i,!0],s,!1,!1),s},i.prototype.then[re.Jt]=o,t.on("executor-start",(function(e){e[0]=n(e[0],"resolve-",this,null,!1),e[1]=n(e[1],"resolve-",this,null,!1)})),t.on("executor-err",(function(e,t,r){e[1](r)})),t.on("cb-end",(function(e,r,n){t.emit("propagate",[n,!0],this.nextPromise,!1,!1)})),t.on("propagate",(function(e,r,n){this.getCtx&&!r||(this.getCtx=function(){if(e instanceof Promise)var r=t.context(e);return r&&r.getCtx?r.getCtx():this})}))}(),t}const Ye={},$e="setTimeout",Qe="setInterval",Je="clearTimeout",et="-start",tt=[$e,"setImmediate",Qe,Je,"clearImmediate"];function rt(e){const t=function(e){return(e||te.ee).get("timer")}(e);if(Ye[t.debugId]++)return t;Ye[t.debugId]=1;var r=(0,re.YM)(t);return r.inPlace(y.gm,tt.slice(0,2),$e+"-"),r.inPlace(y.gm,tt.slice(2,3),Qe+"-"),r.inPlace(y.gm,tt.slice(3),Je+"-"),t.on(Qe+et,(function(e,t,n){e[0]=r(e[0],"fn-",null,n)})),t.on($e+et,(function(e,t,n){this.method=n,this.timerDuration=isNaN(e[1])?0:+e[1],e[0]=r(e[0],"fn-",this,n)})),t}const nt={};function it(e){const t=function(e){return(e||te.ee).get("mutation")}(e);if(!y.RI||nt[t.debugId])return t;nt[t.debugId]=!0;var r=(0,re.YM)(t),n=y.gm.MutationObserver;return n&&(window.MutationObserver=function(e){return this instanceof n?new n(r(e,"fn-")):n.apply(this,arguments)},MutationObserver.prototype=n.prototype),t}const{TZ:ot,d3:at,Kp:st,$p:ct,wW:ut,e5:dt,tH:lt,uP:ft,rw:ht,Lc:pt}=Ge;class gt extends E{static featureName=ot;constructor(e){if(super(e,ot),We(e),!y.RI)return;try{this.removeOnAbort=new AbortController}catch(e){}let t,r=0;const n=this.ee.get("tracer"),o=Ze(this.ee),a=Xe(this.ee),u=rt(this.ee),d=oe(this.ee),l=this.ee.get("events"),f=he(this.ee),h=_e(this.ee),p=it(this.ee);function g(e,t){h.emit("newURL",[""+window.location,t])}function m(){r++,t=window.location.hash,this[ft]=(0,c.t)()}function v(){r--,window.location.hash!==t&&g(0,!0);var e=(0,c.t)();this[dt]=~~this[dt]+e-this[ft],this[pt]=e}function b(e,t){e.on(t,(function(){this[t]=(0,c.t)()}))}this.ee.on(ft,m),a.on(ht,m),o.on(ht,m),this.ee.on(pt,v),a.on(ut,v),o.on(ut,v),this.ee.on("fn-err",((...t)=>{t[2]?.__newrelic?.[e.agentIdentifier]||(0,s.p)("function-err",[...t],void 0,this.featureName,this.ee)})),this.ee.buffer([ft,pt,"xhr-resolved"],this.featureName),l.buffer([ft],this.featureName),u.buffer(["setTimeout"+st,"clearTimeout"+at,ft],this.featureName),d.buffer([ft,"new-xhr","send-xhr"+at],this.featureName),f.buffer([lt+at,lt+"-done",lt+ct+at,lt+ct+st],this.featureName),h.buffer(["newURL"],this.featureName),p.buffer([ft],this.featureName),a.buffer(["propagate",ht,ut,"executor-err","resolve"+at],this.featureName),n.buffer([ft,"no-"+ft],this.featureName),o.buffer(["new-jsonp","cb-start","jsonp-error","jsonp-end"],this.featureName),b(f,lt+at),b(f,lt+"-done"),b(o,"new-jsonp"),b(o,"jsonp-end"),b(o,"cb-start"),h.on("pushState-end",g),h.on("replaceState-end",g),window.addEventListener("hashchange",g,(0,I.jT)(!0,this.removeOnAbort?.signal)),window.addEventListener("load",g,(0,I.jT)(!0,this.removeOnAbort?.signal)),window.addEventListener("popstate",(function(){g(0,r>1)}),(0,I.jT)(!0,this.removeOnAbort?.signal)),this.abortHandler=this.#r,this.importAggregator(e,(()=>i.e(478).then(i.bind(i,5592))))}#r(){this.removeOnAbort?.abort(),this.abortHandler=void 0}}var mt=i(3333);class vt extends E{static featureName=mt.TZ;constructor(e){super(e,mt.TZ);const t=[e.init.page_action.enabled,e.init.performance.capture_marks,e.init.performance.capture_measures,e.init.user_actions.enabled,e.init.performance.resources.enabled];var r;if(r=e,p(u.hG,((e,t)=>z(e,t,r)),r),function(e){p(u.fF,(function(){(0,s.p)(u.Pl+u.fF,[(0,c.t)(),...arguments],void 0,n.K7.genericEvents,e.ee)}),e)}(e),Oe(e),Z(e),function(e){p(u.V1,(function(t,r){const i=(0,c.t)(),{start:o,end:a,customAttributes:d}=r||{},f={customAttributes:d||{}};if("object"!=typeof f.customAttributes||"string"!=typeof t||0===t.length)return void(0,l.R)(57);const h=(e,t)=>null==e?t:"number"==typeof e?e:e instanceof PerformanceMark?e.startTime:Number.NaN;if(f.start=h(o,0),f.end=h(a,i),Number.isNaN(f.start)||Number.isNaN(f.end))(0,l.R)(57);else{if(f.duration=f.end-f.start,!(f.duration<0))return(0,s.p)(u.Pl+u.V1,[f,t],void 0,n.K7.genericEvents,e.ee),f;(0,l.R)(58)}}),e)}(e),y.RI&&(e.init.user_actions.enabled&&(mt.Zp.forEach((e=>(0,I.sp)(e,(e=>(0,s.p)("ua",[e],void 0,this.featureName,this.ee)),!0))),mt.qN.forEach((e=>{const t=(0,x.s)((e=>{(0,s.p)("ua",[e],void 0,this.featureName,this.ee)}),500,{leading:!0});(0,I.sp)(e,t)}))),e.init.performance.resources.enabled&&y.gm.PerformanceObserver?.supportedEntryTypes.includes("resource"))){new PerformanceObserver((e=>{e.getEntries().forEach((e=>{(0,s.p)("browserPerformance.resource",[e],void 0,this.featureName,this.ee)}))})).observe({type:"resource",buffered:!0})}t.some((e=>e))?this.importAggregator(e,(()=>i.e(478).then(i.bind(i,8019)))):this.deregisterDrain()}}var bt=i(2646);const yt=new Map;function wt(e,t,r,n){if("object"!=typeof t||!t||"string"!=typeof r||!r||"function"!=typeof t[r])return(0,l.R)(29);const i=function(e){return(e||te.ee).get("logger")}(e),o=(0,re.YM)(i),a=new bt.y(te.P);a.level=n.level,a.customAttributes=n.customAttributes;const s=t[r]?.[re.Jt]||t[r];return yt.set(s,a),o.inPlace(t,[r],"wrap-logger-",(()=>yt.get(s))),i}var Rt=i(1910);class xt extends E{static featureName=B.TZ;constructor(e){var t;super(e,B.TZ),t=e,p(u.$9,((e,r)=>V(e,r,t)),t),function(e){p(u.Wb,((t,r,{customAttributes:n={},level:i=B.p_.INFO}={})=>{wt(e.ee,t,r,{customAttributes:n,level:i})}),e)}(e),Z(e);const r=this.ee;["log","error","warn","info","debug","trace"].forEach((e=>{(0,Rt.i)(y.gm.console[e]),wt(r,y.gm.console,e,{level:"log"===e?"info":e})})),this.ee.on("wrap-logger-end",(function([e]){const{level:t,customAttributes:n}=this;(0,G.R)(r,e,n,t)})),this.importAggregator(e,(()=>i.e(478).then(i.bind(i,5288))))}}new class extends r{constructor(e){var t;(super(),y.gm)?(this.features={},(0,N.bQ)(this.agentIdentifier,this),this.desiredFeatures=new Set(e.features||[]),this.desiredFeatures.add(_),this.runSoftNavOverSpa=[...this.desiredFeatures].some((e=>e.featureName===n.K7.softNav)),(0,a.j)(this,e,e.loaderType||"agent"),t=this,p(u.cD,(function(e,r,n=!1){if("string"==typeof e){if(["string","number","boolean"].includes(typeof r)||null===r)return g(t,e,r,u.cD,n);(0,l.R)(40,typeof r)}else(0,l.R)(39,typeof e)}),t),function(e){p(u.Dl,(function(t){if("string"==typeof t||null===t)return g(e,"enduser.id",t,u.Dl,!0);(0,l.R)(41,typeof t)}),e)}(this),function(e){p(u.nb,(function(t){if("string"==typeof t||null===t)return g(e,"application.version",t,u.nb,!1);(0,l.R)(42,typeof t)}),e)}(this),function(e){p(u.d3,(function(){e.ee.emit("manual-start-all")}),e)}(this),this.run()):(0,l.R)(21)}get config(){return{info:this.info,init:this.init,loader_config:this.loader_config,runtime:this.runtime}}get api(){return this}run(){try{const e=function(e){const t={};return o.forEach((r=>{t[r]=!!e[r]?.enabled})),t}(this.init),t=[...this.desiredFeatures];t.sort(((e,t)=>n.P3[e.featureName]-n.P3[t.featureName])),t.forEach((t=>{if(!e[t.featureName]&&t.featureName!==n.K7.pageViewEvent)return;if(this.runSoftNavOverSpa&&t.featureName===n.K7.spa)return;if(!this.runSoftNavOverSpa&&t.featureName===n.K7.softNav)return;const r=function(e){switch(e){case n.K7.ajax:return[n.K7.jserrors];case n.K7.sessionTrace:return[n.K7.ajax,n.K7.pageViewEvent];case n.K7.sessionReplay:return[n.K7.sessionTrace];case n.K7.pageViewTiming:return[n.K7.pageViewEvent];default:return[]}}(t.featureName).filter((e=>!(e in this.features)));r.length>0&&(0,l.R)(36,{targetFeature:t.featureName,missingDependencies:r}),this.features[t.featureName]=new t(this)}))}catch(e){(0,l.R)(22,e);for(const e in this.features)this.features[e].abortHandler?.();const t=(0,N.Zm)();delete t.initializedAgents[this.agentIdentifier]?.features,delete this.sharedAggregator;return t.ee.get(this.agentIdentifier).abort(),!1}}}({features:[Te,_,j,De,Ue,k,q,vt,xt,Be,gt],loaderType:"spa"})})()})();</script>
<link rel="icon" type="image/png" sizes="16x16" href="https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantFavicon-Frontiers.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantFavicon-Frontiers.png">
<meta name="apple-mobile-web-app-title" content="Frontiers | Articles">
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full">
<meta property="description" name="description" content="Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional s...">
<meta property="og:title" name="title" content="Frontiers | Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding">
<meta property="og:description" name="description" content="Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional s...">
<meta name="keywords" content="Sparse methods,structured sparsity,Model selection,reproducibility,predictive models">
<meta property="og:site_name" name="site_name" content="Frontiers">
<meta property="og:image" name="image" content="https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg">
<meta property="og:type" name="type" content="article">
<meta property="og:url" name="url" content="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_volume" content="11">
<meta name="citation_journal_title" content="Frontiers in Neuroscience">
<meta name="citation_publisher" content="Frontiers">
<meta name="citation_journal_abbrev" content="Front. Neurosci.">
<meta name="citation_issn" content="1662-453X">
<meta name="citation_doi" content="10.3389/fnins.2017.00062">
<meta name="citation_firstpage" content="209792">
<meta name="citation_language" content="English">
<meta name="citation_title" content="Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding">
<meta name="citation_keywords" content="Sparse methods; structured sparsity; Model selection; reproducibility; predictive models">
<meta name="citation_abstract" content="Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional spatial and temporal constraints in the predictive model and carry the promise of being more interpretable than non-structured sparse methods, such as LASSO or Elastic Net methods. However, although sparsity has often been advocated as leading to more interpretable models it can also lead to unstable models under subsampling or slight changes of the experimental conditions. In the present work we investigated the impact of using stability/reproducibility as an additional model selection criterion on several different sparse (and structured sparse) methods that have been recently applied for fMRI brain decoding. We compared three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions; (iii) classification accuracy and correlation between the solutions. The methods we considered include LASSO, Elastic Net, Total Variation, sparse Total Variation, Laplacian and Graph Laplacian Elastic Net (GraphNET).Our results show that explicitly accounting for stability/reproducibility during the model optimisation can mitigate some of the instability inherent in sparse methods. In particular, using accuracy and overlap between the solutions as a joint optimisation criterion can lead to solutions that are more similar in terms of accuracy, sparsity levels and coefficient maps even when different sparsity methods are considered.">
<meta name="citation_article_type" content="Original Research">
<meta name="citation_pdf_url" content="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/pdf">
<meta name="citation_xml_url" content="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/xml">
<meta name="citation_fulltext_world_readable" content="yes">
<meta name="citation_online_date" content="2017/01/27">
<meta name="citation_publication_date" content="2017/02/17">
<meta name="citation_author" content="Baldassarre, Luca ">
<meta name="citation_author_institution" content="Laboratory for Information and Inference Systems, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland">
<meta name="citation_author" content="Pontil, Massimiliano ">
<meta name="citation_author_institution" content="Istituto Italiano di Tecnologia, Genoa, Italy">
<meta name="citation_author" content="Mourão-Miranda, Janaina ">
<meta name="citation_author_institution" content="Department of Computer Science, University College London, London, UK">
<meta name="dc.identifier" content="doi:10.3389/fnins.2017.00062">
<script type="application/ld+json">{"@context":"https://schema.org","@type":"ScholarlyArticle","headline":"Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding","author":[{"@type":"Person","name":"Luca Baldassarre","affiliation":["Laboratory for Information and Inference Systems, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland"]},{"@type":"Person","name":"Massimiliano Pontil","affiliation":["Istituto Italiano di Tecnologia, Genoa, Italy","Department of Computer Science, University College London, London, UK"]},{"@type":"Person","name":"Janaina Mourão-Miranda","affiliation":["Department of Computer Science, University College London, London, UK","Max Planck University College London Centre for Computational Psychiatry and Ageing Research, University College London, London, UK"]}],"datePublished":"2017-02-17","dateModified":"2025-10-05","publisher":{"@type":"Organization","name":"Frontiers"},"isPartOf":{"@type":"PublicationIssue","datePublished":"2017","isPartOf":{"@type":"PublicationVolume","volumeNumber":"11","isPartOf":{"@type":"Periodical","name":"Frontiers in Neuroscience"}}},"citation":["https://doi.org/10.3389/fnins.2017.00062"],"inLanguage":"en"}</script>
<script type="module" src="/ap-2024/_nuxt/BXwRzDm6.js" crossorigin></script>
<script id="unhead:payload" type="application/json">{"title":"Frontiers | Articles"}</script></head><body  class="body--v3"><div id="__nuxt"><!--[--><!----><div theme="purple"><nav class="Ibar"><div class="Ibar__main"><div class="Ibar__wrapper"><button class="Ibar__burger" aria-label="Open Menu" data-event="iBar-btn-openMenu"></button><div class="Ibar__logo"><a href="//www.frontiersin.org/" aria-label="Frontiershome" data-event="iBar-a-home" class="Ibar__logo__link"><svg class="Ibar__logo__svg" viewBox="0 0 2811 590" fill="none" xmlns="http://www.w3.org/2000/svg"><path class="Ibar__logo__text" d="M633.872 234.191h-42.674v-57.246h42.674c0-19.776 2.082-35.389 5.204-48.92 4.164-13.53 9.368-23.939 17.695-31.225 8.326-8.326 18.735-13.53 32.266-16.653 13.531-3.123 29.143-5.204 47.878-5.204h21.858c7.286 0 14.572 1.04 21.857 1.04v62.451c-8.326-1.041-16.653-2.082-23.939-2.082-10.408 0-17.694 1.041-23.939 4.164-6.245 3.122-9.368 10.408-9.368 22.898v13.531h53.083v57.246h-53.083v213.372h-89.512V234.191zM794.161 176.945h86.39v47.879h1.041c6.245-17.694 16.653-30.185 31.225-39.552 14.572-9.368 31.225-13.531 49.96-13.531h10.409c3.122 0 7.286 1.041 10.408 2.082v81.185c-6.245-2.082-11.449-3.122-16.653-4.163-5.204-1.041-11.449-1.041-16.654-1.041-11.449 0-20.816 2.082-29.143 5.204-8.327 3.123-15.613 8.327-20.817 14.572-5.204 6.245-10.408 12.49-12.49 20.817-3.123 8.326-4.163 15.612-4.163 23.939v133.228h-88.472V176.945h-1.041zM989.84 312.254c0-19.776 3.122-39.552 10.41-56.205 7.28-17.695 16.65-32.266 29.14-45.797 12.49-13.531 27.06-22.899 44.76-30.185 17.69-7.285 36.43-11.449 57.24-11.449 20.82 0 39.56 4.164 57.25 11.449 17.69 7.286 32.27 17.695 45.8 30.185 12.49 12.49 22.9 28.102 29.14 45.797 7.29 17.694 10.41 36.429 10.41 56.205 0 20.817-3.12 39.552-10.41 57.246-7.29 17.695-16.65 32.266-29.14 44.756-12.49 12.49-28.11 22.899-45.8 30.185-17.69 7.286-36.43 11.449-57.25 11.449-20.81 0-40.59-4.163-57.24-11.449-17.7-7.286-32.27-17.695-44.76-30.185-12.49-12.49-21.86-28.102-29.14-44.756-7.288-17.694-10.41-36.429-10.41-57.246zm88.47 0c0 8.327 1.04 17.694 3.12 26.021 2.09 9.368 5.21 16.653 9.37 23.939 4.16 7.286 9.37 13.531 16.65 17.695 7.29 4.163 15.62 7.285 26.03 7.285 10.4 0 18.73-2.081 26.02-7.285 7.28-4.164 12.49-10.409 16.65-17.695 4.16-7.286 7.29-15.612 9.37-23.939 2.08-9.368 3.12-17.694 3.12-26.021 0-8.327-1.04-17.694-3.12-26.021-2.08-9.368-5.21-16.653-9.37-23.939-4.16-7.286-9.37-13.531-16.65-17.695-7.29-5.204-15.62-7.285-26.02-7.285-10.41 0-18.74 2.081-26.03 7.285-7.28 5.205-12.49 10.409-16.65 17.695-4.16 7.286-7.28 15.612-9.37 23.939-2.08 9.368-3.12 17.694-3.12 26.021zM1306.25 176.945h86.39v37.47h1.04c4.17-7.286 9.37-13.531 15.62-18.735 6.24-5.204 13.53-10.408 20.81-14.572 7.29-4.163 15.62-7.286 23.94-9.367 8.33-2.082 16.66-3.123 24.98-3.123 22.9 0 40.6 4.164 53.09 11.449 13.53 7.286 22.89 16.654 29.14 27.062 6.24 10.409 10.41 21.858 12.49 34.348 2.08 12.49 2.08 22.898 2.08 33.307v172.779h-88.47V316.417v-27.061c0-9.368-1.04-16.654-4.16-23.94-3.13-7.286-7.29-12.49-13.53-16.653-6.25-4.164-15.62-6.245-27.07-6.245-8.32 0-15.61 2.081-21.85 5.204-6.25 3.122-11.45 7.286-14.58 13.531-4.16 5.204-6.24 11.449-8.32 18.735s-3.12 14.572-3.12 21.858v145.717h-88.48V176.945zM1780.88 234.19h-55.17v122.819c0 10.408 3.12 17.694 8.33 20.817 6.24 3.122 13.53 5.204 22.9 5.204 4.16 0 7.28 0 11.45-1.041h11.45v65.573c-8.33 0-15.62 1.041-23.94 2.082-8.33 1.04-16.66 1.041-23.94 1.041-18.74 0-34.35-2.082-46.84-5.205-12.49-3.122-21.86-8.326-29.14-15.612-7.29-7.286-12.49-16.654-14.58-29.144-3.12-12.49-4.16-27.062-4.16-45.797V234.19h-44.76v-57.246h44.76V94.717h88.47v82.227h55.17v57.246zM1902.66 143.639h-88.48V75.984h88.48v67.655zm-89.52 33.307h88.48v270.618h-88.48V176.946zM2024.43 334.111c1.04 18.735 6.25 33.307 16.66 44.756 10.4 11.449 24.98 16.653 43.71 16.653 10.41 0 20.82-2.081 30.19-7.286 9.36-5.204 16.65-12.49 20.81-22.898h83.27c-4.16 15.613-10.41 29.144-19.78 40.593-9.36 11.449-19.77 20.817-31.22 28.102-12.49 7.286-24.98 12.491-39.55 16.654-14.57 3.122-29.15 5.204-43.72 5.204-21.86 0-41.63-3.122-60.37-9.367-18.73-6.246-34.34-15.613-46.83-28.103-12.49-12.49-22.9-27.062-30.19-45.797-7.28-17.694-10.41-38.511-10.41-60.369 0-20.817 4.17-39.552 11.45-57.246 7.29-17.694 17.7-32.266 31.23-44.756 13.53-12.49 29.14-21.858 46.83-29.144 17.7-7.286 36.43-10.408 56.21-10.408 23.94 0 45.8 4.163 63.49 12.49 17.7 8.327 33.31 19.776 44.76 35.389 11.45 15.612 20.81 32.266 26.02 52.042 5.2 19.776 8.33 41.633 7.28 64.532h-199.84v-1.041zm110.33-49.961c-1.04-15.612-6.24-28.102-15.61-39.551-9.37-10.409-21.86-16.654-37.47-16.654s-28.1 5.204-38.51 15.613c-10.41 10.408-16.66 23.939-18.74 40.592h110.33zM2254.46 176.945h86.39v47.879h1.04c6.25-17.694 16.65-30.185 31.23-39.552 14.57-9.368 31.22-13.531 49.96-13.531h10.4c3.13 0 7.29 1.041 10.41 2.082v81.185c-6.24-2.082-11.45-3.122-16.65-4.163-5.21-1.041-11.45-1.041-16.65-1.041-11.45 0-20.82 2.082-29.15 5.204-8.32 3.123-15.61 8.327-20.81 14.572-6.25 6.245-10.41 12.49-12.49 20.817-3.13 8.326-4.17 15.612-4.17 23.939v133.228h-88.47V176.945h-1.04zM2534.45 359.091c0 7.286 1.04 12.49 4.16 17.694 3.12 5.204 6.24 9.368 10.41 12.49 4.16 3.123 9.36 5.204 14.57 7.286 6.24 2.082 11.45 2.082 17.69 2.082 4.17 0 8.33 0 13.53-2.082 5.21-1.041 9.37-3.123 13.53-5.204 4.17-2.082 7.29-5.204 10.41-9.368 3.13-4.163 4.17-8.327 4.17-13.531 0-5.204-2.09-9.367-5.21-12.49-3.12-3.122-7.28-6.245-11.45-8.327-4.16-2.081-9.36-4.163-14.57-5.204-5.2-1.041-9.37-2.081-13.53-3.122-13.53-3.123-28.1-6.245-42.67-9.368-14.58-3.122-28.11-7.286-40.6-12.49-12.49-6.245-22.9-13.531-30.18-23.939-8.33-10.409-11.45-23.94-11.45-42.675 0-16.653 4.16-30.184 11.45-40.592 8.33-10.409 17.69-18.736 30.18-24.981 12.49-6.245 26.02-10.408 40.6-13.53 14.57-3.123 28.1-4.164 41.63-4.164 14.57 0 29.14 1.041 43.71 4.164 14.58 2.081 27.07 7.285 39.56 13.53 12.49 6.245 21.85 15.613 29.14 27.062 7.29 11.45 11.45 26.021 12.49 43.716h-82.23c0-10.409-4.16-18.736-11.45-23.94-7.28-4.163-16.65-7.286-28.1-7.286-4.16 0-8.32 0-12.49 1.041-4.16 1.041-8.32 1.041-12.49 2.082-4.16 1.041-7.28 3.122-9.37 6.245-2.08 3.122-4.16 6.245-4.16 11.449 0 6.245 3.12 11.449 10.41 15.613 6.24 4.163 14.57 7.286 24.98 10.408 10.41 2.082 20.82 5.204 32.27 7.286 11.44 2.082 22.89 4.163 33.3 6.245 13.53 3.123 24.98 7.286 33.31 13.531 9.37 6.245 15.61 12.49 20.82 19.776 5.2 7.286 9.36 14.572 11.45 21.858 2.08 7.285 3.12 13.53 3.12 19.776 0 17.694-4.17 33.306-11.45 45.796-8.33 12.491-17.7 21.858-30.19 30.185-12.49 7.286-26.02 12.49-41.63 16.653-15.61 3.123-31.22 5.204-45.8 5.204-15.61 0-32.26-1.04-47.87-4.163-15.62-3.122-29.15-8.327-41.64-15.612a83.855 83.855 0 01-30.18-30.185c-8.33-12.49-12.49-28.102-12.49-46.838h84.31v-2.081z" fill="#FFFFFF"></path><path d="M0 481.911V281.028l187.351-58.287v200.882L0 481.911z" fill="#8BC53F"></path><path d="M187.351 423.623V222.741l126.983 87.431v200.882l-126.983-87.431z" fill="#EBD417"></path><path d="M126.982 569.341L0 481.911l187.351-58.287 126.983 87.43-187.352 58.287z" fill="#034EA1"></path><path d="M183.188 212.331l51.001-116.574 65.573 155.085-51.001 116.574-65.573-155.085z" fill="#712E74"></path><path d="M248.761 367.415l51.001-116.574 171.739-28.102-49.96 115.533-172.78 29.143z" fill="#009FD1"></path><path d="M299.762 250.842L234.189 95.757l171.739-28.103 65.573 155.085-171.739 28.103z" fill="#F6921E"></path><path d="M187.352 222.741L59.328 198.802 44.757 71.819 172.78 95.76l14.572 126.982z" fill="#DA2128"></path><path d="M172.78 95.758L44.757 71.818l70.777-70.776 128.023 23.94-70.777 70.776z" fill="#25BCBD"></path><path d="M258.129 153.005l-70.777 69.736-14.571-126.982 70.777-70.778 14.571 128.024z" fill="#00844A"></path></svg></a></div><a href="//www.frontiersin.org/journals/neuroscience" class="Ibar__journalName" data-event="iBar-a-journalHome"><div class="Ibar__journalName__container" logoclass="Ibar__logo--mixed"><div class="Ibar__journal__maskLogo" style="display:none;"><img class="Ibar__journal__logo" src></div><div class="Ibar__journalName"><span>Frontiers in</span><span> Neuroscience</span></div></div></a><div class="Ibar__dropdown--aboutUs" parent-data-event="iBar"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> About us</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">About us</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><div class="Ibar__dropdown__about"><!--[--><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Who we are</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/mission" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Mission and values</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/history" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">History</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/leadership" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Leadership</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/awards" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Awards</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Impact and progress</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/impact" target="_self" data-event="iBar-aboutUs_1-a_impactAndProgress">Frontiers&#39; impact</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/annual-reports" target="_self" data-event="iBar-aboutUs_1-a_impactAndProgress">Our annual reports</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Publishing model</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/how-we-publish" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">How we publish</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/open-access" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Open access</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/peer-review" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Peer review</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/research-integrity" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Research integrity</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/research-topics" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Research Topics</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/fair-data-management" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">FAIR² Data Management</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/fee-policy" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Fee policy</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Services</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://publishingpartnerships.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_3-a_services">Societies</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/open-access-agreements/consortia" target="_self" data-event="iBar-aboutUs_3-a_services">National consortia</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/open-access-agreements" target="_self" data-event="iBar-aboutUs_3-a_services">Institutional partnerships</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/collaborators" target="_self" data-event="iBar-aboutUs_3-a_services">Collaborators</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">More from Frontiers</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://forum.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Frontiers Forum</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/frontiers-planet-prize" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Frontiers Planet Prize</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://pressoffice.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Press office</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/sustainability" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Sustainability</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://careers.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Career opportunities</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/contact" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Contact us</a></li><!--]--></ul><!--]--></div><!--]--></div></div></div><!--[--><a class="Ibar__link" href="https://www.frontiersin.org/journals" data-event="iBar-a-allJournals">All journals</a><a class="Ibar__link" href="https://www.frontiersin.org/articles" data-event="iBar-a-allArticles">All articles</a><!--]--><a class="Ibar__button Ibar__submit" href="https://www.frontiersin.org/submission/submit?domainid=1&amp;fieldid=55&amp;specialtyid=0&amp;entitytype=2&amp;entityid=1" data-event="iBar-a-submit">Submit your research</a><div class="Ibar__spacer"></div><a class="Ibar__icon Ibar__icon--search" href="//www.frontiersin.org/search" aria-label="Search" target="_self" data-event="iBar-a-search"><span>Search</span></a><!----><!----><!----><div class="Ibar__userArea"></div></div></div><div><div class="Ibar__menu Ibar__menu--journal"><div class="Ibar__menu__header"><div class="Ibar__logo"><div class="Ibar__logo"><a href="//www.frontiersin.org/" aria-label="Frontiershome" data-event="iBar-a-home" class="Ibar__logo__link"><svg class="Ibar__logo__svg" viewBox="0 0 2811 590" fill="none" xmlns="http://www.w3.org/2000/svg"><path class="Ibar__logo__text" d="M633.872 234.191h-42.674v-57.246h42.674c0-19.776 2.082-35.389 5.204-48.92 4.164-13.53 9.368-23.939 17.695-31.225 8.326-8.326 18.735-13.53 32.266-16.653 13.531-3.123 29.143-5.204 47.878-5.204h21.858c7.286 0 14.572 1.04 21.857 1.04v62.451c-8.326-1.041-16.653-2.082-23.939-2.082-10.408 0-17.694 1.041-23.939 4.164-6.245 3.122-9.368 10.408-9.368 22.898v13.531h53.083v57.246h-53.083v213.372h-89.512V234.191zM794.161 176.945h86.39v47.879h1.041c6.245-17.694 16.653-30.185 31.225-39.552 14.572-9.368 31.225-13.531 49.96-13.531h10.409c3.122 0 7.286 1.041 10.408 2.082v81.185c-6.245-2.082-11.449-3.122-16.653-4.163-5.204-1.041-11.449-1.041-16.654-1.041-11.449 0-20.816 2.082-29.143 5.204-8.327 3.123-15.613 8.327-20.817 14.572-5.204 6.245-10.408 12.49-12.49 20.817-3.123 8.326-4.163 15.612-4.163 23.939v133.228h-88.472V176.945h-1.041zM989.84 312.254c0-19.776 3.122-39.552 10.41-56.205 7.28-17.695 16.65-32.266 29.14-45.797 12.49-13.531 27.06-22.899 44.76-30.185 17.69-7.285 36.43-11.449 57.24-11.449 20.82 0 39.56 4.164 57.25 11.449 17.69 7.286 32.27 17.695 45.8 30.185 12.49 12.49 22.9 28.102 29.14 45.797 7.29 17.694 10.41 36.429 10.41 56.205 0 20.817-3.12 39.552-10.41 57.246-7.29 17.695-16.65 32.266-29.14 44.756-12.49 12.49-28.11 22.899-45.8 30.185-17.69 7.286-36.43 11.449-57.25 11.449-20.81 0-40.59-4.163-57.24-11.449-17.7-7.286-32.27-17.695-44.76-30.185-12.49-12.49-21.86-28.102-29.14-44.756-7.288-17.694-10.41-36.429-10.41-57.246zm88.47 0c0 8.327 1.04 17.694 3.12 26.021 2.09 9.368 5.21 16.653 9.37 23.939 4.16 7.286 9.37 13.531 16.65 17.695 7.29 4.163 15.62 7.285 26.03 7.285 10.4 0 18.73-2.081 26.02-7.285 7.28-4.164 12.49-10.409 16.65-17.695 4.16-7.286 7.29-15.612 9.37-23.939 2.08-9.368 3.12-17.694 3.12-26.021 0-8.327-1.04-17.694-3.12-26.021-2.08-9.368-5.21-16.653-9.37-23.939-4.16-7.286-9.37-13.531-16.65-17.695-7.29-5.204-15.62-7.285-26.02-7.285-10.41 0-18.74 2.081-26.03 7.285-7.28 5.205-12.49 10.409-16.65 17.695-4.16 7.286-7.28 15.612-9.37 23.939-2.08 9.368-3.12 17.694-3.12 26.021zM1306.25 176.945h86.39v37.47h1.04c4.17-7.286 9.37-13.531 15.62-18.735 6.24-5.204 13.53-10.408 20.81-14.572 7.29-4.163 15.62-7.286 23.94-9.367 8.33-2.082 16.66-3.123 24.98-3.123 22.9 0 40.6 4.164 53.09 11.449 13.53 7.286 22.89 16.654 29.14 27.062 6.24 10.409 10.41 21.858 12.49 34.348 2.08 12.49 2.08 22.898 2.08 33.307v172.779h-88.47V316.417v-27.061c0-9.368-1.04-16.654-4.16-23.94-3.13-7.286-7.29-12.49-13.53-16.653-6.25-4.164-15.62-6.245-27.07-6.245-8.32 0-15.61 2.081-21.85 5.204-6.25 3.122-11.45 7.286-14.58 13.531-4.16 5.204-6.24 11.449-8.32 18.735s-3.12 14.572-3.12 21.858v145.717h-88.48V176.945zM1780.88 234.19h-55.17v122.819c0 10.408 3.12 17.694 8.33 20.817 6.24 3.122 13.53 5.204 22.9 5.204 4.16 0 7.28 0 11.45-1.041h11.45v65.573c-8.33 0-15.62 1.041-23.94 2.082-8.33 1.04-16.66 1.041-23.94 1.041-18.74 0-34.35-2.082-46.84-5.205-12.49-3.122-21.86-8.326-29.14-15.612-7.29-7.286-12.49-16.654-14.58-29.144-3.12-12.49-4.16-27.062-4.16-45.797V234.19h-44.76v-57.246h44.76V94.717h88.47v82.227h55.17v57.246zM1902.66 143.639h-88.48V75.984h88.48v67.655zm-89.52 33.307h88.48v270.618h-88.48V176.946zM2024.43 334.111c1.04 18.735 6.25 33.307 16.66 44.756 10.4 11.449 24.98 16.653 43.71 16.653 10.41 0 20.82-2.081 30.19-7.286 9.36-5.204 16.65-12.49 20.81-22.898h83.27c-4.16 15.613-10.41 29.144-19.78 40.593-9.36 11.449-19.77 20.817-31.22 28.102-12.49 7.286-24.98 12.491-39.55 16.654-14.57 3.122-29.15 5.204-43.72 5.204-21.86 0-41.63-3.122-60.37-9.367-18.73-6.246-34.34-15.613-46.83-28.103-12.49-12.49-22.9-27.062-30.19-45.797-7.28-17.694-10.41-38.511-10.41-60.369 0-20.817 4.17-39.552 11.45-57.246 7.29-17.694 17.7-32.266 31.23-44.756 13.53-12.49 29.14-21.858 46.83-29.144 17.7-7.286 36.43-10.408 56.21-10.408 23.94 0 45.8 4.163 63.49 12.49 17.7 8.327 33.31 19.776 44.76 35.389 11.45 15.612 20.81 32.266 26.02 52.042 5.2 19.776 8.33 41.633 7.28 64.532h-199.84v-1.041zm110.33-49.961c-1.04-15.612-6.24-28.102-15.61-39.551-9.37-10.409-21.86-16.654-37.47-16.654s-28.1 5.204-38.51 15.613c-10.41 10.408-16.66 23.939-18.74 40.592h110.33zM2254.46 176.945h86.39v47.879h1.04c6.25-17.694 16.65-30.185 31.23-39.552 14.57-9.368 31.22-13.531 49.96-13.531h10.4c3.13 0 7.29 1.041 10.41 2.082v81.185c-6.24-2.082-11.45-3.122-16.65-4.163-5.21-1.041-11.45-1.041-16.65-1.041-11.45 0-20.82 2.082-29.15 5.204-8.32 3.123-15.61 8.327-20.81 14.572-6.25 6.245-10.41 12.49-12.49 20.817-3.13 8.326-4.17 15.612-4.17 23.939v133.228h-88.47V176.945h-1.04zM2534.45 359.091c0 7.286 1.04 12.49 4.16 17.694 3.12 5.204 6.24 9.368 10.41 12.49 4.16 3.123 9.36 5.204 14.57 7.286 6.24 2.082 11.45 2.082 17.69 2.082 4.17 0 8.33 0 13.53-2.082 5.21-1.041 9.37-3.123 13.53-5.204 4.17-2.082 7.29-5.204 10.41-9.368 3.13-4.163 4.17-8.327 4.17-13.531 0-5.204-2.09-9.367-5.21-12.49-3.12-3.122-7.28-6.245-11.45-8.327-4.16-2.081-9.36-4.163-14.57-5.204-5.2-1.041-9.37-2.081-13.53-3.122-13.53-3.123-28.1-6.245-42.67-9.368-14.58-3.122-28.11-7.286-40.6-12.49-12.49-6.245-22.9-13.531-30.18-23.939-8.33-10.409-11.45-23.94-11.45-42.675 0-16.653 4.16-30.184 11.45-40.592 8.33-10.409 17.69-18.736 30.18-24.981 12.49-6.245 26.02-10.408 40.6-13.53 14.57-3.123 28.1-4.164 41.63-4.164 14.57 0 29.14 1.041 43.71 4.164 14.58 2.081 27.07 7.285 39.56 13.53 12.49 6.245 21.85 15.613 29.14 27.062 7.29 11.45 11.45 26.021 12.49 43.716h-82.23c0-10.409-4.16-18.736-11.45-23.94-7.28-4.163-16.65-7.286-28.1-7.286-4.16 0-8.32 0-12.49 1.041-4.16 1.041-8.32 1.041-12.49 2.082-4.16 1.041-7.28 3.122-9.37 6.245-2.08 3.122-4.16 6.245-4.16 11.449 0 6.245 3.12 11.449 10.41 15.613 6.24 4.163 14.57 7.286 24.98 10.408 10.41 2.082 20.82 5.204 32.27 7.286 11.44 2.082 22.89 4.163 33.3 6.245 13.53 3.123 24.98 7.286 33.31 13.531 9.37 6.245 15.61 12.49 20.82 19.776 5.2 7.286 9.36 14.572 11.45 21.858 2.08 7.285 3.12 13.53 3.12 19.776 0 17.694-4.17 33.306-11.45 45.796-8.33 12.491-17.7 21.858-30.19 30.185-12.49 7.286-26.02 12.49-41.63 16.653-15.61 3.123-31.22 5.204-45.8 5.204-15.61 0-32.26-1.04-47.87-4.163-15.62-3.122-29.15-8.327-41.64-15.612a83.855 83.855 0 01-30.18-30.185c-8.33-12.49-12.49-28.102-12.49-46.838h84.31v-2.081z" fill="#FFFFFF"></path><path d="M0 481.911V281.028l187.351-58.287v200.882L0 481.911z" fill="#8BC53F"></path><path d="M187.351 423.623V222.741l126.983 87.431v200.882l-126.983-87.431z" fill="#EBD417"></path><path d="M126.982 569.341L0 481.911l187.351-58.287 126.983 87.43-187.352 58.287z" fill="#034EA1"></path><path d="M183.188 212.331l51.001-116.574 65.573 155.085-51.001 116.574-65.573-155.085z" fill="#712E74"></path><path d="M248.761 367.415l51.001-116.574 171.739-28.102-49.96 115.533-172.78 29.143z" fill="#009FD1"></path><path d="M299.762 250.842L234.189 95.757l171.739-28.103 65.573 155.085-171.739 28.103z" fill="#F6921E"></path><path d="M187.352 222.741L59.328 198.802 44.757 71.819 172.78 95.76l14.572 126.982z" fill="#DA2128"></path><path d="M172.78 95.758L44.757 71.818l70.777-70.776 128.023 23.94-70.777 70.776z" fill="#25BCBD"></path><path d="M258.129 153.005l-70.777 69.736-14.571-126.982 70.777-70.778 14.571 128.024z" fill="#00844A"></path></svg></a></div></div><button class="Ibar__close" aria-label="Close Menu" data-event="iBarMenu-btn-closeMenu"></button></div><div class="Ibar__menu__wrapper"><div class="Ibar__menu__journal"><a href="//www.frontiersin.org/journals/neuroscience" data-event="iBarMenu-a-journalHome"><div class="Ibar__journalName__container"><div class="Ibar__journal__maskLogo" style="display:none;"><img class="Ibar__journal__logo" src></div><div class="Ibar__journalName"><span>Frontiers in</span><span> Neuroscience</span></div></div></a><div parent-data-event="iBarMenu"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> Sections</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">Sections</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><ul class="Ibar__dropdown__sections"><!--[--><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/auditory-cognitive-neuroscience" data-event="iBarJournal-sections-a_id_65">Auditory Cognitive Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/autonomic-neuroscience" data-event="iBarJournal-sections-a_id_157">Autonomic Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/brain-imaging-methods" data-event="iBarJournal-sections-a_id_600">Brain Imaging Methods</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/decision-neuroscience" data-event="iBarJournal-sections-a_id_33">Decision Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/gut-brain-axis" data-event="iBarJournal-sections-a_id_2416">Gut-Brain Axis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neural-technology" data-event="iBarJournal-sections-a_id_1206">Neural Technology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodegeneration" data-event="iBarJournal-sections-a_id_73">Neurodegeneration</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodevelopment" data-event="iBarJournal-sections-a_id_1944">Neurodevelopment</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroendocrine-science" data-event="iBarJournal-sections-a_id_113">Neuroendocrine Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroenergetics-and-brain-health" data-event="iBarJournal-sections-a_id_818">Neuroenergetics and Brain Health</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenesis" data-event="iBarJournal-sections-a_id_25">Neurogenesis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenomics" data-event="iBarJournal-sections-a_id_19">Neurogenomics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuromorphic-engineering" data-event="iBarJournal-sections-a_id_31">Neuromorphic Engineering</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuropharmacology" data-event="iBarJournal-sections-a_id_26">Neuropharmacology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroprosthetics" data-event="iBarJournal-sections-a_id_23">Neuroprosthetics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroscience-methods-and-techniques" data-event="iBarJournal-sections-a_id_3022">Neuroscience Methods and Techniques</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/perception-science" data-event="iBarJournal-sections-a_id_41">Perception Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/sleep-and-circadian-rhythms" data-event="iBarJournal-sections-a_id_1409">Sleep and Circadian Rhythms</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/social-and-evolutionary-neuroscience" data-event="iBarJournal-sections-a_id_57">Social and Evolutionary Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/translational-neuroscience" data-event="iBarJournal-sections-a_id_2450">Translational Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/visual-neuroscience" data-event="iBarJournal-sections-a_id_2411">Visual Neuroscience</a></li><!--]--></ul><!--]--></div></div></div><!--[--><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/articles" target="_self" data-event="iBar-a-articles">Articles</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/research-topics" target="_self" data-event="iBar-a-researchTopics">Research Topics</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/editors" target="_self" data-event="iBar-a-editorialBoard">Editorial board</a><!--]--><div parent-data-event="iBarMenu"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> About journal</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">About journal</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><div class="Ibar__dropdown__about"><!--[--><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>Scope</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-editors" target="_self" data-event="iBar-aboutJournal_0-a_fieldChiefEditors">Field chief editors</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-scope" target="_self" data-event="iBar-aboutJournal_1-a_mission &amp;Scope">Mission &amp; scope</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-facts" target="_self" data-event="iBar-aboutJournal_2-a_facts">Facts</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-submission" target="_self" data-event="iBar-aboutJournal_3-a_journalSections">Journal sections</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-open" target="_self" data-event="iBar-aboutJournal_4-a_openAccessStatemen">Open access statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#copyright-statement" target="_self" data-event="iBar-aboutJournal_5-a_copyrightStatement">Copyright statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-quality" target="_self" data-event="iBar-aboutJournal_6-a_quality">Quality</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>For authors</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/why-submit" target="_self" data-event="iBar-aboutJournal_0-a_whySubmit?">Why submit?</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/article-types" target="_self" data-event="iBar-aboutJournal_1-a_articleTypes">Article types</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/author-guidelines" target="_self" data-event="iBar-aboutJournal_2-a_authorGuidelines">Author guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/editor-guidelines" target="_self" data-event="iBar-aboutJournal_3-a_editorGuidelines">Editor guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/publishing-fees" target="_self" data-event="iBar-aboutJournal_4-a_publishingFees">Publishing fees</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/submission-checklist" target="_self" data-event="iBar-aboutJournal_5-a_submissionChecklis">Submission checklist</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/contact-editorial-office" target="_self" data-event="iBar-aboutJournal_6-a_contactEditorialOf">Contact editorial office</a></li><!--]--></ul><!--]--></div><!--]--></div></div></div></div><div class="Ibar__dropdown--aboutUs" parent-data-event="iBarMenu"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> About us</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">About us</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><div class="Ibar__dropdown__about"><!--[--><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Who we are</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/mission" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Mission and values</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/history" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">History</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/leadership" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Leadership</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/awards" target="_self" data-event="iBar-aboutUs_0-a_whoWeAre">Awards</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Impact and progress</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/impact" target="_self" data-event="iBar-aboutUs_1-a_impactAndProgress">Frontiers&#39; impact</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/annual-reports" target="_self" data-event="iBar-aboutUs_1-a_impactAndProgress">Our annual reports</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Publishing model</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/how-we-publish" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">How we publish</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/open-access" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Open access</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/peer-review" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Peer review</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/research-integrity" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Research integrity</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/research-topics" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Research Topics</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/fair-data-management" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">FAIR² Data Management</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/fee-policy" target="_self" data-event="iBar-aboutUs_2-a_publishingModel">Fee policy</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">Services</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://publishingpartnerships.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_3-a_services">Societies</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/open-access-agreements/consortia" target="_self" data-event="iBar-aboutUs_3-a_services">National consortia</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/open-access-agreements" target="_self" data-event="iBar-aboutUs_3-a_services">Institutional partnerships</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/collaborators" target="_self" data-event="iBar-aboutUs_3-a_services">Collaborators</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title">More from Frontiers</li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://forum.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Frontiers Forum</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/frontiers-planet-prize" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Frontiers Planet Prize</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://pressoffice.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Press office</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/sustainability" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Sustainability</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://careers.frontiersin.org/" target="_blank" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Career opportunities</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/about/contact" target="_self" data-event="iBar-aboutUs_4-a_moreFromFrontiers">Contact us</a></li><!--]--></ul><!--]--></div><!--]--></div></div></div><!--[--><a class="Ibar__link" href="https://www.frontiersin.org/journals" data-event="iBar-a-allJournals">All journals</a><a class="Ibar__link" href="https://www.frontiersin.org/articles" data-event="iBar-a-allArticles">All articles</a><!--]--><!----><!----><!----><a class="Ibar__button Ibar__submit" href="https://www.frontiersin.org/submission/submit?domainid=1&amp;fieldid=55&amp;specialtyid=0&amp;entitytype=2&amp;entityid=1" data-event="iBarMenu-a-submit">Submit your research</a></div></div></div><!--[--><div class="Ibar__journal Ibar__journal--main"><div class="Ibar__wrapper Ibar__wrapper--journal"><a href="//www.frontiersin.org/journals/neuroscience" class="Ibar__journalName" data-event="iBarJournal-a-journalHome"><div class="Ibar__journalName__container"><div class="Ibar__journal__maskLogo" style="display:none;"><img class="Ibar__journal__logo" src></div><div class="Ibar__journalName"><span>Frontiers in</span><span> Neuroscience</span></div></div></a><div parent-data-event="iBarJournal"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> Sections</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">Sections</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><ul class="Ibar__dropdown__sections"><!--[--><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/auditory-cognitive-neuroscience" data-event="iBarJournal-sections-a_id_65">Auditory Cognitive Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/autonomic-neuroscience" data-event="iBarJournal-sections-a_id_157">Autonomic Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/brain-imaging-methods" data-event="iBarJournal-sections-a_id_600">Brain Imaging Methods</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/decision-neuroscience" data-event="iBarJournal-sections-a_id_33">Decision Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/gut-brain-axis" data-event="iBarJournal-sections-a_id_2416">Gut-Brain Axis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neural-technology" data-event="iBarJournal-sections-a_id_1206">Neural Technology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodegeneration" data-event="iBarJournal-sections-a_id_73">Neurodegeneration</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodevelopment" data-event="iBarJournal-sections-a_id_1944">Neurodevelopment</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroendocrine-science" data-event="iBarJournal-sections-a_id_113">Neuroendocrine Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroenergetics-and-brain-health" data-event="iBarJournal-sections-a_id_818">Neuroenergetics and Brain Health</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenesis" data-event="iBarJournal-sections-a_id_25">Neurogenesis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenomics" data-event="iBarJournal-sections-a_id_19">Neurogenomics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuromorphic-engineering" data-event="iBarJournal-sections-a_id_31">Neuromorphic Engineering</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuropharmacology" data-event="iBarJournal-sections-a_id_26">Neuropharmacology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroprosthetics" data-event="iBarJournal-sections-a_id_23">Neuroprosthetics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroscience-methods-and-techniques" data-event="iBarJournal-sections-a_id_3022">Neuroscience Methods and Techniques</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/perception-science" data-event="iBarJournal-sections-a_id_41">Perception Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/sleep-and-circadian-rhythms" data-event="iBarJournal-sections-a_id_1409">Sleep and Circadian Rhythms</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/social-and-evolutionary-neuroscience" data-event="iBarJournal-sections-a_id_57">Social and Evolutionary Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/translational-neuroscience" data-event="iBarJournal-sections-a_id_2450">Translational Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/visual-neuroscience" data-event="iBarJournal-sections-a_id_2411">Visual Neuroscience</a></li><!--]--></ul><!--]--></div></div></div><!--[--><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/articles" target="_self" data-event="iBar-a-articles">Articles</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/research-topics" target="_self" data-event="iBar-a-researchTopics">Research Topics</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/editors" target="_self" data-event="iBar-a-editorialBoard">Editorial board</a><!--]--><div parent-data-event="iBarJournal"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> About journal</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">About journal</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><div class="Ibar__dropdown__about"><!--[--><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>Scope</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-editors" target="_self" data-event="iBar-aboutJournal_0-a_fieldChiefEditors">Field chief editors</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-scope" target="_self" data-event="iBar-aboutJournal_1-a_mission &amp;Scope">Mission &amp; scope</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-facts" target="_self" data-event="iBar-aboutJournal_2-a_facts">Facts</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-submission" target="_self" data-event="iBar-aboutJournal_3-a_journalSections">Journal sections</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-open" target="_self" data-event="iBar-aboutJournal_4-a_openAccessStatemen">Open access statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#copyright-statement" target="_self" data-event="iBar-aboutJournal_5-a_copyrightStatement">Copyright statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-quality" target="_self" data-event="iBar-aboutJournal_6-a_quality">Quality</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>For authors</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/why-submit" target="_self" data-event="iBar-aboutJournal_0-a_whySubmit?">Why submit?</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/article-types" target="_self" data-event="iBar-aboutJournal_1-a_articleTypes">Article types</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/author-guidelines" target="_self" data-event="iBar-aboutJournal_2-a_authorGuidelines">Author guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/editor-guidelines" target="_self" data-event="iBar-aboutJournal_3-a_editorGuidelines">Editor guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/publishing-fees" target="_self" data-event="iBar-aboutJournal_4-a_publishingFees">Publishing fees</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/submission-checklist" target="_self" data-event="iBar-aboutJournal_5-a_submissionChecklis">Submission checklist</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/contact-editorial-office" target="_self" data-event="iBar-aboutJournal_6-a_contactEditorialOf">Contact editorial office</a></li><!--]--></ul><!--]--></div><!--]--></div></div></div><div class="Ibar__spacer"></div></div></div><div class="Ibar__journal Ibar__journal--mix"><div class="Ibar__wrapper Ibar__wrapper--journal"><div class="Ibar__logo"><a href="//www.frontiersin.org/" aria-label="Frontiershome" data-event="iBar-a-home" class="Ibar__logo__link"><svg class="Ibar__logo__svg" viewBox="0 0 2811 590" fill="none" xmlns="http://www.w3.org/2000/svg"><path class="Ibar__logo__text" d="M633.872 234.191h-42.674v-57.246h42.674c0-19.776 2.082-35.389 5.204-48.92 4.164-13.53 9.368-23.939 17.695-31.225 8.326-8.326 18.735-13.53 32.266-16.653 13.531-3.123 29.143-5.204 47.878-5.204h21.858c7.286 0 14.572 1.04 21.857 1.04v62.451c-8.326-1.041-16.653-2.082-23.939-2.082-10.408 0-17.694 1.041-23.939 4.164-6.245 3.122-9.368 10.408-9.368 22.898v13.531h53.083v57.246h-53.083v213.372h-89.512V234.191zM794.161 176.945h86.39v47.879h1.041c6.245-17.694 16.653-30.185 31.225-39.552 14.572-9.368 31.225-13.531 49.96-13.531h10.409c3.122 0 7.286 1.041 10.408 2.082v81.185c-6.245-2.082-11.449-3.122-16.653-4.163-5.204-1.041-11.449-1.041-16.654-1.041-11.449 0-20.816 2.082-29.143 5.204-8.327 3.123-15.613 8.327-20.817 14.572-5.204 6.245-10.408 12.49-12.49 20.817-3.123 8.326-4.163 15.612-4.163 23.939v133.228h-88.472V176.945h-1.041zM989.84 312.254c0-19.776 3.122-39.552 10.41-56.205 7.28-17.695 16.65-32.266 29.14-45.797 12.49-13.531 27.06-22.899 44.76-30.185 17.69-7.285 36.43-11.449 57.24-11.449 20.82 0 39.56 4.164 57.25 11.449 17.69 7.286 32.27 17.695 45.8 30.185 12.49 12.49 22.9 28.102 29.14 45.797 7.29 17.694 10.41 36.429 10.41 56.205 0 20.817-3.12 39.552-10.41 57.246-7.29 17.695-16.65 32.266-29.14 44.756-12.49 12.49-28.11 22.899-45.8 30.185-17.69 7.286-36.43 11.449-57.25 11.449-20.81 0-40.59-4.163-57.24-11.449-17.7-7.286-32.27-17.695-44.76-30.185-12.49-12.49-21.86-28.102-29.14-44.756-7.288-17.694-10.41-36.429-10.41-57.246zm88.47 0c0 8.327 1.04 17.694 3.12 26.021 2.09 9.368 5.21 16.653 9.37 23.939 4.16 7.286 9.37 13.531 16.65 17.695 7.29 4.163 15.62 7.285 26.03 7.285 10.4 0 18.73-2.081 26.02-7.285 7.28-4.164 12.49-10.409 16.65-17.695 4.16-7.286 7.29-15.612 9.37-23.939 2.08-9.368 3.12-17.694 3.12-26.021 0-8.327-1.04-17.694-3.12-26.021-2.08-9.368-5.21-16.653-9.37-23.939-4.16-7.286-9.37-13.531-16.65-17.695-7.29-5.204-15.62-7.285-26.02-7.285-10.41 0-18.74 2.081-26.03 7.285-7.28 5.205-12.49 10.409-16.65 17.695-4.16 7.286-7.28 15.612-9.37 23.939-2.08 9.368-3.12 17.694-3.12 26.021zM1306.25 176.945h86.39v37.47h1.04c4.17-7.286 9.37-13.531 15.62-18.735 6.24-5.204 13.53-10.408 20.81-14.572 7.29-4.163 15.62-7.286 23.94-9.367 8.33-2.082 16.66-3.123 24.98-3.123 22.9 0 40.6 4.164 53.09 11.449 13.53 7.286 22.89 16.654 29.14 27.062 6.24 10.409 10.41 21.858 12.49 34.348 2.08 12.49 2.08 22.898 2.08 33.307v172.779h-88.47V316.417v-27.061c0-9.368-1.04-16.654-4.16-23.94-3.13-7.286-7.29-12.49-13.53-16.653-6.25-4.164-15.62-6.245-27.07-6.245-8.32 0-15.61 2.081-21.85 5.204-6.25 3.122-11.45 7.286-14.58 13.531-4.16 5.204-6.24 11.449-8.32 18.735s-3.12 14.572-3.12 21.858v145.717h-88.48V176.945zM1780.88 234.19h-55.17v122.819c0 10.408 3.12 17.694 8.33 20.817 6.24 3.122 13.53 5.204 22.9 5.204 4.16 0 7.28 0 11.45-1.041h11.45v65.573c-8.33 0-15.62 1.041-23.94 2.082-8.33 1.04-16.66 1.041-23.94 1.041-18.74 0-34.35-2.082-46.84-5.205-12.49-3.122-21.86-8.326-29.14-15.612-7.29-7.286-12.49-16.654-14.58-29.144-3.12-12.49-4.16-27.062-4.16-45.797V234.19h-44.76v-57.246h44.76V94.717h88.47v82.227h55.17v57.246zM1902.66 143.639h-88.48V75.984h88.48v67.655zm-89.52 33.307h88.48v270.618h-88.48V176.946zM2024.43 334.111c1.04 18.735 6.25 33.307 16.66 44.756 10.4 11.449 24.98 16.653 43.71 16.653 10.41 0 20.82-2.081 30.19-7.286 9.36-5.204 16.65-12.49 20.81-22.898h83.27c-4.16 15.613-10.41 29.144-19.78 40.593-9.36 11.449-19.77 20.817-31.22 28.102-12.49 7.286-24.98 12.491-39.55 16.654-14.57 3.122-29.15 5.204-43.72 5.204-21.86 0-41.63-3.122-60.37-9.367-18.73-6.246-34.34-15.613-46.83-28.103-12.49-12.49-22.9-27.062-30.19-45.797-7.28-17.694-10.41-38.511-10.41-60.369 0-20.817 4.17-39.552 11.45-57.246 7.29-17.694 17.7-32.266 31.23-44.756 13.53-12.49 29.14-21.858 46.83-29.144 17.7-7.286 36.43-10.408 56.21-10.408 23.94 0 45.8 4.163 63.49 12.49 17.7 8.327 33.31 19.776 44.76 35.389 11.45 15.612 20.81 32.266 26.02 52.042 5.2 19.776 8.33 41.633 7.28 64.532h-199.84v-1.041zm110.33-49.961c-1.04-15.612-6.24-28.102-15.61-39.551-9.37-10.409-21.86-16.654-37.47-16.654s-28.1 5.204-38.51 15.613c-10.41 10.408-16.66 23.939-18.74 40.592h110.33zM2254.46 176.945h86.39v47.879h1.04c6.25-17.694 16.65-30.185 31.23-39.552 14.57-9.368 31.22-13.531 49.96-13.531h10.4c3.13 0 7.29 1.041 10.41 2.082v81.185c-6.24-2.082-11.45-3.122-16.65-4.163-5.21-1.041-11.45-1.041-16.65-1.041-11.45 0-20.82 2.082-29.15 5.204-8.32 3.123-15.61 8.327-20.81 14.572-6.25 6.245-10.41 12.49-12.49 20.817-3.13 8.326-4.17 15.612-4.17 23.939v133.228h-88.47V176.945h-1.04zM2534.45 359.091c0 7.286 1.04 12.49 4.16 17.694 3.12 5.204 6.24 9.368 10.41 12.49 4.16 3.123 9.36 5.204 14.57 7.286 6.24 2.082 11.45 2.082 17.69 2.082 4.17 0 8.33 0 13.53-2.082 5.21-1.041 9.37-3.123 13.53-5.204 4.17-2.082 7.29-5.204 10.41-9.368 3.13-4.163 4.17-8.327 4.17-13.531 0-5.204-2.09-9.367-5.21-12.49-3.12-3.122-7.28-6.245-11.45-8.327-4.16-2.081-9.36-4.163-14.57-5.204-5.2-1.041-9.37-2.081-13.53-3.122-13.53-3.123-28.1-6.245-42.67-9.368-14.58-3.122-28.11-7.286-40.6-12.49-12.49-6.245-22.9-13.531-30.18-23.939-8.33-10.409-11.45-23.94-11.45-42.675 0-16.653 4.16-30.184 11.45-40.592 8.33-10.409 17.69-18.736 30.18-24.981 12.49-6.245 26.02-10.408 40.6-13.53 14.57-3.123 28.1-4.164 41.63-4.164 14.57 0 29.14 1.041 43.71 4.164 14.58 2.081 27.07 7.285 39.56 13.53 12.49 6.245 21.85 15.613 29.14 27.062 7.29 11.45 11.45 26.021 12.49 43.716h-82.23c0-10.409-4.16-18.736-11.45-23.94-7.28-4.163-16.65-7.286-28.1-7.286-4.16 0-8.32 0-12.49 1.041-4.16 1.041-8.32 1.041-12.49 2.082-4.16 1.041-7.28 3.122-9.37 6.245-2.08 3.122-4.16 6.245-4.16 11.449 0 6.245 3.12 11.449 10.41 15.613 6.24 4.163 14.57 7.286 24.98 10.408 10.41 2.082 20.82 5.204 32.27 7.286 11.44 2.082 22.89 4.163 33.3 6.245 13.53 3.123 24.98 7.286 33.31 13.531 9.37 6.245 15.61 12.49 20.82 19.776 5.2 7.286 9.36 14.572 11.45 21.858 2.08 7.285 3.12 13.53 3.12 19.776 0 17.694-4.17 33.306-11.45 45.796-8.33 12.491-17.7 21.858-30.19 30.185-12.49 7.286-26.02 12.49-41.63 16.653-15.61 3.123-31.22 5.204-45.8 5.204-15.61 0-32.26-1.04-47.87-4.163-15.62-3.122-29.15-8.327-41.64-15.612a83.855 83.855 0 01-30.18-30.185c-8.33-12.49-12.49-28.102-12.49-46.838h84.31v-2.081z" fill="#FFFFFF"></path><path d="M0 481.911V281.028l187.351-58.287v200.882L0 481.911z" fill="#8BC53F"></path><path d="M187.351 423.623V222.741l126.983 87.431v200.882l-126.983-87.431z" fill="#EBD417"></path><path d="M126.982 569.341L0 481.911l187.351-58.287 126.983 87.43-187.352 58.287z" fill="#034EA1"></path><path d="M183.188 212.331l51.001-116.574 65.573 155.085-51.001 116.574-65.573-155.085z" fill="#712E74"></path><path d="M248.761 367.415l51.001-116.574 171.739-28.102-49.96 115.533-172.78 29.143z" fill="#009FD1"></path><path d="M299.762 250.842L234.189 95.757l171.739-28.103 65.573 155.085-171.739 28.103z" fill="#F6921E"></path><path d="M187.352 222.741L59.328 198.802 44.757 71.819 172.78 95.76l14.572 126.982z" fill="#DA2128"></path><path d="M172.78 95.758L44.757 71.818l70.777-70.776 128.023 23.94-70.777 70.776z" fill="#25BCBD"></path><path d="M258.129 153.005l-70.777 69.736-14.571-126.982 70.777-70.778 14.571 128.024z" fill="#00844A"></path></svg></a></div><a href="//www.frontiersin.org/journals/neuroscience" class="Ibar__journalName" data-event="iBarJournal-a-journalHome"><div class="Ibar__journalName__container" logoclass="Ibar__logo--mixed"><div class="Ibar__journal__maskLogo" style="display:none;"><img class="Ibar__journal__logo" src></div><div class="Ibar__journalName"><span>Frontiers in</span><span> Neuroscience</span></div></div></a><div class="Ibar__spacer"></div><div parent-data-event="iBarJournal"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> Sections</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">Sections</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><ul class="Ibar__dropdown__sections"><!--[--><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/auditory-cognitive-neuroscience" data-event="iBarJournal-sections-a_id_65">Auditory Cognitive Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/autonomic-neuroscience" data-event="iBarJournal-sections-a_id_157">Autonomic Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/brain-imaging-methods" data-event="iBarJournal-sections-a_id_600">Brain Imaging Methods</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/decision-neuroscience" data-event="iBarJournal-sections-a_id_33">Decision Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/gut-brain-axis" data-event="iBarJournal-sections-a_id_2416">Gut-Brain Axis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neural-technology" data-event="iBarJournal-sections-a_id_1206">Neural Technology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodegeneration" data-event="iBarJournal-sections-a_id_73">Neurodegeneration</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurodevelopment" data-event="iBarJournal-sections-a_id_1944">Neurodevelopment</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroendocrine-science" data-event="iBarJournal-sections-a_id_113">Neuroendocrine Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroenergetics-and-brain-health" data-event="iBarJournal-sections-a_id_818">Neuroenergetics and Brain Health</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenesis" data-event="iBarJournal-sections-a_id_25">Neurogenesis</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neurogenomics" data-event="iBarJournal-sections-a_id_19">Neurogenomics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuromorphic-engineering" data-event="iBarJournal-sections-a_id_31">Neuromorphic Engineering</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuropharmacology" data-event="iBarJournal-sections-a_id_26">Neuropharmacology</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroprosthetics" data-event="iBarJournal-sections-a_id_23">Neuroprosthetics</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/neuroscience-methods-and-techniques" data-event="iBarJournal-sections-a_id_3022">Neuroscience Methods and Techniques</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/perception-science" data-event="iBarJournal-sections-a_id_41">Perception Science</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/sleep-and-circadian-rhythms" data-event="iBarJournal-sections-a_id_1409">Sleep and Circadian Rhythms</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/social-and-evolutionary-neuroscience" data-event="iBarJournal-sections-a_id_57">Social and Evolutionary Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/translational-neuroscience" data-event="iBarJournal-sections-a_id_2450">Translational Neuroscience</a></li><li class="Ibar__dropdown__sections__item"><a href="/journals/neuroscience/sections/visual-neuroscience" data-event="iBarJournal-sections-a_id_2411">Visual Neuroscience</a></li><!--]--></ul><!--]--></div></div></div><!--[--><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/articles" target="_self" data-event="iBar-a-articles">Articles</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/research-topics" target="_self" data-event="iBar-a-researchTopics">Research Topics</a><a class="Ibar__link" href="//www.frontiersin.org/journals/neuroscience/editors" target="_self" data-event="iBar-a-editorialBoard">Editorial board</a><!--]--><div parent-data-event="iBarJournal"><div class="Ibar__dropdown"><button class="Ibar__dropdown__trigger"><!----> About journal</button><div class="Ibar__dropdown__menu"><div class="Ibar__dropdown__menu__header"><button class="Ibar__dropdown__menu__header__title" aria-label="Close Dropdown">About journal</button><button class="Ibar__close" aria-label="Close Dropdown"></button></div><!--[--><div class="Ibar__dropdown__about"><!--[--><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>Scope</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-editors" target="_self" data-event="iBar-aboutJournal_0-a_fieldChiefEditors">Field chief editors</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-scope" target="_self" data-event="iBar-aboutJournal_1-a_mission &amp;Scope">Mission &amp; scope</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-facts" target="_self" data-event="iBar-aboutJournal_2-a_facts">Facts</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-submission" target="_self" data-event="iBar-aboutJournal_3-a_journalSections">Journal sections</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-open" target="_self" data-event="iBar-aboutJournal_4-a_openAccessStatemen">Open access statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#copyright-statement" target="_self" data-event="iBar-aboutJournal_5-a_copyrightStatement">Copyright statement</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/about#about-quality" target="_self" data-event="iBar-aboutJournal_6-a_quality">Quality</a></li><!--]--></ul><ul class="Ibar__dropdown__about__block"><li class="Ibar__dropdown__about__block__title"><span>For authors</span></li><!--[--><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/why-submit" target="_self" data-event="iBar-aboutJournal_0-a_whySubmit?">Why submit?</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/article-types" target="_self" data-event="iBar-aboutJournal_1-a_articleTypes">Article types</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/author-guidelines" target="_self" data-event="iBar-aboutJournal_2-a_authorGuidelines">Author guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/editor-guidelines" target="_self" data-event="iBar-aboutJournal_3-a_editorGuidelines">Editor guidelines</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/publishing-fees" target="_self" data-event="iBar-aboutJournal_4-a_publishingFees">Publishing fees</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/submission-checklist" target="_self" data-event="iBar-aboutJournal_5-a_submissionChecklis">Submission checklist</a></li><li class="Ibar__dropdown__about__block__item"><a href="https://www.frontiersin.org/journals/neuroscience/for-authors/contact-editorial-office" target="_self" data-event="iBar-aboutJournal_6-a_contactEditorialOf">Contact editorial office</a></li><!--]--></ul><!--]--></div><!--]--></div></div></div><div class="Ibar__spacer"></div><a class="Ibar__button Ibar__submit" href="https://www.frontiersin.org/submission/submit?domainid=1&amp;fieldid=55&amp;specialtyid=0&amp;entitytype=2&amp;entityid=1" data-event="iBarJournal-a-submit"><span>Submit</span><span> your research</span></a><a class="Ibar__icon Ibar__icon--search" href="//www.frontiersin.org/search" aria-label="Search" target="_self" data-event="iBar-a-search"><span>Search</span></a><!----><!----><!----><div class="Ibar__userArea"></div></div></div><!--]--></nav><div class="ArticlePage"><!--[--><div class="Layout Layout--withAside Layout--withIbarMix"><div class="Alert Alert--info Alert--noInfo ArticleTemplateBanner"><div class="Alert__icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="24px" class="FeedbackIcon"><path fill="#fff" d="M10 10h28v28H10z"></path><path fill="var(--blue50)" d="M24 2.88a21.12 21.12 0 1 0 0 42.24 21.12 21.12 0 0 0 0-42.24ZM22.08 13.4a.96.96 0 0 1 .96-.96h1.92a.96.96 0 0 1 .96.96v1.92a.96.96 0 0 1-.96.96h-1.92a.96.96 0 0 1-.96-.96V13.4Zm5.76 21.2a.96.96 0 0 1-.96.97h-5.76a.96.96 0 0 1-.96-.96v-1.92a.96.96 0 0 1 .96-.96h.96v-7.68h-.96a.96.96 0 0 1-.96-.96v-1.92a.96.96 0 0 1 .96-.96h3.84a.96.96 0 0 1 .96.96v10.56h.96a.96.96 0 0 1 .96.96v1.92Z"></path></svg></div><div class="Alert__main"><p class="Alert__message">Your new experience awaits. Try the new design now and help us make it even better</p><!--[--><button type="button" class="Button Button--outline Button--grey80 Button--small ArticleTemplateBanner__switchButton" data-event="btn-action"><span>Switch to the new experience</span></button><!--]--><!----></div><ol class="Alert__info"><!--[--><!--]--></ol></div><!----><main class="Layout__main"><!----><div class="ArticleDetails"><div class="ArticleLayoutHeader"><div class="ArticleLayoutHeader__info"><p class="ArticleLayoutHeader__info__title">ORIGINAL RESEARCH article</p><p class="ArticleLayoutHeader__info__journalDate"><span>Front. Neurosci.</span><span>, 17 February 2017</span></p><p class="ArticleLayoutHeader__info__journalDate"> Sec. Brain Imaging Methods</p><p class="ArticleLayoutHeader__info__doiVolume"><span>Volume 11 - 2017 | </span><a class="ArticleLayoutHeader__info__doi" href="https://doi.org/10.3389/fnins.2017.00062">https://doi.org/10.3389/fnins.2017.00062</a></p><!----></div><!----><!----></div><div class="ArticleDetails__main__content"><div class="ArticleDetails__main__content__main ArticleDetails__main__content__main--fullArticle"><div class="JournalAbstract"><div class="JournalAbstract__titleWrapper"><h1>Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding</h1><!----></div><!----></div><div class="JournalFullText"><div class="JournalAbstract">
<a id="h1" name="h1"></a>
<div class="authors"><span class="author-wrapper notranslate">
<a href="https://loop.frontiersin.org/people/357845" class="user-id-357845"><img class="pr5" src="https://loop.frontiersin.org/images/profile/357845/74" onerror="this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';" alt="
Luca Baldassarre">Luca Baldassarre</a><sup>1</sup></span><span class="author-wrapper notranslate"><a href="https://loop.frontiersin.org/people/368732" class="user-id-368732"><img class="pr5" src="https://loop.frontiersin.org/images/profile/368732/74" onerror="this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';" alt="Massimiliano Pontil,">Massimiliano Pontil</a><sup>2,3</sup></span><span class="author-wrapper notranslate"><a href="https://loop.frontiersin.org/people/63987" class="user-id-63987"><img class="pr5" src="https://loop.frontiersin.org/images/profile/63987/74" onerror="this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';" alt="Janaina Mour&#xE;o-Miranda,*">Janaina Mour&#x000E3;o-Miranda</a><sup>3,4</sup><sup>*</sup></span></div>
<ul class="notes">
<li><span><sup>1</sup></span>Laboratory for Information and Inference Systems, &#x000C9;cole Polytechnique F&#x000E9;d&#x000E9;rale de Lausanne (EPFL), Lausanne, Switzerland</li>
<li><span><sup>2</sup></span>Istituto Italiano di Tecnologia, Genoa, Italy</li>
<li><span><sup>3</sup></span>Department of Computer Science, University College London, London, UK</li>
<li><span><sup>4</sup></span>Max Planck University College London Centre for Computational Psychiatry and Ageing Research, University College London, London, UK</li>
</ul>
<p>Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional spatial and temporal constraints in the predictive model and carry the promise of being more interpretable than non-structured sparse methods, such as LASSO or Elastic Net methods. However, although sparsity has often been advocated as leading to more interpretable models it can also lead to unstable models under subsampling or slight changes of the experimental conditions. In the present work we investigate the impact of using stability/reproducibility as an additional model selection criterion<sup id="footnotesuper1"><a id="note1a"></a><a class="footnoteanchor" href="#note1" style="color:grey;">1</a></sup> on several different sparse (and structured sparse) methods that have been recently applied for fMRI brain decoding. We compare three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions; (iii) classification accuracy and correlation between the solutions. The methods we consider include LASSO, Elastic Net, Total Variation, sparse Total Variation, Laplacian and Graph Laplacian Elastic Net (GraphNET). Our results show that explicitly accounting for stability/reproducibility during the model optimization can mitigate some of the instability inherent in sparse methods. In particular, using accuracy and overlap between the solutions as a joint optimization criterion can lead to solutions that are more similar in terms of accuracy, sparsity levels and coefficient maps even when different sparsity methods are considered.</p>
<div class="clear"></div>
</div>
<div class="JournalFullText">
<a id="h2" name="h2"></a><h2>1. Introduction</h2>
<p class="mb15">Supervised machine learning techniques are being increasingly used in neuroimaging analysis for their inherent ability to deal with multivariate data, higher sensibility and possibility of incorporating specific prior-information.</p>
<p class="mb15">Given the high-dimensionality of neuroimaging, and the few number of samples, regularized linear models have been applied in order to produce effective predictive models (<a href="#B28">Mourao-Miranda et al., 2006</a>, <a href="#B27">2007</a>; <a href="#B15">Grosenick et al., 2011</a>; <a href="#B25">Michel et al., 2011</a>). However, ordinary linear models, such as, the Least Squares Ridge Regression (<a href="#B39">Tikhonov and Arsenin, 1977</a>) or standard Support Vector Machines (SVMs) (<a href="#B8">Cortes and Vapnik, 1995</a>) employ an l2 regularization scheme, hence they are incapable of discriminating which areas (or voxels) of the brain mostly contribute to the model&#x00027;s predictions. In other words, these models are dense, in the sense that they use the information contained in the entire voxel set to generate a predictive function.</p>
<p class="mb15">Sparse methods, like the LASSO (<a href="#B38">Tibshirani, 1996</a>) or the Elastic Net (<a href="#B43">Zou and Hastie, 2005</a>), are able to estimate solutions for which only few voxels are deemed relevant, therefore aiding interpretation. However, often these models provide overly sparse solutions, where the non-zero coefficients are assigned to disparate regions across the brain, without exploiting any spatial or temporal prior information (<a href="#B15">Grosenick et al., 2011</a>; <a href="#B25">Michel et al., 2011</a>; <a href="#B31">Rasmussen et al., 2012</a>).</p>
<p class="mb0">Structured sparsity models (<a href="#B7">Chambolle, 2004</a>; <a href="#B2">Bach et al., 2011</a>; <a href="#B3">Baldassarre et al., 2012a</a>; <a href="#B24">Micchelli et al., 2013</a>) extend the well-known methods of LASSO by encouraging models which are sparse in some preferred way, e.g., the non-zero regression coefficients may be preferred to be associated to the same brain region or nearby voxels. Furthermore, the coefficients may be encouraged to be constant or vary smoothly within regions of the brain. Despite sparsity has traditionally been connected with interpretability, in the sense that sparser models are easier to interpret, these new structured sparsity models promise an even greater ease of interpretation of the coefficient maps, because the active voxels are grouped together in possibly few clusters, which fits well with our knowledge about the brain&#x00027;s specialized regions and networks. These method hence have the potential to further improve out-of-sample performance in comparison to standard sparsity methods such as the LASSO.</p>
<h3>1.1. Structured Sparse Models in Neuroimaging</h3>
<p class="mb15">Recently, (structured) sparsity methods have received significant attention in neuroimaging, see <a href="#B13">Gramfort et al. (2013)</a>, <a href="#B26">Mohr et al. (2015)</a>, <a href="#B5">Belilovsky et al. (2015)</a>, <a href="#B21">Jenatton et al. (2012)</a>, <a href="#B19">Hoyos-Idrobo et al. (2015)</a>, <a href="#B9">Dohmatob et al. (2014)</a>, and <a href="#B14">Grosenick et al. (2013)</a> and references therein. For example <a href="#B20">Jenatton et al. (2011)</a> investigated the benefits of using hierarchical structured sparsity for brain decoding, taking into account the spatial and multi-scale structure of the fMRI data. Their proposed approach yielded similar or higher prediction accuracy than the compared approaches (l1 and squared l2 regularization penalties), and the obtained map of weights or coefficients exhibited a cluster-like structure. <a href="#B12">Fiot et al. (2014)</a> compared a number of structured sparse methods (Sobolev, total variation, fused LASSO) with regularization methods which do no take into account the spatial structure (LASSO, Ridge and Elastic-Net) on a clinical classification problem. Their results showed that the structured sparse approaches can lead to coherent and improved coefficient maps with better classification performance than the ones obtained with the standard regularization methods.</p>
<p class="mb15"><a href="#B26">Mohr et al. (2015)</a> presented a comparison of different sparse and non sparse regularization methods for brain decoding. They focused on a classification problem and use the Logistic Loss or Hinge Loss (SVMs). The authors argued that l1 regularization can improve classification performance over l2 approaches (using SVM as an example of an l2 approach) as well as improve model interpretability. In addition, by considering the 3D structure of fMRI data, even better interpretability of the weights or coefficient maps could be possible. For this purpose, one more promising method which was not considered in <a href="#B26">Mohr et al. (2015)</a> is sparse total variation. This method has been suggested in the context of fMRI by <a href="#B4">Baldassarre et al. (2012b)</a> as means to learn interpretable and more stable brain maps. Further work investigating applications of sparse total variation in this context include <a href="#B13">Gramfort et al. (2013)</a>, <a href="#B9">Dohmatob et al. (2014)</a>, and <a href="#B10">Eickenberg et al. (2015)</a>.</p>
<p class="mb15">Despite of all the evidence that sparsity and structured sparsity can lead to predictive models that are easier to interpret, sparsity alone is not sufficient for making reasonable inferences as sparse models can be unstable under subsampling or slight changes of the experimental conditions. One key source of instability is correlation between features, a problem specific to multivariate methods but not univariate methods. However, univariate methods are often too simplistic and may be suboptimal. Another difficulty with sparse models is that there are many possible ways of imposing sparsity or structured sparsity in predictive models. Finding the ideal sparsity for a specific problem is therefore a model selection problem. A common difficulty in neuroimaging applications is that often different models lead to very similar generalization performance (e.g., accuracy), then it becomes difficult to choose the best model and identify the &#x0201C;true brain map&#x0201D; of informative or predictive regions. Some authors have used the capacity to recover the &#x0201C;best brain regions&#x0201D; as alternative criterion to evaluate the models. In theses cases the &#x0201C;best regions&#x0201D; are based either on prior knowledge about the problem or univariate statistical tests applied to the data, both of which might not correspond to the ground truth. In fact, in most neuroimaging applications we do not know a-priori which regions are expected to be relevant for prediction therefore alternative approaches for model comparison are necessary.</p>
<p class="mb15">One way to increase the stability or reproducibility of sparse models is to explicitly account for it during the model selection procedure. The use of a tradeoff between accuracy and reproducibility as a model selection criterion has been previously proposed in neuroimaging (e.g., <a href="#B35">Strother et al., 2002</a>; <a href="#B31">Rasmussen et al., 2012</a>). For example, in <a href="#B31">Rasmussen et al. (2012)</a>, the authors investigated the relative influence of model regularization parameter choices on both the model generalization and the reliability of the spatial patterns (coefficient maps) extracted from a classification model. Building upon their work, we advocate stability/reproducibility as the natural counterpart of sparsity in order to obtain interpretable inferences from sparse supervised learning methods.</p>
<p class="mb0">The issue of improving interpretability and stability of predictive brain maps has also been studied from a different perspective by <a href="#B19">Hoyos-Idrobo et al. (2015)</a> and <a href="#B41">Wang et al. (2014)</a>. In <a href="#B19">Hoyos-Idrobo et al. (2015)</a> the authors focused on feature clustering and bagging as a means to improve stability of l1 regularization and interpretability of the associated brain maps. In <a href="#B41">Wang et al. (2014)</a> the authors proposed a &#x0201C;randomized structural sparsity,&#x0201D; incorporating the idea of structural sparsity in the stability selection framework. They demonstrated that their proposed approach can achieve better control of false positives and false negatives than alternative methods.</p>
<h3>1.2. Our Contribution</h3>
<p class="mb15">In this paper, we investigate the role of model selection criteria on different sparsity (and structured sparsity) methods that have been recently applied for decoding fMRI data, including one we proposed in a previous work (<a href="#B4">Baldassarre et al., 2012b</a>), and assess their performance with respect to accuracy, sparsity and reproducibility. In order to investigate the impact of using reproducibility as an additional criterion for model selection, we compare three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions (or coefficient maps); (iii) classification accuracy and correlation between the solutions (or coefficient maps). The methods we consider include LASSO (<a href="#B38">Tibshirani, 1996</a>), Elastic Net (<a href="#B43">Zou and Hastie, 2005</a>), Total Variation (<a href="#B25">Michel et al., 2011</a>), Graph Laplacian Elastic Net (GraphNET) (<a href="#B15">Grosenick et al., 2011</a>) and sparse Total Variation (<a href="#B4">Baldassarre et al., 2012b</a>). For our comparison, we use a dataset of fMRI scans collected from 16 healthy volunteers while watching pleasant or unpleasant images (<a href="#B28">Mourao-Miranda et al., 2006</a>, <a href="#B27">2007</a>; <a href="#B16">Hardoon et al., 2007</a>).</p>
<p class="mb15">Model selection is performed by a Leave-One-Subject-Out Cross-Validation (LOSO-CV) scheme, which we describe in detail in the methods section. Although regularization helps to reduce model variance, the value of the regularization parameter(s) which yield a maximal accuracy model varies across the cross-validation folds, resulting in models with varying degree of sparsity and sets of selected variables (voxels). A main point of this paper is to show that this instability effect can be substantially reduced by employing a different model selection criterion which involves accuracy and &#x0201C;reproducibility&#x0201D; simultaneously. Specifically, we discuss the relevance of our findings with respect to using classification accuracy as a proxy for statistical significance of a given model. Our results suggest that the model selection criterion plays a more important role than the choice of the sparsity or structured sparsity. When using sparsity and overlap between the solutions as a joint optimization criterion the solutions for different methods became very similar in terms of accuracy, sparsity levels and coefficient maps. These results demonstrate the added value of accounting for reproducibility/stability in addition to generalization performance during model selection in supervising learning models.</p>
<p class="mb0">The paper is organized in the following manner. In Section 2 we present the sparse (and structured) methods, experimental protocol, model selection criteria and dataset. We present the results in Section 3 and the discussion in Section 4.</p>
<a id="h3" name="h3"></a><h2>2. Materials and Methods</h2>
<h3 class="pt0">2.1. Supervised Learning for Classification</h3>
<p class="mb15">Given a training set of input-output pairs <math><mrow><mi mathvariant="-tex-caligraphic">D</mi></mrow><mo>=</mo><msubsup><mrow><mrow><mo>{</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi>x</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>}</mo></mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi></mrow></msubsup></math>, with <math><msub><mrow><mi>x</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>&#x02208;</mo><msup><mrow><mi>&#x0211D;</mi></mrow><mrow><mi>p</mi></mrow></msup></math> and <i>y</i><sub><i>i</i></sub> &#x02208; &#x0211D;, a supervised learning method infers the relationship between <i>x</i> and <i>y</i> by estimating a function <i>f</i> : &#x0211D;<sup><i>p</i></sup> &#x02192; &#x0211D; such that, for every <i>x</i> &#x02208; &#x0211D;<sup><i>p</i></sup>, <i>f</i>(<i>x</i>) provides the prediction of <i>y</i> given <i>x</i>.</p>
<p class="mb15">In neuroimaging studies, the input <i>x</i><sub><i>i</i></sub> represents the brain scans in vector format and the number of variables <i>p</i> corresponds to the number of recorded voxels. In the present paper we consider a binary classification task, so that <i>y</i> &#x02208; {&#x02212;1, 1}, but our results can easily be extended to the regression or the multi-class setting. Furthermore, we limit our analysis to linear models, so that the decision function can be written as <i>f</i>(<i>x</i>) = sign(<i>x</i><sup><i>T</i></sup>&#x003B2;), where &#x003B2; &#x02208; &#x0211D;<sup><i>p</i></sup> is a vector of coefficients to be estimated, one associated to each voxel.</p>
<p class="mb15">The aim of a machine learning algorithm is to find a coefficient vector &#x003B2; able to classify new examples and with specific properties such as sparsity (i.e., few non-zero coefficients) or smoothness. Regularization methods find &#x003B2; by minimizing an objective function consisting of a data fit term <i>E</i>(&#x003B2;) and a penalty term &#x003A9;(&#x003B2;) that favors certain properties and improves the generalization over unseen examples (outside the training set <math><mrow><mi mathvariant="-tex-caligraphic">D</mi></mrow><mrow><mo stretchy="false">)</mo></mrow></math>.</p>
<p class="mb0">As data fitting term we consider the square loss that can be concisely written as</p>
<div class="equationImageholder"><math id="M1"><mi mathsize="10.5pt" mathcolor="black">E</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">m</mi></mrow></mfrac><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mi mathsize="10.5pt" mathcolor="black">X</mi><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">Y</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msubsup><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msubsup></math><div class="clear"></div></div>
<p class="mb0">where <i>X</i> &#x02208; &#x0211D;<sup><i>m</i>&#x000D7;<i>p</i></sup> is the matrix that contains the training examples as rows and <math><mi>Y</mi><mo>=</mo><msup><mrow><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi>y</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>,</mo><mo>&#x02026;</mo><mo>,</mo><msub><mrow><mi>y</mi></mrow><mrow><mi>m</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>T</mi></mrow></msup></math> is the column vector formed by the target variables.</p>
<h3>2.2. Structured Sparsity Models</h3>
<p class="mb0">Note that, since for a linear model each regression coefficient is associated to a voxel, the vector &#x003B2; can also be interpreted as 3D matrix of the same size as the brain scans and we use this 3D structure to define particular penalty functions &#x003B2; &#x021A6; &#x003A9;(&#x003B2;). We define the &#x02113;<sub>1</sub> norm of &#x003B2; as <math><mo>|</mo><mo>|</mo><mi>&#x003B2;</mi><mo>|</mo><msub><mrow><mo>|</mo></mrow><mrow><mn>1</mn></mrow></msub><mo>=</mo><munderover accentunder="false" accent="false"><mrow><mo>&#x02211;</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi></mrow></munderover><mo>|</mo><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></math>; the discrete gradient of &#x003B2; in 3 dimensions as &#x02207;&#x003B2;, with</p>
<div class="equationImageholder"><math id="M2"><mtable columnalign="left"><mtr><mtd><msubsup><mrow><mrow><mo stretchy="false">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02207;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mo stretchy="false">)</mo></mrow></mtd></mtr><mtr><mtd><msubsup><mrow><mrow><mo stretchy="false">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02207;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mo stretchy="false">)</mo></mrow></mtd></mtr><mtr><mtd><msubsup><mrow><mrow><mo stretchy="false">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02207;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">3</mn></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">j</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mi mathsize="10.5pt" mathcolor="black">k</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mo stretchy="false">)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb15">and <math><msubsup><mrow><mrow><mo stretchy="false">(</mo><mrow><mo>&#x02207;</mo><mi>&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mi>&#x02113;</mi></mrow></msubsup><mo>=</mo><mn>0</mn></math> if (<i>i, j, k</i>) is on the boundary w.r.t. the direction &#x02113;. Finally, <math><munder class="msub"><mrow><mo>&#x02211;</mo></mrow><mrow><mi>i</mi><mo>&#x0007E;</mo><mi>j</mi></mrow></munder><msup><mrow><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>-</mo><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>j</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mn>2</mn></mrow></msup></math> means that the sum is only for neighboring voxels <i>i</i> and <i>j</i>.</p>
<p class="mb0">For each method, the model <math><mover accent="true"><mrow><mi>&#x003B2;</mi></mrow><mo>^</mo></mover></math> is estimated by solving the optimization problem</p>
<div class="equationImageholder"><math id="M3"><mtable columnalign="left"><mtr><mtd><mrow><munder><mrow><mi mathsize="10.5pt" mathcolor="black">min</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">&#x02208;</mo><msup><mi mathsize="10.5pt" mathcolor="black">R</mi><mi mathsize="10.5pt" mathcolor="black">p</mi></msup></mrow></munder><mrow><mo mathsize="10.5pt" mathcolor="black">{</mo><mrow><mi mathsize="10.5pt" mathcolor="black">E</mi><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo><mo mathsize="10.5pt" mathcolor="black">+</mo><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">}</mo></mrow></mrow></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">1</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb0">where &#x003A9;(&#x003B2;) is defined as follows.</p>
<h4>2.2.1. Elastic Net (ENET) and LASSO</h4>
<div class="equationImageholder"><math id="M4"><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msub><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub><mo mathsize="10.5pt" mathcolor="black">&#43;</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msub><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msubsup><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black">.</mo></math><div class="clear"></div></div>
<p class="mb0">This regularizer entails a tradeoff between variable selection and coefficient shrinkage. For &#x003BB;<sub>2</sub> = 0, we obtain the LASSO, while &#x003BB;<sub>2</sub> &#x02260; 0 allows for correlated features to be selected together. Notice also that unlike the structured sparsity regularizers described below, the location of the non-zero components is not constrained in any manner.</p>
<h4>2.2.2. Total Variation (TV)</h4>
<div class="equationImageholder"><math id="M5"><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">&#x02207;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msub><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub><mo mathsize="10.5pt" mathcolor="black">.</mo></math><div class="clear"></div></div>
<p class="mb0">This regularizer favors solutions that have constant value in contiguous regions and has its origins in image de-noising applications (<a href="#B33">Rudin et al., 1992</a>), however it does not enforce any coefficient to be exactly zero.</p>
<h4>2.2.3. Sparse Total Variation (STV)</h4>
<div class="equationImageholder"><math id="M6"><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi><mrow><mo mathsize="10.5pt" mathcolor="black">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">&#x02207;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msub><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub><mo mathsize="10.5pt" mathcolor="black">&#43;</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msub><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub></mrow><mo mathsize="10.5pt" mathcolor="black">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">.</mo></math><div class="clear"></div></div>
<p class="mb0">By adding a &#x02113;<sub>1</sub>-penalty term to the Total Variation functional, this regularize favors solutions whose coefficients are constant within contiguous regions, but also promotes sparsity. This hybrid method has been proposed in other domains, such as image de-noising using Fourier or wavelet representations (see e.g., <a href="#B23">Ma et al., 2008</a>) and was applied to brain decoding in our previous work (<a href="#B4">Baldassarre et al., 2012b</a>). Notice also that (Sparse) Total Variation reduces to a fused Lasso in 3D space (<a href="#B9">Dohmatob et al., 2014</a>).</p>
<h4>2.2.4. Laplacian (LAP)</h4>
<div class="equationImageholder"><math id="M7"><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></mfrac><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi><mstyle displaystyle="true"><munder class="msub"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">&#x0007E;</mo><mi mathsize="10.5pt" mathcolor="black">j</mi></mrow></munder></mstyle><msup><mrow><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black">-</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">j</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msup><mo mathsize="10.5pt" mathcolor="black">.</mo></math><div class="clear"></div></div>
<p class="mb0">This regularizer relaxes the constancy requirement of the Total Variation method, allowing for smooth variations within regions. It is called &#x0201C;Laplacian&#x0201D; since the regularizer can be rewritten as <math><munderover accentunder="false" accent="false"><mrow><mo>&#x02211;</mo></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi></mrow></munderover><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>i</mi></mrow></msub><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>j</mi></mrow></msub><msub><mrow><mi>L</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></math>, where the matrix <i>L</i> is the Laplacian associated to a 3D grid graph modeling neighboring voxels.</p>
<h4>2.2.5. Sparse Laplacian (SLAP)</h4>
<div class="equationImageholder"><math id="M8"><mi mathsize="10.5pt" mathcolor="black">&#x003A9;</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></mfrac><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi><mrow><mo stretchy="false">(</mo><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B1;</mi></mrow><mo stretchy="false">)</mo></mrow><mstyle displaystyle="true"><munder class="msub"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">&#x0007E;</mo><mi mathsize="10.5pt" mathcolor="black">j</mi></mrow></munder></mstyle><msup><mrow><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black">-</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">j</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">2</mn></mrow></msup><mo mathsize="10.5pt" mathcolor="black">&#43;</mo><mi mathsize="10.5pt" mathcolor="black">&#x003BB;</mi><mi mathsize="10.5pt" mathcolor="black">&#x003B1;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><mo mathsize="10.5pt" mathcolor="black">|</mo><mi mathsize="10.5pt" mathcolor="black">&#x003B2;</mi><mo mathsize="10.5pt" mathcolor="black">|</mo><msub><mrow><mo mathsize="10.5pt" mathcolor="black">|</mo></mrow><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow></msub></math><div class="clear"></div></div>
<p class="mb0">where &#x003B1; &#x02208; [0, 1]. This regularizer encourages both smooth variations within regions and sparsity of the regression vector. The corresponding method is similar to GraphNET (<a href="#B15">Grosenick et al., 2011</a>), with &#x003BB;<sub>1</sub> = &#x003BB;&#x003B1; and &#x003BB;<sub><i>G</i></sub> = &#x003BB;(1 &#x02212; &#x003B1;). Note also that LAP corresponds to the special case that &#x003B1; = 0. In all cases, &#x003BB; and &#x003B1; are hyper-parameters (often referred to as regularization parameters) that control the trade-off between the data fitting term, typically measured by classification accuracy, and the degree of regularization, which measures the parsimony (sparsity) of the model. These hyper-parameters must be chosen in an unbiased way during learning. The numerical algorithm employed to solve the optimization problem (Equation 1) is outlined in Appendix 1 (Supplementary Material).</p>
<h3>2.3. Experimental Protocol and Assessment</h3>
<p class="mb15">In this section we present details about the experimental protocol used, including criteria for model selection and measures used to assess the performance of the different methods.</p>
<p class="mb0">Our aim is to provide a consistent and unbiased procedure in order to best compare different supervised learning methods that goes beyond the simple prediction accuracy performance measure. For this purpose, we introduce two measures of model reproducibility/stability and study their impact for model selection and model assessment.</p>
<h4>2.3.1. Nested Cross-Validation</h4>
<p class="mb0">We perform two nested loops of Leave-One-Subject-Out Cross-Validation (LOSO-CV). The external loop is used for assessing the classification accuracy, the sparsity and the stability of the methods; the internal loop is used for selecting the hyper-parameter(s) in each method (e.g., &#x003BB;<sub>1</sub> and &#x003BB;<sub>2</sub> for Elastic Net). Hence, for each method, we train <i>N</i> different models, where <i>N</i> is the number of subjects in the dataset. Note that each subject has many examples of each class, therefore the LOSO-CV used in the present work does not correspond to the commonly used Leave-One-Out Cross-Validation (LOO-CV) procedure, where only one example is left for test in each cross-validation fold.</p>
<h4>2.3.2. Thresholding</h4>
<p class="mb0">Although the sparse methods should yield sparse coefficient vectors, due to numerical approximations during optimization some of the estimated coefficients might not have been set exactly to zero. Therefore, we adopt the heuristic of setting to zero the smallest components of the regression vector which contribute to only 0.01% to the ||&#x003B2;||<sub>1</sub>. Specifically we reorder the components of &#x003B2; so that |&#x003B2;<sub>1</sub>| &#x02265; |&#x003B2;<sub>2</sub>| &#x02265; &#x022EF; &#x02265; |&#x003B2;<sub><i>p</i></sub>|, choose the smallest integer <i>r</i> such <math><munderover accentunder="false" accent="false"><mrow><mo>&#x02211;</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>r</mi></mrow></munderover><mo>|</mo><msub><mrow><mi>&#x003B2;</mi></mrow><mrow><mi>k</mi></mrow></msub><mo>|</mo><mo>&#x02265;</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>-</mo><mn>1</mn><msup><mrow><mn>0</mn></mrow><mrow><mo>-</mo><mn>4</mn></mrow></msup></mrow><mo stretchy="false">)</mo></mrow><mo>|</mo><mo>|</mo><mi>&#x003B2;</mi><mo>|</mo><msub><mrow><mo>|</mo></mrow><mrow><mn>1</mn></mrow></msub></math> and set to zero the components &#x003B2;<sub><i>r</i>&#43;1</sub>, &#x02026;, &#x003B2;<sub><i>p</i></sub>.</p>
<h4>2.3.3. Performance Measures</h4>
<p class="mb0">Let &#x003B2;(<i>s</i>) (the <i>signature</i>) be the coefficient vector estimated when the data for subject <i>s</i> is left out for testing. We define the model or signature support <i>I</i><sub><i>s</i></sub>: = {<i>i</i> | &#x003B2;(<i>s</i>)<sub><i>i</i></sub> &#x02260; 0} the index set of the locations of the non-zero coefficients (or sparsity pattern), the model <i>sparsity</i> <math><mi>S</mi><mrow><mo stretchy="false">(</mo><mrow><mi>s</mi></mrow><mo stretchy="false">)</mo></mrow><mo>:</mo><mo>=</mo><mfrac><mrow><mo>|</mo><msub><mrow><mi>I</mi></mrow><mrow><mi>s</mi></mrow></msub><mo>|</mo></mrow><mrow><mi>p</mi></mrow></mfrac></math> as the relative number of non-zero coefficients and the <i>pairwise relative overlap</i> as</p>
<div class="equationImageholder"><math id="M9"><msub><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow></msub><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black">&#x02229;</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow></msub><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo></mrow><mrow><mo class="qopname">max</mo><mrow><mo stretchy="false">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><mo mathsize="10.5pt" mathcolor="black">,</mo><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msubsup><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo mathsize="10.5pt" mathcolor="black">.</mo></math><div class="clear"></div></div>
<p class="mb15">We then define the <i>corrected pairwise relative overlap</i> as</p>
<div class="equationImageholder"><math id="M10"><msubsup><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">c</mi></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black">&#x02229;</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow></msub><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><mo mathsize="10.5pt" mathcolor="black">-</mo><mi mathsize="10.5pt" mathcolor="black">E</mi></mrow><mrow><mo class="qopname">max</mo><mrow><mo stretchy="false">(</mo><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><mo mathsize="10.5pt" mathcolor="black">,</mo><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo><msubsup><mrow><mi mathsize="10.5pt" mathcolor="black">I</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></msubsup><mo mathsize="10.5pt" mathcolor="black" stretchy="false">|</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo mathsize="10.5pt" mathcolor="black">,</mo></math><div class="clear"></div></div>
<p class="mb15">where <i>E</i> is the expected overlap between the support of two random vectors with sparsity <i>S</i>(<i>s</i>) and <i>S</i>(<i>s</i>&#x02032;), respectively, given by the formula<sup id="footnotesuper2"><a id="note2a"></a><a class="footnoteanchor" href="#note2">2</a></sup></p>
<div class="equationImageholder"><math id="M11"><mtable columnalign="left"><mtr><mtd><mi mathsize="10.5pt" mathcolor="black">E</mi><mo mathsize="10.5pt" mathcolor="black">=</mo><mi mathsize="10.5pt" mathcolor="black">p</mi><mi mathsize="10.5pt" mathcolor="black">S</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mo stretchy="false">)</mo></mrow><mi mathsize="10.5pt" mathcolor="black">S</mi><mrow><mo stretchy="false">(</mo><mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">.</mo></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">2</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb15">The correction term <i>E</i> compensates the fact that the pairwise relative overlap increases with the size of the sparsity pattern of the models, see <a href="#B31">Rasmussen et al. (2012)</a> for a discussion; note also that in that paper model sparsity is defined as the number of non-zero coefficients.</p>
<p class="mb0">Next we define the <strong>average pairwise overlap</strong></p>
<div class="equationImageholder"><math id="M12"><mtable columnalign="left"><mtr><mtd><mover accent="false" class="mml-overline"><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mo accent="true">&#x000AF;</mo></mover><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munderover accentunder="false" accent="false"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">&#x02260;</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow><mo mathsize="10.5pt" mathcolor="black">=</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi></mrow></munderover></mstyle><msub><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow></msub></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">3</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb15">and the <strong>average corrected pairwise overlap</strong></p>
<div class="equationImageholder"><math id="M13"><mtable columnalign="left"><mtr><mtd><msup><mrow><mover accent="false" class="mml-overline"><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mo accent="true">&#x000AF;</mo></mover></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">c</mi></mrow></msup><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munderover accentunder="false" accent="false"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">&#x02260;</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow><mo mathsize="10.5pt" mathcolor="black">=</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi></mrow></munderover></mstyle><msubsup><mrow><mi mathsize="10.5pt" mathcolor="black">O</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">c</mi></mrow></msubsup></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">4</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb15">as measures of <i>stability</i> and <i>corrected stability</i>, respectively.</p>
<p class="mb0">As a further measure of stability we also use the <strong>average pairwise correlation</strong> defined as</p>
<div class="equationImageholder"><math id="M14"><mtable columnalign="left"><mtr><mtd><mover accent="false" class="mml-overline"><mrow><mi mathsize="10.5pt" mathcolor="black">C</mi></mrow><mo accent="true">&#x000AF;</mo></mover><mo mathsize="10.5pt" mathcolor="black">:</mo><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mrow><mo stretchy="false">(</mo><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi><mo mathsize="10.5pt" mathcolor="black">-</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munderover accentunder="false" accent="false"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">&#x02260;</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow><mo mathsize="10.5pt" mathcolor="black">=</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi></mrow></munderover></mstyle><msub><mrow><mi mathsize="10.5pt" mathcolor="black">C</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">,</mo><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">&#x02032;</mi></mrow></mrow></msub><mo mathsize="10.5pt" mathcolor="black">,</mo></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">5</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb15">where <i>C</i>(<i>s, s</i>&#x02032;) is the sample Pearson&#x00027;s correlation between &#x003B2;(<i>s</i>) and &#x003B2;(<i>s</i>&#x02032;).</p>
<p class="mb0">The <strong>accuracy</strong> of a method is the average percentage of correctly classified examples over all the LOSO folds, namely</p>
<div class="equationImageholder"><math id="M15"><mtable columnalign="left"><mtr><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext class="textrm" mathvariant="normal">Accuracy</mtext></mstyle><mo mathsize="10.5pt" mathcolor="black">=</mo><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi></mrow></mfrac><mstyle displaystyle="true"><munderover accentunder="false" accent="false"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi><mo mathsize="10.5pt" mathcolor="black">=</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">N</mi></mrow></munderover></mstyle><mfrac><mrow><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">m</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub></mrow></mfrac><mstyle displaystyle="true"><munderover accentunder="false" accent="false"><mrow><mo mathsize="10.5pt" mathcolor="black">&#x02211;</mo></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi><mo mathsize="10.5pt" mathcolor="black">=</mo><mn mathsize="10.5pt" mathcolor="black">1</mn></mrow><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">m</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub></mrow></munderover></mstyle><mi mathsize="10.5pt" mathcolor="black">&#x003B4;</mi><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">f</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">s</mi></mrow></msub><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi mathsize="10.5pt" mathcolor="black">x</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow><mo mathsize="10.5pt" mathcolor="black">=</mo><msub><mrow><mi mathsize="10.5pt" mathcolor="black">y</mi></mrow><mrow><mi mathsize="10.5pt" mathcolor="black">i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mtd><mtd><mstyle class="text" mathsize="10.5pt" mathcolor="black"><mtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;</mtext></mstyle><mrow><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>(</mo><mn mathsize="10.5pt" mathcolor="black">6</mn><mo mathsize="10.5pt" mathcolor="black" stretchy='false'>)</mo></mrow></mtd></mtr></mtable></math><div class="clear"></div></div>
<p class="mb0">where <math><msub><mrow><mi>f</mi></mrow><mrow><mi>s</mi></mrow></msub><mrow><mo stretchy="false">(</mo><mrow><msub><mrow><mi>x</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow><mo>=</mo><mstyle class="text"><mtext class="textrm" mathvariant="normal">sign</mtext></mstyle><mrow><mo stretchy="false">(</mo><mrow><mi>&#x003B2;</mi><msup><mrow><mrow><mo stretchy="false">(</mo><mrow><mi>s</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>T</mi></mrow></msup><msub><mrow><mi>x</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></math> and <i>m</i><sub><i>s</i></sub> is the number of examples for subject <i>s</i>.</p>
<h3>2.4. Model Selection</h3>
<p class="mb15">Since we are interested in evaluating methods not only according to classification accuracy, but also with respect to measures of reproducibility/stability such as correlation and corrected overlap, it behooves us to consider these measures also during model selection. Obviously, the stability measures by themselves cannot directly be used for model selection, because selecting the model&#x00027;s hyper-parameters that only maximize stability will yield highly biased models that do not actually learn from data. For instance, a model with just one constant non-zero coefficient will maximize both correlation and corrected overlap, but won&#x00027;t be able to accurately predict.</p>
<p class="mb0">Henceforth, adopting and extending the procedure proposed by <a href="#B31">Rasmussen et al. (2012)</a>, we consider both prediction accuracy and either correlation or corrected overlap simultaneously<sup id="footnotesuper3"><a id="note3a"></a><a class="footnoteanchor" href="#note3">3</a></sup>. We can use a diagram to visualize the dependency between accuracy and one of the stability measures: by varying the model&#x00027;s hyper-parameters values we obtain different points on this diagram. Ideally, we would like to find the values that yield exactly the point (1, 1), that is perfect accuracy and perfect stability. However, since this hardly happens in practice, we are satisfied with the hyper-parameters values that yield the point closest (with respect to the Euclidean distance) to (1, 1) in either the accuracy vs. correlation or accuracy vs. corrected overlap diagrams. An example of these diagram is reported in Figure <a href="#F1">1</a> for the LASSO.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">FIGURE 1</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" name="figure1" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg" alt="www.frontiersin.org" id="F1" loading="lazy">
  </picture>
</a>
<p><strong>Figure 1. Mean accuracy vs. mean corrected overlap (left)</strong> and mean accuracy vs. mean correlation <strong>(right)</strong> for the first external LOSO fold for the LASSO model. The curves are obtained by varying the regularization parameter and computing the measures across the internal LOSO folds.</p></div>
<div class="clear"></div>
<div class="DottedLine mb15"></div>
<p class="mb15">Summarizing, we consider three model selection criteria:</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left">1. <strong>Accuracy-based</strong>. The model hyper-parameters are selected to maximize the classification accuracy over the internal LOSO-CV.</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left">2. <strong>Corrected overlap based</strong>. The hyper-parameters are selected in order to minimize the distance to (1, 1) in the mean accuracy vs. mean corrected overlap diagram. Note that this criteria was only applied to the sparse methods (LASSO, ENET, STV, and SLAP).</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left">3. <strong>Correlation-based</strong>. The hyper-parameters are selected in order to minimize the distance to (1, 1) in the mean accuracy vs. mean correlation diagram.</p>
<h3>2.5. Multi-Measure Assessment</h3>
<p class="mb0">The accuracy vs. stability diagrams introduced in the previous section for model selection can also be used for model assessment. In fact, when training a model and selecting its hyper-parameters in order to maximize both accuracy and stability, it is appropriate to compare its performance to other methods with respect to the same criterion used for model selection. In this case, each method yields a single point in the accuracy vs. stability diagram and we can both visually assess the differences in the methods&#x02014;which is the most accurate, which is the most stable and which obtains the best balance between accuracy and stability&#x02014;but also quantitatively compute their distances to the ideal (1, 1) point. In Figure <a href="#F2">2</a> we use these diagrams to visualize the performance of the various methods on the dataset considered in this paper.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">FIGURE 2</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" name="figure2" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg" alt="www.frontiersin.org" id="F2" loading="lazy">
  </picture>
</a>
<p><strong>Figure 2. Summary results for different models when the model selection criteria Acc/Corr and Acc/OC are employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<h3>2.6. Dataset</h3>
<p class="mb15">We used fMRI data from 16 male healthy US college students (age 20&#x02013;25) (<a href="#B28">Mourao-Miranda et al., 2006</a>, <a href="#B27">2007</a>; <a href="#B16">Hardoon et al., 2007</a>). Participants did not have any history of neurological or psychiatric illness, had normal vision and had given written informed consent to participate in the study after the study was explained to them.</p>
<p class="mb0">The fMRI data were acquired on a 3T Allegra Head-only MRI system, using a T2* sequence with 43 axial slices (slice thickness, 3 mm; gap between slices, 0 mm; <i>TR</i> = 3 s; <i>TE</i> = 30 ms; <i>FA</i> = 80&#x000B0;; FOV = 192 &#x000D7; 192 mm; matrix, 64 &#x000D7; 64; voxel dimensions, 3 &#x000D7; 3 &#x000D7; 3 mm).</p>
<h4>2.6.1. fMRI Experimental Design</h4>
<p class="mb0">There were three different active conditions: viewing unpleasant (dermatological diseases), neutral (people) and pleasant images (pretty girls in swimsuits), and a control condition (fixation). In each run, there were 6 blocks of the active condition (each consisting of 7 brain scans) alternating with control blocks (fixation) of 7 brain scans. The six blocks of each of the 3 stimuli were presented in random order. Here we focus the analyses on two active conditions: viewing unpleasant and pleasant images. The fMRI scans acquired during the pleasant and unpleasant conditions (considering an hemodynamic delay of 3 s) defined the input patterns.</p>
<h4>2.6.2. Preprocessing</h4>
<p class="mb0">The data were pre-processed using SPM2<sup id="footnotesuper4"><a id="note4a"></a><a class="footnoteanchor" href="#note4">4</a></sup>. All the scans were realigned to remove residual motion effects and transformed into standard space (<a href="#B37">Talairach and Tournoux, 1988</a>). The data were de-trended and smoothed in space using an 8 mm Gaussian filter. Finally, a mask was applied to select voxels that have probability 0.5 or higher of being located in gray matter. This operation nearly halves the number of voxels from 219, 727 to 122, 128. The preprocessed dataset consists of 1344 scans of size 122, 128 voxels, with 42 scans per subject per active condition.</p>
<h3>2.7. Summarization of the Coefficient Maps</h3>
<p class="mb0">In order to summarize the coefficient maps for the sparse methods (LASSO, ENET, STV and SLAP) we listed the clusters according to their extension using the script 3dclust from AFNI (<a href="https://afni.nimh.nih.gov/afni/">https://afni.nimh.nih.gov/afni/</a>) and found the brain regions correspondent to the maximum coefficient within each cluster using the software Talairach Daemon (<a href="http://www.talairach.org/daemon.html">http://www.talairach.org/daemon.html</a>).</p>
<a id="h4" name="h4"></a><h2>3. Results</h2>
<p class="mb15">In this section, we describe the experimental results obtained applying the different sparsity regularization methods as well as non sparse ones to decode the mental state (i.e., viewing pleasant or unpleasant images) of the subject left out of the LOSO-CV as described in the methods section. The Matlab code one may use to reproduce our results is available at <a href="https://github.com/lucabaldassarre/neurosparse">https://github.com/lucabaldassarre/neurosparse</a>.</p>
<p class="mb15">The main aim of the experiments is to compare three different model selection criteria: (i) classification accuracy, (ii) classification accuracy and overlap between the solutions, (iii) classification accuracy and correlation between the solutions; and investigate their impact on the different performance measures: <i>Accuracy, Sparsity, Correlation, Overlap</i>, and <i>Corrected Overlap (OC)</i>. As we noted in the previous section, the last three quantities are stability/reproducibility measures which indicate the extent to which maps of coefficients or sparsity patterns associated with a learning method are stable across LOSO-CV folds and hence reproducible.</p>
<p class="mb0">Table <a href="#T1">1</a> reports the average and standard deviation for the five performance measures computed on the external LOSO-CV (test error) of each learning method and model selection criterion. Each row in the table refers to one learning method trained with one of the three model selection criteria: &#x0201C;Acc,&#x0201D; &#x0201C;Acc/OC,&#x0201D; and &#x0201C;Acc/Corr.&#x0201D; For example, in the table,&#x0201C;LASSO - Acc&#x0201D; means that we run LASSO and selected its regularization parameter according to best accuracy, whereas &#x0201C;LASSO - Acc/OC&#x0201D; means that we run LASSO and selected the regularization parameter which minimizes the distance in the Accuracy/Corrected Overlap diagram. Likewise, &#x0201C;LASSO - Acc/Corr&#x0201D; means that we run LASSO and selected the regularization parameter which minimizes the distance in the Accuracy/Correlation diagram. As expected when test performance is measured according to accuracy, the most effective model selection criterion is accuracy itself. Similarly, when test performance accounts for correlation or corrected overlap, the best performance tends to be obtained by using Acc/Correlation or Acc/OC as the model selection criterion, respectively. In Figure <a href="#F1">1</a>, we show an example of &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; and of &#x0201C;Mean Accuracy vs. Mean Correlation&#x0201D; plot for the LASSO model trained for the first external LOSO fold. Note that for each learning method, there is significant discrepancy between the different optimization criteria used.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">TABLE 1</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" name="Table1" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg" alt="www.frontiersin.org" id="T1" loading="lazy">
  </picture>
</a>
<p><strong>Table 1. Model performance</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<p class="mb15 w100pc float_left mt15">One interesting observation from Table <a href="#T1">1</a> is the fact that using accuracy and stability (measured by OC) as a joint criterion for model selection leads to solutions that are more similar across different sparsity models in terms of accuracy, sparsity levels and corrected overlap, with respect to using only accuracy as optimization criterion. For example, when using the criterion Acc/OC the accuracy across different sparsity models varies from 81.03% (STV) to 84.08% (E-NET), the sparsity varies from 0.25 (LASSO) to 3 (E-NET) and the corrected overlap (OC) varies from 52 (SLAP) to 82 (E-NET). These variations are much smaller than the ones observed for model selection based on accuracy only. In this case the accuracy varies from 83.71% (LAP) to 88.02% (E-NET), the sparsity varies from 0.64 (LASSO) to 84.14 (E-NET) and the corrected overlap (OC) varies from 2 (E-NET) to 35 (SLAP). Interestingly, when using the criterion Acc/Corr this effect is not observed.</p>
<p class="mb15">In Figure <a href="#F2">2</a>, we present the results for the different methods in the planes &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; and &#x0201C;Mean Accuracy vs. Mean Correlation.&#x0201D; Overall the best performing method is the Elastic Net, achieving an average accuracy of over 84% when the model selection criterion Acc/OC is employed, yielding at the same time a highly stable sparsity pattern. The LASSO gives the most sparse coefficient vectors (maps), however these are less stable than those obtained by Elastic Net.</p>
<p class="mb0">Figures <a href="#F3">3</a>&#x02013;<a href="#F5">5</a> show the coefficient maps for the different methods and different optimization criteria (averaged across the external LOSO folds). Figure <a href="#F3">3</a> shows the coefficient maps when accuracy was employed as a model selection criterion. It is possible to notice that the coefficient maps present very different levels of sparsity and smoothness even though the accuracy for the different methods varies less than 5% (from 83.71 to 88.02%). These results illustrate the effect of different sparsity constraints on the coefficient maps. As expected the LASSO solution is extremely sparse regardless of the model selection criterion. The coefficient maps for ENET are not sparse and show a smooth variation over the voxels/regions. Not surprisingly, the coefficient maps for Total Variation (TV) and Laplacian (LAP) methods led to non-sparse solutions, however the TV coefficients show large regions with constant values while the LAP coefficients show a smooth variation across the brain voxels/regions, presenting a similar pattern as the ENET. Finally, the coefficient maps for Sparse Total Variation (STV) and Sparse Laplacian (SLAP) are sparser versions of the TV and LAP. Including correlation across the LOSO solutions as an additional model selection criterion leads to coefficient maps similar to the ones obtained using only accuracy (Figure <a href="#F4">4</a>), with STV showing a pattern similar to TV.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">FIGURE 3</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" name="figure3" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg" alt="www.frontiersin.org" id="F3" loading="lazy">
  </picture>
</a>
<p><strong>Figure 3. Coefficient maps for different models when the model selection criterion Acc is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine mb15"></div>
<div class="Imageheaders">FIGURE 4</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" name="figure4" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg" alt="www.frontiersin.org" id="F4" loading="lazy">
  </picture>
</a>
<p><strong>Figure 4. Coefficient maps for different models when the model selection criterion ACC/Corr is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<p class="mt15 w100pc float_left">In Figure <a href="#F5">5</a>, we can see the coefficient maps when accuracy and corrected overlap (OC) were employed as model selection criteria for the sparse methods (LASSO, ENET, STV, and SLAP). It is interesting to see that in this case all maps became very similar both in terms of sparsity and smoothness. In all cases the coefficient maps are very sparse with well localized clusters and peaks. Overall, the Acc/OC model selection criterion seems to lead to solutions that are the most sparse and stable (according to the overlap and corrected overlap measures), while the observed decrease in accuracy performance is not significant (according to the Welch&#x00027;s <i>t</i>-test).</p>
<div class="DottedLine"></div>
<div class="Imageheaders">FIGURE 5</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" name="figure5" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg" alt="www.frontiersin.org" id="F5" loading="lazy">
  </picture>
</a>
<p><strong>Figure 5. Coefficient maps for different sparse models when the model selection criterion Acc/OC is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<p class="mt15 w100pc float_left">In order to illustrate the impact of the model selection criteria on the stability of the coefficients across folds, in Figure <a href="#F6">6</a> we present the coefficient maps for the first and second LOSO folds for the STV method using the different model section criteria. As we can see there is a lot of variation between the coefficients when the regularization parameters are selected according to accuracy, whereas when distance in the &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; diagram is used the coefficients become very similar which indicates that the solutions become more reproducible/stable.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">FIGURE 6</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" name="figure6" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg" alt="www.frontiersin.org" id="F6" loading="lazy">
  </picture>
</a>
<p><strong>Figure 6. Coefficient maps for the first two LOSO folds for the STV method using different model selection criteria (Accuracy, Accuracy and Correlation, Accuracy and Corrected Overlap)</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<p class="mt15 w100pc float_left">A more objective description of the coefficient maps is provided in Tables <a href="#T2">2</a>&#x02013;<a href="#T4">4</a> with a list of the five top clusters found by each method and each model selection criterion. This description was not done for the non sparse approaches as in this case all voxels within the image are included in a single cluster. The Tables show the total number of clusters found and the brain regions (including the corresponding Brodman Area - BA) corresponding to the five top clusters ranked according to the maximum coefficient within the cluster. It is possible to see that although different methods find very different numbers of clusters depending on the sparsity constraint and model selection criteria, there is a good agreement between the main clusters found by the different methods. In particular when the optimization criteria Acc/OC was used the different sparse methods (LASSO, ENET, STV, and SLAP) identified the same regions (Table <a href="#T4">4</a>), with some differences in the ranking order. As expected, considering the fMRI experimental task (visualization of pleasant or unpleasant pictures), the main clusters include visual areas (e.g., left and right middle occipital gyrus), areas often associated with emotional processing (e.g., right medial frontal gyrus, right anterior cingulate) and cerebellum (left cummen). A visual inspection of the non-sparse approaches shows that their peaks are also in similar regions selected by the sparse approaches.</p>
<div class="DottedLine"></div>
<div class="Imageheaders">TABLE 2</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" name="Table2" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg" alt="www.frontiersin.org" id="T2" loading="lazy">
  </picture>
</a>
<p><strong>Table 2. List of clusters for sparse methods when the model selection criterion Acc is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine mb15"></div>
<div class="Imageheaders">TABLE 3</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" name="Table3" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg" alt="www.frontiersin.org" id="T3" loading="lazy">
  </picture>
</a>
<p><strong>Table 3. List of clusters for sparse methods when the model selection criterion Acc/Corr is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine mb15"></div>
<div class="Imageheaders">TABLE 4</div>
<div class="FigureDesc">
<a href="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" name="Table4" target="_blank">

  <picture>
    <source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" media="(max-width: 563px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" media="(max-width: 1024px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" media="(max-width: 1441px)"><source type="image/webp" srcset="https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" media=""><source type="image/jpg" srcset="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" media=""> <img src="https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg" alt="www.frontiersin.org" id="T4" loading="lazy">
  </picture>
</a>
<p><strong>Table 4. List of clusters for sparse methods when the model selection criterion Acc/OC is employed</strong>.</p></div>
<div class="clear"></div>
<div class="DottedLine"></div>
<a id="h5" name="h5"></a><h2>4. Discussion</h2>
<p class="mb15">During the last years there has been a huge increase in the application of machine learning methods to analyse neuroimaging data (see <a href="#B29">Pereira et al., 2009</a>; <a href="#B17">Haynes, 2015</a>, and references therein), varying from neuroscience applications for decoding mental or cognitive states (e.g., <a href="#B30">Polyn et al., 2005</a>; <a href="#B28">Mourao-Miranda et al., 2006</a>; <a href="#B18">Haynes et al., 2007</a>; <a href="#B34">Schrouff et al., 2012</a>) to clinical applications for diagnoses and prognoses (e.g., <a href="#B22">Kloppel et al., 2012</a>). Despite their inherent ability to deal with multivariate data and their predictive framework which enables decisions at the single subject level, one of their main limitations is the interpretability issue. For linear machine learning models, the vector of coefficients (also known as weight vector) can be plotted and visualized as a brain image showing the contribution of each voxel in the image to the decision function. The main issue is that, for non sparse approaches (e.g., Kernel Ridge Regression, Support Vector Machines) all voxels within the image will have some contribution to the decision function, making it difficult to decide which voxels contribute the most. A number of approaches have been proposed to ease the interpretability issue, such as feature selection (e.g., Martino et al., 2008; Langs et al., 2011; Rondina et al., 2014), searchlight (Kriegeskorte et al., 2006) and sparse models (see references in the introduction). Sparsity has often been advocated as a proxy for interpretability, however sparsity can be imposed by very different penalties or constraints which should be related to prior knowledge about the problem considered.</p>
<p class="mb15">Our previous work (<a href="#B4">Baldassarre et al., 2012b</a>) showed that different sparsity constraints can lead to similar performance in terms of accuracy, but the resulting models differ in term of sparsity and stability. In the present work, we investigated the impact of the model selection criteria (parameter optimization criteria) on models with different sparsity penalties. Our results show that having a second criterion (in addition to accuracy) for model selection improves the stability/reproducibility (measured by OC or correlation across LOSO solutions) of the sparse models, i.e., the instability of the sparse models decreases by including reproducibility as an additional model selection criterion.</p>
<p class="mb15">When trying to interpret brain maps resulting from sparse models it is important to have in mind that the properties of the maps, such as sparsity and smoothness, are strongly driven by the choice of the penalty term in the objective function. The effect of the chosen penalty on the map of coefficients can be clearly seen in Figure <a href="#F3">3</a>. It is possible to observe that when accuracy is used for model selection, methods with different penalties can have similar performance and very different coefficient maps. However, when reproducibility (measured by OC) is used in addition to accuracy for models selection, the solutions or maps became more similar even across the different sparse methods (Figure <a href="#F5">5</a>). Interestingly the same effect is not observed when reproducibility (measured by correlation) is used as additional model selection criterion (Figure <a href="#F4">4</a>). One possible explanation for the difference observed on the results when using OC or correlation representing stability is the fact that correlation is significantly affected, i.e., reduced, by differences in models&#x00027; supports. Therefore, correlation between models can be very high when the models are both very sparse or both very dense, leading to choosing such models during model selection, as evidenced by Figure <a href="#F4">4</a>. We also noticed that the criteria Acc/OC tended to select higher sparsity regularization parameters, because corrected overlap (due to its correction term) favors highly overlapping, but not dense models. This might explain the reason why the models using the criteria Acc/OC are very sparse (Figure <a href="#F5">5</a>). Although a sparse solution seems the most stable for the considered data set, the sparsity of the learned solution is likely to be dataset dependent. Different fMRI datasets might have different levels of sparsity depending on the cognitive task. If a cognitive task only engages a very small network of few regions, then very sparse solutions will probably show the best performance in terms of accuracy and stability. On the other hand, if a cognitive task engages a large network, then less sparse solutions will probably lead to best overall performance. The stability or reproducibility of the model is also an important aspect to be considered for the interpretation as sparsity in itself can produce highly unstable models. Figure <a href="#F6">6</a> illustrates the impact of including reproducibility as a second criterion for model selection for STV. The STV solutions for two different cross validations folds of the LOSO are extremely different when accuracy is used for model selection and become much more similar/stable when correlation or OC is included as a second criterion for model selection.</p>
<p class="mb15">If we compare the clusters&#x00027; location for different sparse methods it is interesting to observe that the solutions of LASSO, ENET, STV, and SLAP include basically the same top five regions (with some differences in the ranking order) when accuracy and OC are used as model selection criteria. The top clusters include left middle occipital gyrus (BA 37), right middle occipital gyrus (BA19), left culmen, right middle frontal gyrus (BA 11/10), and right anterior cingulate (BA 24). The fist two regions are known to be involved in visual processing (e.g., <a href="#B40">Wandell et al., 2007</a>) and the last two have been associated with emotional processing (e.g., <a href="#B11">Etkin et. al., 2011</a>). The involvement of these regions would be expected in the problem considered, i.e., decoding visualization of emotional pictures.</p>
<p class="mb15">The potential gains of unstructured vs. structured sparse models for neuroimaging applications will depend on how well the model assumptions (or sparsity penalty) agree with the data structure. Structured sparse models can incorporate more prior knowledge about the data structure and therefore can potentially lead to models with higher performance. However, since neuroimage data, in general, has very high dimensionality and complex structure it is not certain that structured sparse models will have the highest performance when compared with other types of sparsity, as was the case in the present work. Among the penalties considered in the present work, the SLAP penalty seems closer to our beliefs about how the brain works, i.e., the brain is organized in regions and the activities within these regions are expected to vary smoothly. Nevertheless, ENET presented the best performance in terms of accuracy and reproducibility. Our results show that SLAP can lead to very noisy maps with hundreds of cluster, many of them being very small and more likely to be related to noise than brain activity. One difficulty to choose the optimal penalty is the lack of an absolute ground truth in terms of informative or predictive regions in the brain, making it difficult to define an objective criterion for model comparison. Some studies have used results from mass univariate statistical tests between the classes (e.g., <i>t</i>-test) as a proxy for the ground truth, however such tests would fail to capture multivariate properties (e.g., subtle differences observed when a set of voxels is considered jointly). Here we investigate the use of two criteria for model selection, decoding accuracy and stability/reproducibility (measured by OC or correlation across LOSO folds). Although these criteria do not embed a metric of distance to the ground truth solution, the combination of decoding accuracy and overlap between the solutions leads to similar solutions across different learning methods.</p>
<p class="mb15"><a href="#B31">Rasmussen et al. (2012)</a> have previously investigated the impact of choices of model regularization parameters on the generalization and the stability/reproducibility of spatial patterns extracted from classification models in neuroimaging. The authors evaluate the models using the NPAIRS resampling scheme (i.e., half-splits resamples <a href="#B35">Strother et al., 2002</a>) and constructed performance-vs.-reproducibility curves (pr-curves) for three classifiers: Support Vector Machine, Fisher Discriminant Analyses and Logistic Regression. For each classifier type, they compared the models that optimized the prediction accuracy, joint prediction accuracy and reproducibility (measured by Pearson correlation coefficient between the models&#x00027; coefficients), and only reproducibility. The authors observed a trade-off between prediction accuracy and reproducibility and argued that regularization parameters must be selected to balance this trade-off in order to provide a more accurate representation of the underlying brain networks. They also investigated how performance and stability/reproducibility (measured by overlap and mutual information between the solution) varied for the logistic regression with ENET penalty as function of the regularization parameters, however in this case the stability/reproducibility metrics were only used to access the models and not for parameter optimization. Other studies also reported a tradeoff between prediction vs. reproducibility using a penalized Fishers discriminant analysis (FDA) on PCA basis (<a href="#B36">Strother et al., 2004</a>; <a href="#B42">Yourganov et al., 2011</a>).</p>
<p class="mb15">Our work builds upon <a href="#B31">Rasmussen et al. (2012)</a>, as we also investigate the trade-off between prediction accuracy and reproducibility as model selection criteria, but differs from it in many aspects. First, our goal was to investigate the role of model selection criteria on several different sparse methods (LASSO, ENET, TV, LAP, STV, and SLAP). Second, we used a LOSO framework with nested cross-validation for parameter optimization instead of a half-split framework. Third, we investigated two stability/reproducibility metrics, the Pearson correlation coefficient and the pairwise corrected overlap across the LOSO solutions. Using our framework, we observed that when using prediction accuracy and corrected overlap as joint optimization criterion the solutions for different sparse methods become very similar in terms of performance and brain regions identified as relevant. These results suggest that the choice of model regularization parameters might be more important than the choice of the sparsity constraint.</p>
<p class="mb0">One limitation of our work is to use the LOSO cross-validation framework, i.e., the LOSO framework is known to have high variance and the solutions for different cross-validation folds are not independent. Nevertheless, considering the sample size of 16 subjects, it would be difficult to explore other cross-validation frameworks. It should be noted that since each subject has 42 scans of each active condition, leaving one subject out corresponds to leaving 84 examples out for test. Future work, using larger sample sizes should be performed to investigate the impact of adding stability/reproducibility as model selection criteria in other cross-validation frameworks. A possible future direction could be to explore multitask learning methods, in which the subjects are treated as distinct classification or regression tasks, which are related by means of a joint regularizer (see, for example, <a href="#B1">Argyriou et al., 2008</a>; <a href="#B32">Romera-Paredes et al., 2013</a>, and references therein). Ideas from <a href="#B6">Bzdok et al. (2015)</a> may also prove valuable in this direction.</p>
<a id="h6" name="h6"></a><h2>Ethics Statement</h2>
<p class="mb0">The study was performed in accordance with the local Ethics Committee of the University of North Carolina where the data was originally acquired. Participants had given written informed consent to participate in the study after the study was explained to them.</p>
<a id="h7" name="h7"></a><h2>Author Contributions</h2>
<p class="mb0">LB contributed to designing the experiments, implementing and running the models and writing the paper. JMM and MP contributed to designing the experiments, interpreting the results and writing the paper.</p>
<a id="h8" name="h8"></a><h2>Funding</h2>
<p class="mb0">JMM was supported by the Wellcome Trust under grant no. WT102845/Z/13/Z. MP was partially supported by EPSRC grants EP/P009069/1 and EP/M006093/1.</p>
<a id="h9" name="h9"></a><h2>Conflict of Interest Statement</h2>
<p class="mb0">The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<a id="h10" name="h10"></a><h2>Acknowledgments</h2>
<p class="mb0">The authors thank Professor Michael Brammer from the Institute of Psychiatry, Psychology and Neuroscience at King&#x00027;s College London for providing the fMRI dataset. This work is a longer version of our conference paper (<a href="#B3">Baldassarre et al., 2012a</a>). It contains a novel model selection criterion and extended experimental study. Furthermore, we discuss the coefficient maps obtained by the different models and model selection criteria considered.</p>
<a id="h11" name="h11"></a><h2>Supplementary Material</h2>
<p class="mb0">The Supplementary Material for this article can be found online at: <a href="http://journal.frontiersin.org/article/10.3389/fnins.2017.00062/full#supplementary-material">http://journal.frontiersin.org/article/10.3389/fnins.2017.00062/full#supplementary-material</a></p>
<a id="h12" name="h12"></a><h2>Footnotes</h2>
<div id="footnotetext" class="fulltextdescription">
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;" id="note1">1. <a class="footnotetextanchor" href="#note1a" title="">^</a>Model selection is a procedure through which, one among many possible statistical models is selected. The prototypical case is when each model corresponds to a different hyper-parameter, e.g., the regularization parameter in ridge regression, SVMs, or LASSO.</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;" id="note2">2. <a class="footnotetextanchor" href="#note2a" title="">^</a>We remark that there is a typo in the definition of <i>E</i> in <a href="#B4" style="color:grey;">Baldassarre et al. (2012b)</a>, which should coincide with Equation (2) hereafter.</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;" id="note3">3. <a class="footnotetextanchor" href="#note3a" title="">^</a>Specifically, <a href="#B31" style="color:grey;">Rasmussen et al. (2012)</a> has not employed the accuracy&#x02014;reproducibility diagram as model selection criterion for sparse models. They have only used it to assess the ENET performance. Whereas in this paper these measures are used both for model selection and assessment of different sparse methods.</p>
<p style="margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;" id="note4">4. <a class="footnotetextanchor" href="#note4a" title="">^</a>Wellcome Department of Imaging Neuroscience, <a href="http://www.fil.ion.ucl.ac.uk/spm/" style="color:grey;">http://www.fil.ion.ucl.ac.uk/spm/</a>.</p>
</div>
<a id="h13" name="h13"></a><h2>References</h2>
<div class="References">
<p class="ReferencesCopy1"><a name="B1" id="B1"></a> Argyriou, A., Evgeniou, T., and Pontil, M. (2008). Convex multi-task feature learning. <i>J. Mach. Learn.</i> 73, 243&#x02013;272. doi: 10.1007/s10994-007-5040-8</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1007/s10994-007-5040-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Argyriou&#x00026;author=T.+Evgeniou&#x00026;author=M.+Pontil+&#x00026;publication_year=2008&#x00026;title=Convex+multi-task+feature+learning&#x00026;journal=J.+Mach.+Learn.&#x00026;volume=73&#x00026;pages=243-272" target="_blank">Google Scholar</a></p></div>
<div class="References" style="margin-bottom:0.5em;">
<p class="ReferencesCopy1"><a name="B2" id="B2"></a> Bach, F., Jenatton, R., Mairal, J., and Obozinski, G. (2011). <i>Structured Sparsity through Convex Optimization.</i> Technical Report. <i>Arxiv preprint:1109.2397</i>.</p>
</div>
<div class="References">
<p class="ReferencesCopy1"><a name="B3" id="B3"></a> Baldassarre, L., Morales, J. M., Argyriou, A., and Pontil, M. (2012a). &#x0201C;A general framework for structured sparsity via proximal optimization,&#x0201D; in <i>International Conference on Artificial Intelligence and Statistics</i> (La Palma), 82&#x02013;90.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=L.+Baldassarre&#x00026;author=J.+M.+Morales&#x00026;author=A.+Argyriou&#x00026;author=M.+Pontil+&#x00026;publication_year=2012a&#x00026;title=&#x0201C;A+general+framework+for+structured+sparsity+via+proximal+optimization,&#x0201D;&#x00026;pages=82-90" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B4" id="B4"></a> Baldassarre, L., Mourao-Miranda, J., and Pontil, M. (2012b). &#x0201C;Structured sparsity models for brain decoding from fMRI data,&#x0201D; in <i>International Workshop on Pattern Recognition in NeuroImaging</i> (London), 5&#x02013;8. doi: 10.1109/prni.2012.31</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1109/prni.2012.31" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=L.+Baldassarre&#x00026;author=J.+Mourao-Miranda&#x00026;author=M.+Pontil+&#x00026;publication_year=2012b&#x00026;title=&#x0201C;Structured+sparsity+models+for+brain+decoding+from+fMRI+data,&#x0201D;&#x00026;pages=5-8" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B5" id="B5"></a> Belilovsky, E., Argyriou, A., Varoquaux, G., and Blaschko, M. (2015). Convex relaxations of penalties for sparse correlated variables with bounded total variation. <i>Mach. Learn.</i> 100, 533&#x02013;553. doi: 10.1007/s10994-015-5511-2</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1007/s10994-015-5511-2" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+Belilovsky&#x00026;author=A.+Argyriou&#x00026;author=G.+Varoquaux&#x00026;author=M.+Blaschko+&#x00026;publication_year=2015&#x00026;title=Convex+relaxations+of+penalties+for+sparse+correlated+variables+with+bounded+total+variation&#x00026;journal=Mach.+Learn.&#x00026;volume=100&#x00026;pages=533-553" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B6" id="B6"></a> Bzdok, D., Eickenberg, M., Grisel, O., Thirion, B., and Varoquaux, G. (2015). Semi-supervised factored logistic regression for high-dimensional neuroimaging data. <i>Adv. Neural Inform. Process. Syst.</i> 28, 3348&#x02013;3356. Available online at: <a href="http://papers.nips.cc/paper/5646-semi-supervised-factored-logistic-regression-for-high-dimensional-neuroimaging-data.pdf">http://papers.nips.cc/paper/5646-semi-supervised-factored-logistic-regression-for-high-dimensional-neuroimaging-data.pdf</a></p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=D.+Bzdok&#x00026;author=M.+Eickenberg&#x00026;author=O.+Grisel&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2015&#x00026;title=Semi-supervised+factored+logistic+regression+for+high-dimensional+neuroimaging+data&#x00026;journal=Adv.+Neural+Inform.+Process.+Syst.&#x00026;volume=28&#x00026;pages=3348-3356" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B7" id="B7"></a> Chambolle, A. (2004). An algorithm for total variation minimization and applications. <i>J. Math. Imaging Vis.</i> 20, 89&#x02013;97. doi: 10.1023/B:JMIV.0000011321.19549.88</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1023/B:JMIV.0000011321.19549.88" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Chambolle+&#x00026;publication_year=2004&#x00026;title=An+algorithm+for+total+variation+minimization+and+applications&#x00026;journal=J.+Math.+Imaging+Vis.&#x00026;volume=20&#x00026;pages=89-97" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B8" id="B8"></a> Cortes, C., and Vapnik, V. (1995). Support vector networks. <i>Mach. Learn.</i> 20, 273&#x02013;297. doi: 10.1007/BF00994018</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1007/BF00994018" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=C.+Cortes&#x00026;author=V.+Vapnik+&#x00026;publication_year=1995&#x00026;title=Support+vector+networks&#x00026;journal=Mach.+Learn.&#x00026;volume=20&#x00026;pages=273-297" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B9" id="B9"></a> Dohmatob, E., Gramfort, A., Thirion, B., and Varoquaux, G. (2014). &#x0201C;Benchmarking solvers for TV-l1 least-squares and logistic regression in brain imaging,&#x0201D; in <i>International Workshop on Pattern Recognition in Neuroimaging (PRNI)</i> (T&#x000FC;bingen: IEEE), 1&#x02013;4.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=E.+Dohmatob&#x00026;author=A.+Gramfort&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2014&#x00026;title=&#x0201C;Benchmarking+solvers+for+TV-l1+least-squares+and+logistic+regression+in+brain+imaging,&#x0201D;&#x00026;pages=1-4" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B10" id="B10"></a> Eickenberg, M., Dohmatob, E., Thirion, B., and Varoquaux, G. (2015). &#x0201C;Grouping total variation and sparsity: statistical learning with segmenting penalties,&#x0201D; in <i>Medical Image Computing and Computer-Assisted Intervention &#x02013; MICCAI 2015: 18th International Conference, October 5-9, Proceedings, Part I</i> (Munich), 685&#x02013;693.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=M.+Eickenberg&#x00026;author=E.+Dohmatob&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2015&#x00026;title=&#x0201C;Grouping+total+variation+and+sparsity%3A+statistical+learning+with+segmenting+penalties,&#x0201D;&#x00026;pages=685-693" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B11" id="B11"></a> Etkin, A. (2011). Emotional processing in anterior cingulate and medial prefrontal. <i>Trends Cogn. Sci.</i> 15, 85&#x02013;93. doi: 10.1016/j.tics.2010.11.004</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=21167765" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.tics.2010.11.004" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Etkin+&#x00026;publication_year=2011&#x00026;title=Emotional+processing+in+anterior+cingulate+and+medial+prefrontal&#x00026;journal=Trends+Cogn.+Sci.&#x00026;volume=15&#x00026;pages=85-93" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B12" id="B12"></a> Fiot, J. B., Raguet, H., Risser, L., Cohen, L. D., Fripp, J., and Vialard, F. X. (2014). Longitudinal deformation models, spatial regularizations and learning strategies to quantify alzheimer&#x00027;s disease progression. <i>Neuroimage</i> 4, 718&#x02013;729. doi: 10.1016/j.nicl.2014.02.002</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=24936423" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.nicl.2014.02.002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+B.+Fiot&#x00026;author=H.+Raguet&#x00026;author=L.+Risser&#x00026;author=L.+D.+Cohen&#x00026;author=J.+Fripp&#x00026;author=F.+X.+Vialard+&#x00026;publication_year=2014&#x00026;title=Longitudinal+deformation+models,+spatial+regularizations+and+learning+strategies+to+quantify+alzheimer&#x00027;s+disease+progression&#x00026;journal=Neuroimage&#x00026;volume=4&#x00026;pages=718-729" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B13" id="B13"></a> Gramfort, A., Thirion, B., and Varoquaux, G. (2013). &#x0201C;Identifying predictive regions from fMRI with TV-l1 prior,&#x0201D; in <i>International Workshop on Pattern Recognition in Neuroimaging (PRNI)</i> (Philadelphia, PA), 17&#x02013;20. doi: 10.1109/prni.2013.14</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1109/prni.2013.14" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Gramfort&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2013&#x00026;title=&#x0201C;Identifying+predictive+regions+from+fMRI+with+TV-l1+prior,&#x0201D;&#x00026;pages=17-20" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B14" id="B14"></a> Grosenick, L., Klingenberg, B., Katovich, K., Knutson, B., and Taylor, J. (2013). Interpretable whole-brain prediction analysis with graphnet. <i>Neuroimage</i> 72, 304&#x02013;321. doi: 10.1016/j.neuroimage.2012.12.062</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=23298747" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2012.12.062" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=L.+Grosenick&#x00026;author=B.+Klingenberg&#x00026;author=K.+Katovich&#x00026;author=B.+Knutson&#x00026;author=J.+Taylor+&#x00026;publication_year=2013&#x00026;title=Interpretable+whole-brain+prediction+analysis+with+graphnet&#x00026;journal=Neuroimage&#x00026;volume=72&#x00026;pages=304-321" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B15" id="B15"></a> Grosenick, L., Klingenberg, B., Katovich, K., Knutson, B., and Taylor, J. E. (2011). A family of interpretable multivariate models for regression and classification of whole-brain fMRI data. <i>ArXiv e-prints 1110.4139</i>.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=L.+Grosenick&#x00026;author=B.+Klingenberg&#x00026;author=K.+Katovich&#x00026;author=B.+Knutson&#x00026;author=J.+E.+Taylor+&#x00026;publication_year=2011&#x00026;title=A+family+of+interpretable+multivariate+models+for+regression+and+classification+of+whole-brain+fMRI+data&#x00026;journal=ArXiv+e-prints+1110.4139" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B16" id="B16"></a> Hardoon, D., Mourao-Miranda, J., Brammer, M., and Shawe-Taylor, J. (2007). Unsupervised analysis of fMRI data using kernel canonical correlation. <i>Neuroimage</i> 37, 1250&#x02013;1259. doi: 10.1016/j.neuroimage.2007.06.017</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17686634" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2007.06.017" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=D.+Hardoon&#x00026;author=J.+Mourao-Miranda&#x00026;author=M.+Brammer&#x00026;author=J.+Shawe-Taylor+&#x00026;publication_year=2007&#x00026;title=Unsupervised+analysis+of+fMRI+data+using+kernel+canonical+correlation&#x00026;journal=Neuroimage&#x00026;volume=37&#x00026;pages=1250-1259" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B17" id="B17"></a> Haynes, J. (2015). A primer on pattern-based approaches to fMRI: principles, pitfalls, and perspectives. <i>Neuron</i> 85, 257&#x02013;270. doi: 10.1016/j.neuron.2015.05.025</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1016/j.neuron.2015.05.025" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+Haynes+&#x00026;publication_year=2015&#x00026;title=A+primer+on+pattern-based+approaches+to+fMRI%3A+principles,+pitfalls,+and+perspectives&#x00026;journal=Neuron&#x00026;volume=85&#x00026;pages=257-270" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B18" id="B18"></a> Haynes, J., Sakai, K., Rees, G., Gilbert, S., Frith, C., and Passingham, R. E. (2007). Reading hidden intentions in the human brain. <i>Curr. Biol.</i> 17, 323&#x02013;328. doi: 10.1016/j.cub.2006.11.072</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17291759" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2006.11.072" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+Haynes&#x00026;author=K.+Sakai&#x00026;author=G.+Rees&#x00026;author=S.+Gilbert&#x00026;author=C.+Frith&#x00026;author=R.+E.+Passingham+&#x00026;publication_year=2007&#x00026;title=Reading+hidden+intentions+in+the+human+brain&#x00026;journal=Curr.+Biol.&#x00026;volume=17&#x00026;pages=323-328" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B19" id="B19"></a> Hoyos-Idrobo, A., Schwartz, Y., Varoquaux, G., and Thirion, B. (2015). &#x0201C;Improving sparse recovery on structured images with bagged clustering,&#x0201D; in <i>International Workshop on Pattern Recognition In Neuroimaging (PRNI)</i> (Palo Alto, CA), 73&#x02013;76.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=A.+Hoyos-Idrobo&#x00026;author=Y.+Schwartz&#x00026;author=G.+Varoquaux&#x00026;author=B.+Thirion+&#x00026;publication_year=2015&#x00026;title=&#x0201C;Improving+sparse+recovery+on+structured+images+with+bagged+clustering,&#x0201D;&#x00026;pages=73-76" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B20" id="B20"></a> Jenatton, R., Gramfort, A., Michel, V., Obozinski, G., Eger, E., Bach, F., et al. (2011). Multi-scale mining of fMRI data with hierarchical structured sparsity. <i>ArXiv e-prints 1105.0363</i>.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=R.+Jenatton&#x00026;author=A.+Gramfort&#x00026;author=V.+Michel&#x00026;author=G.+Obozinski&#x00026;author=E.+Eger&#x00026;author=F.+Bach+&#x00026;publication_year=2011&#x00026;title=Multi-scale+mining+of+fMRI+data+with+hierarchical+structured+sparsity&#x00026;journal=ArXiv+e-prints+1105.0363" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B21" id="B21"></a> Jenatton, R., Gramfort, A., Michel, V., Obozinski, G., Eger, E., Bach, F., et al. (2012). Multiscale mining of fMRI data with hierarchical structured sparsity. <i>SIAM J. Imaging Sci.</i> 5, 835&#x02013;856. doi: 10.1137/110832380</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1137/110832380" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+Jenatton&#x00026;author=A.+Gramfort&#x00026;author=V.+Michel&#x00026;author=G.+Obozinski&#x00026;author=E.+Eger&#x00026;author=F.+Bach+&#x00026;publication_year=2012&#x00026;title=Multiscale+mining+of+fMRI+data+with+hierarchical+structured+sparsity&#x00026;journal=SIAM+J.+Imaging+Sci.&#x00026;volume=5&#x00026;pages=835-856" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B22" id="B22"></a> Kloppel, S., Abdulkadir, A., Jack, C. R. J., Koutsouleris, N., Mourao-Miranda, J., and Vemur, J. (2012). Diagnostic neuroimaging across diseases. <i>Neuroimage</i> 61, 457&#x02013;463. doi: 10.1016/j.neuroimage.2011.11.002</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=22094642" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2011.11.002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Kloppel&#x00026;author=A.+Abdulkadir&#x00026;author=C.+R.+J.+Jack&#x00026;author=N.+Koutsouleris&#x00026;author=J.+Mourao-Miranda&#x00026;author=J.+Vemur+&#x00026;publication_year=2012&#x00026;title=Diagnostic+neuroimaging+across+diseases&#x00026;journal=Neuroimage&#x00026;volume=61&#x00026;pages=457-463" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B23" id="B23"></a> Ma, S., Yin, W., Zhang, Y., and Chakraborty, A. (2008). &#x0201C;An efficient algorithm for compressed MR imaging using total variation and wavelets,&#x0201D; in <i>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on (IEEE)</i> (Anchorage, AK), 1&#x02013;8.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=S.+Ma&#x00026;author=W.+Yin&#x00026;author=Y.+Zhang&#x00026;author=A.+Chakraborty+&#x00026;publication_year=2008&#x00026;title=&#x0201C;An+efficient+algorithm+for+compressed+MR+imaging+using+total+variation+and+wavelets,&#x0201D;&#x00026;pages=1-8" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B24" id="B24"></a> Micchelli, C. A., Morales, J. M., and Pontil, M. (2013). Regularizers for structured sparsity. <i>Adv. Comput. Math.</i> 38, 455&#x02013;489. doi: 10.1007/s10444-011-9245-9</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1007/s10444-011-9245-9" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=C.+A.+Micchelli&#x00026;author=J.+M.+Morales&#x00026;author=M.+Pontil+&#x00026;publication_year=2013&#x00026;title=Regularizers+for+structured+sparsity&#x00026;journal=Adv.+Comput.+Math.&#x00026;volume=38&#x00026;pages=455-489" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B25" id="B25"></a> Michel, V., Gramfort, A., Varoquaux, G., Eger, E., and Thirion, B. (2011). Total variation regularization for fMRI-based prediction of behavior. <i>IEEE Trans. Med. Imaging</i> 30, 1328&#x02013;1340. doi: 10.1109/TMI.2011.2113378</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=21317080" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1109/TMI.2011.2113378" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=V.+Michel&#x00026;author=A.+Gramfort&#x00026;author=G.+Varoquaux&#x00026;author=E.+Eger&#x00026;author=B.+Thirion+&#x00026;publication_year=2011&#x00026;title=Total+variation+regularization+for+fMRI-based+prediction+of+behavior&#x00026;journal=IEEE+Trans.+Med.+Imaging&#x00026;volume=30&#x00026;pages=1328-1340" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B26" id="B26"></a> Mohr, H., Wolfensteller, U., Frimmel, S., and Ruge, H. (2015). Sparse regularization techniques provide novel insights into outcome integration processes. <i>Neuroimage</i> 104, 163&#x02013;176. doi: 10.1016/j.neuroimage.2014.10.025</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=25467302" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2014.10.025" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=H.+Mohr&#x00026;author=U.+Wolfensteller&#x00026;author=S.+Frimmel&#x00026;author=H.+Ruge+&#x00026;publication_year=2015&#x00026;title=Sparse+regularization+techniques+provide+novel+insights+into+outcome+integration+processes&#x00026;journal=Neuroimage&#x00026;volume=104&#x00026;pages=163-176" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B27" id="B27"></a> Mourao-Miranda, J., Friston, K., and Brammer, M. (2007). Dynamic discrimination analysis: a spatial-temporal svm. <i>Neuroimage</i> 36, 88&#x02013;99. doi: 10.1016/j.neuroimage.2007.02.020</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17400479" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2007.02.020" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+Mourao-Miranda&#x00026;author=K.+Friston&#x00026;author=M.+Brammer+&#x00026;publication_year=2007&#x00026;title=Dynamic+discrimination+analysis%3A+a+spatial-temporal+svm&#x00026;journal=Neuroimage&#x00026;volume=36&#x00026;pages=88-99" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B28" id="B28"></a> Mourao-Miranda, J., Reynaud, E., McGlone, F., Calvert, G., and Brammer, M. (2006). The impact of temporal compression and space selection on svm analysis of single-subject and multi-subject fMRI data. <i>Neuroimage</i> 33, 1055&#x02013;1065. doi: 10.1016/j.neuroimage.2006.08.016</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17010645" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2006.08.016" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+Mourao-Miranda&#x00026;author=E.+Reynaud&#x00026;author=F.+McGlone&#x00026;author=G.+Calvert&#x00026;author=M.+Brammer+&#x00026;publication_year=2006&#x00026;title=The+impact+of+temporal+compression+and+space+selection+on+svm+analysis+of+single-subject+and+multi-subject+fMRI+data&#x00026;journal=Neuroimage&#x00026;volume=33&#x00026;pages=1055-1065" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B29" id="B29"></a> Pereira, F., Mitchell, T., and Botvinick, M. (2009). Machine learning classifiers and fMRI: a tutorial overview. <i>Neuroimage</i> 45, S199&#x02013;S209. doi: 10.1016/j.neuroimage.2008.11.007</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=19070668" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2008.11.007" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+Pereira&#x00026;author=T.+Mitchell&#x00026;author=M.+Botvinick+&#x00026;publication_year=2009&#x00026;title=Machine+learning+classifiers+and+fMRI%3A+a+tutorial+overview&#x00026;journal=Neuroimage&#x00026;volume=45&#x00026;pages=S199-S209" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B30" id="B30"></a> Polyn, S. M., Natu, V. S., Cohen, J. D., and Norman, K. A. (2005). Category-specific cortical activity precedes retrieval during memory search. <i>Science</i> 310, 1963&#x02013;1966. doi: 10.1126/science.1117645</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=16373577" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1126/science.1117645" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+M.+Polyn&#x00026;author=V.+S.+Natu&#x00026;author=J.+D.+Cohen&#x00026;author=K.+A.+Norman+&#x00026;publication_year=2005&#x00026;title=Category-specific+cortical+activity+precedes+retrieval+during+memory+search&#x00026;journal=Science&#x00026;volume=310&#x00026;pages=1963-1966" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B31" id="B31"></a> Rasmussen, P. M., Hansen, L. K., Madsen, K. H., Churchill, N. W., and Strother, S. C. (2012). Model sparsity and brain pattern interpretation of classification models in neuroimaging. <i>Patt. Recogn</i>. 45, 2085&#x02013;2100. doi: 10.1016/j.patcog.2011.09.011</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1016/j.patcog.2011.09.011" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=P.+M.+Rasmussen&#x00026;author=L.+K.+Hansen&#x00026;author=K.+H.+Madsen&#x00026;author=N.+W.+Churchill&#x00026;author=S.+C.+Strother+&#x00026;publication_year=2012&#x00026;title=Model+sparsity+and+brain+pattern+interpretation+of+classification+models+in+neuroimaging&#x00026;journal=Patt.+Recogn&#x00026;volume=45&#x00026;pages=2085-2100" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B32" id="B32"></a> Romera-Paredes, B., Aung, M. H., Bianchi-Berthouze, N., and Pontil, M. (2013). &#x0201C;Multilinear multitask learning,&#x0201D; in <i>Proceedings of the 30th International Conference on Machine Learning (ICML)</i> (Atlanta, GA), 1444&#x02013;1452.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=B.+Romera-Paredes&#x00026;author=M.+H.+Aung&#x00026;author=N.+Bianchi-Berthouze&#x00026;author=M.+Pontil+&#x00026;publication_year=2013&#x00026;title=&#x0201C;Multilinear+multitask+learning,&#x0201D;&#x00026;pages=1444-1452" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B33" id="B33"></a> Rudin, L., Osher, S., and Fatemi, E. (1992). Nonlinear total variation based noise removal algorithms. <i>Physica D</i> 60, 259&#x02013;268. doi: 10.1016/0167-2789(92)90242-F</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1016/0167-2789(92)90242-F" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=L.+Rudin&#x00026;author=S.+Osher&#x00026;author=E.+Fatemi+&#x00026;publication_year=1992&#x00026;title=Nonlinear+total+variation+based+noise+removal+algorithms&#x00026;journal=Physica+D&#x00026;volume=60&#x00026;pages=259-268" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B34" id="B34"></a> Schrouff, J., Kusse, C., Wehenkel, L., Maquet, P., and Phillips, C. (2012). ecoding semi-constrained brain activity from fMRI using support vector machines and gaussian processes. <i>PLoS ONE</i> 7:e35860. doi: 10.1371/journal.pone.0035860</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=22563410" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1371/journal.pone.0035860" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+Schrouff&#x00026;author=C.+Kusse&#x00026;author=L.+Wehenkel&#x00026;author=P.+Maquet&#x00026;author=C.+Phillips+&#x00026;publication_year=2012&#x00026;title=ecoding+semi-constrained+brain+activity+from+fMRI+using+support+vector+machines+and+gaussian+processes&#x00026;journal=PLoS+ONE" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B35" id="B35"></a> Strother, S., Anderson, J., Hansen, L., Kjems, U., Kustra, R., Sidtis, J., et al. (2002). The quantitative evaluation of functional neuroimaging experiments: the npairs data analysis framework. <i>Neuroimage</i> 15, 747&#x02013;771. doi: 10.1006/nimg.2001.1034</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=11906218" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1006/nimg.2001.1034" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Strother&#x00026;author=J.+Anderson&#x00026;author=L.+Hansen&#x00026;author=U.+Kjems&#x00026;author=R.+Kustra&#x00026;author=J.+Sidtis+&#x00026;publication_year=2002&#x00026;title=The+quantitative+evaluation+of+functional+neuroimaging+experiments%3A+the+npairs+data+analysis+framework&#x00026;journal=Neuroimage&#x00026;volume=15&#x00026;pages=747-771" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B36" id="B36"></a> Strother, S., Conte, S. L., Hansen, L. K., Anderson, J., Zhang, J., Pulapura, S., et al. (2004). Optimizing the fMRI data-processing pipeline using prediction and reproducibility performance metrics: I. A preliminary group analysis. <i>Neuroimage</i> 23(Suppl. 1), S196&#x02013;S207. doi: 10.1016/j.neuroimage.2004.07.022</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=15501090" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2004.07.022" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Strother&#x00026;author=S.+L.+Conte&#x00026;author=L.+K.+Hansen&#x00026;author=J.+Anderson&#x00026;author=J.+Zhang&#x00026;author=S.+Pulapura+&#x00026;publication_year=2004&#x00026;title=Optimizing+the+fMRI+data-processing+pipeline+using+prediction+and+reproducibility+performance+metrics%3A+I.+A+preliminary+group+analysis&#x00026;journal=Neuroimage&#x00026;volume=23&#x00026;pages=S196-S207" target="_blank">Google Scholar</a></p></div>
<div class="References" style="margin-bottom:0.5em;">
<p class="ReferencesCopy1"><a name="B37" id="B37"></a> Talairach, P., and Tournoux, J. (1988). <i>A Stereotactic Coplanar Atlas of the Human Brain</i>. Stuttgart: Thieme.</p>
</div>
<div class="References">
<p class="ReferencesCopy1"><a name="B38" id="B38"></a> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. <i>J. R. Stat. Soc. Ser. B</i> 58, 267&#x02013;288.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=R.+Tibshirani+&#x00026;publication_year=1996&#x00026;title=Regression+shrinkage+and+selection+via+the+lasso&#x00026;journal=J.+R.+Stat.+Soc.+Ser.+B&#x00026;volume=58&#x00026;pages=267-288" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B39" id="B39"></a> Tikhonov, A. N., and Arsenin, V. Y. (1977). <i>Solutions of Ill-Posed Problems</i>. Washington, DC: John Wiley.</p>
<p class="ReferencesCopy2"><a href="http://scholar.google.com/scholar_lookup?author=A.+N.+Tikhonov&#x00026;author=V.+Y.+Arsenin+&#x00026;publication_year=1977&#x00026;title=Solutions+of+Ill-Posed+Problems" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B40" id="B40"></a> Wandell, B. A., Dumoulin, S. O., and Brewer, A. A. (2007). Visual field maps in human cortex. <i>Neuron</i> 56, 366&#x02013;383. doi: 10.1016/j.neuron.2007.10.012</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17964252" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuron.2007.10.012" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=B.+A.+Wandell&#x00026;author=S.+O.+Dumoulin&#x00026;author=A.+A.+Brewer+&#x00026;publication_year=2007&#x00026;title=Visual+field+maps+in+human+cortex&#x00026;journal=Neuron&#x00026;volume=56&#x00026;pages=366-383" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B41" id="B41"></a> Wang, Y., Zheng, J., Zhang, S., Duan, X., and Chen, H. (2014). Randomized structural sparsity via constrained block subsampling for improved sensitivity of discriminative voxel identification. <i>ArXiv e-prints 1410.4650</i>.</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=26027884" target="_blank">PubMed Abstract</a> | <a href="http://scholar.google.com/scholar_lookup?author=Y.+Wang&#x00026;author=J.+Zheng&#x00026;author=S.+Zhang&#x00026;author=X.+Duan&#x00026;author=H.+Chen+&#x00026;publication_year=2014&#x00026;title=Randomized+structural+sparsity+via+constrained+block+subsampling+for+improved+sensitivity+of+discriminative+voxel+identification&#x00026;journal=ArXiv+e-prints+1410.4650" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B42" id="B42"></a> Yourganov, G., Chen, X., Lukic, A. S., Grady, C. L., Small, S. L., Wernick, M. N., et al. (2011). Dimensionality estimation for optimal detection of functional networks in bold fMRI data. <i>Neuroimage</i> 56, 531&#x02013;543. doi: 10.1016/j.neuroimage.2010.09.034</p>
<p class="ReferencesCopy2"><a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=20858546" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2010.09.034" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Yourganov&#x00026;author=X.+Chen&#x00026;author=A.+S.+Lukic&#x00026;author=C.+L.+Grady&#x00026;author=S.+L.+Small&#x00026;author=M.+N.+Wernick+&#x00026;publication_year=2011&#x00026;title=Dimensionality+estimation+for+optimal+detection+of+functional+networks+in+bold+fMRI+data&#x00026;journal=Neuroimage&#x00026;volume=56&#x00026;pages=531-543" target="_blank">Google Scholar</a></p></div>
<div class="References">
<p class="ReferencesCopy1"><a name="B43" id="B43"></a> Zou, H., and Hastie, T. (2005). Regularization and variable selection via the elastic net. <i>J. R. Stat. Soc. Ser. B (Stat. Methodol.)</i> 67, 301&#x02013;320. doi: 10.1111/j.1467-9868.2005.00503.x</p>
<p class="ReferencesCopy2"><a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=H.+Zou&#x00026;author=T.+Hastie+&#x00026;publication_year=2005&#x00026;title=Regularization+and+variable+selection+via+the+elastic+net&#x00026;journal=J.+R.+Stat.+Soc.+Ser.+B+(Stat.+Methodol.)&#x00026;volume=67&#x00026;pages=301-320" target="_blank">Google Scholar</a></p></div>
</div>
<div class="thinLineM20"></div>
<div class="AbstractSummary">
<p><span>Keywords:</span> sparse methods, structured sparsity, model selection, reproducibility, predictive models</p>
<p><span>Citation:</span> Baldassarre L, Pontil M and Mour&#x000E3;o-Miranda J (2017) Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding. <i>Front. Neurosci</i>. 11:62. doi: 10.3389/fnins.2017.00062</p>
<p id="timestamps"><span>Received:</span> 14 June 2016; <span>Accepted:</span> 27 January 2017;<br> <span>Published:</span> 17 February 2017.</p>
<div><p>Edited by:</p> <a href="http://loop.frontiersin.org/people/53467/overview">Bertrand Thirion</a>, Institut National de Recherche en Informatique et en Automatique (INRIA), France</div>
<div><p>Reviewed by:</p> <a href="http://loop.frontiersin.org/people/49944/overview">Danilo Bzdok</a>, Research Center J&#x000FC;lich, Germany<br> <a href="http://loop.frontiersin.org/people/77204/overview">Bernard Ng</a>, University of British Columbia, Canada</div>
<p><span>Copyright</span> &#x000A9; 2017 Baldassarre, Pontil and Mour&#x000E3;o-Miranda. This is an open-access article distributed under the terms of the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution License (CC BY)</a>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</p>
<p><span>*Correspondence:</span> Janaina Mour&#x000E3;o-Miranda, <a id="encmail">ai5tb3VyYW8tbWlyYW5kYUB1Y2wuYWMudWs=</a></p>
<div class="clear"></div></div>

</div></div><p class="AbstractSummary__disclaimer"><span>Disclaimer: </span> All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. </p></div></div><!----></main><aside class="Layout__aside"><div class="ArticleDetails__wrapper"><div class="ArticleDetails__aside"><div class="ArticleDetails__aside__responsiveButtons"><div class="ActionsDropDown" id="FloatingButtonsEl"><button aria-label="Open dropdown" class="ActionsDropDown__button--type ActionsDropDown__button--icon ActionsDropDown__button--color ActionsDropDown__button" data-event="actionsDropDown-button-toggle"><span class="ActionsDropDown__button__label">Download article</span></button><div class="ActionsDropDown__menuWrapper"><!----><ul class="ActionsDropDown__menu"><!--[--><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/pdf" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-pdf">Download PDF</a></li><li><a href="http://www.readcube.com/articles/10.3389/fnins.2017.00062" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-readCube">ReadCube</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/epub" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-epub">EPUB</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/xml" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-nlmXml">XML</a></li><!--]--></ul><button class="ActionsDropDown__mobileClose" aria-label="Close modal" data-event="actionsDropDown-button-close"></button></div></div><div class="ArticleDetails__aside__responsiveButtons__items"><span></span><div class="ArticleDetailsShare__responsive"><button class="ArticleDetailsShare__trigger" aria-label="Open share options"></button><div class="ArticleDetailsShare"><p class="ArticleDetailsShare__title">Share on</p><ul class="ArticleDetailsShare__list"><!--[--><li class="ArticleDetailsShare__item"><a href="https://www.twitter.com/share?url=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--x ArticleDetailsShare__link" title="Share on X" aria-label="Share on X"></a></li><li class="ArticleDetailsShare__item"><a href="https://www.linkedin.com/share?url=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--linkedin ArticleDetailsShare__link" title="Share on Linkedin" aria-label="Share on Linkedin"></a></li><li class="ArticleDetailsShare__item"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--facebook ArticleDetailsShare__link" title="Share on Facebook" aria-label="Share on Facebook"></a></li><!--]--></ul></div></div><div class="ActionsDropDown"><button aria-label="Open dropdown" class="ActionsDropDown__button--typeIconButton ActionsDropDown__button--iconQuote ActionsDropDown__button--color ActionsDropDown__button" data-event="actionsDropDown-button-toggle"><!----></button><div class="ActionsDropDown__menuWrapper"><div class="ActionsDropDown__mobileTitle">Export citation</div><ul class="ActionsDropDown__menu"><!--[--><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/endNote" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-endNote">EndNote</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/reference" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-referenceManager">Reference Manager</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/text" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-simpleTextFile">Simple Text file</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/bibTex" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-bibTex">BibTex</a></li><!--]--></ul><button class="ActionsDropDown__mobileClose" aria-label="Close modal" data-event="actionsDropDown-button-close"></button></div></div></div></div><div class="TotalViews"><div class="TotalViews__data"><div class="TotalViews__data__metrics"><div class="TotalViews__data__metrics__number">8,5K</div><div class="TotalViews__data__metrics__text"><div class="TotalViews__data__metrics__label">Total views</div></div></div><div class="TotalViews__data__metrics"><div class="TotalViews__data__metrics__number">1,5K</div><div class="TotalViews__data__metrics__text"><div class="TotalViews__data__metrics__label">Downloads</div></div></div><div class="TotalViews__data__metrics"><div class="TotalViews__data__metrics__number">39</div><div class="TotalViews__data__metrics__text"><div class="TotalViews__data__metrics__label">Citations</div></div></div><div class="ImpactMetricsInfoPopover"><button aria-label="Open impact metrics info" class="ImpactMetricsInfoPopover__button"></button><div class="ImpactMetricsInfoPopover__tooltip"><button aria-label="Close impact metrics info" class="ImpactMetricsInfoPopover__tooltip__closeButton"></button><div class="ImpactMetricsInfoPopover__tooltip__text"> Citation numbers are available from Dimensions </div></div></div></div><div class="TotalViews__viewImpactLink"><span class="Link__wrapper"><a class="Link Link--linkType Link--maincolor Link--medium Link--icon Link--chevronRight Link--right" aria-label="View article impact" href="http://loop-impact.frontiersin.org/impact/article/209792#totalviews/views" target="_blank" data-event="customLink-link-a_viewArticleImpact"><span>View article impact</span></a></span></div><div class="TotalViews__altmetric"><div data-badge-popover="bottom" data-badge-type="donut" data-doi="10.3389/fnins.2017.00062" data-condensed="true" data-link-target="new" class="altmetric-embed"></div><span class="Link__wrapper"><a class="Link Link--linkType Link--maincolor Link--medium Link--icon Link--chevronRight Link--right" aria-label="View altmetric score" href="https://www.altmetric.com/details/doi/10.3389/fnins.2017.00062" target="_blank" data-event="customLink-link-a_viewAltmetricScore"><span>View altmetric score</span></a></span></div></div><div class="ArticleDetailsShare"><p class="ArticleDetailsShare__title">Share on</p><ul class="ArticleDetailsShare__list"><!--[--><li class="ArticleDetailsShare__item"><a href="https://www.twitter.com/share?url=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--x ArticleDetailsShare__link" title="Share on X" aria-label="Share on X"></a></li><li class="ArticleDetailsShare__item"><a href="https://www.linkedin.com/share?url=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--linkedin ArticleDetailsShare__link" title="Share on Linkedin" aria-label="Share on Linkedin"></a></li><li class="ArticleDetailsShare__item"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full" target="_blank" class="ArticleDetailsShare__link--facebook ArticleDetailsShare__link" title="Share on Facebook" aria-label="Share on Facebook"></a></li><!--]--></ul></div><div class="ArticleDetailsEditors"><div class="ArticleDetailsEditors__editors"><div class="ArticleDetailsEditors__title">Edited by</div><!--[--><a href="https://loop.frontiersin.org/people/53467/overview" data-event="editorInfo-a-bertrandThirion" class="ArticleDetailsEditors__ediorInfo"><div class="Avatar Avatar--size-32 Avatar--text Avatar--grey"><!--[--><span class="notranslate">B</span><span class="notranslate">T</span><!--]--></div><div class="ArticleDetailsEditors__ediorInfo__info"><div class="ArticleDetailsEditors__ediorInfo__name notranslate">Bertrand  Thirion</div><div class="ArticleDetailsEditors__ediorInfo__affiliation notranslate">Institut National de Recherche en Informatique et en Automatique (INRIA), France</div></div></a><!--]--></div></div><div class="ArticleDetailsEditors"><div class="ArticleDetailsEditors__editors"><div class="ArticleDetailsEditors__title">Reviewed by</div><!--[--><a href="https://loop.frontiersin.org/people/49944/overview" data-event="editorInfo-a-daniloBzdok" class="ArticleDetailsEditors__ediorInfo"><div class="Avatar Avatar--size-32 Avatar--text Avatar--grey"><!--[--><span class="notranslate">D</span><span class="notranslate">B</span><!--]--></div><div class="ArticleDetailsEditors__ediorInfo__info"><div class="ArticleDetailsEditors__ediorInfo__name notranslate">Danilo  Bzdok</div><div class="ArticleDetailsEditors__ediorInfo__affiliation notranslate">Julich Research Center, Helmholtz Association of German Research Centres (HZ), Germany</div></div></a><a href="https://loop.frontiersin.org/people/77204/overview" data-event="editorInfo-a-bernardNg" class="ArticleDetailsEditors__ediorInfo"><div class="Avatar Avatar--size-32 Avatar--text Avatar--grey"><!--[--><span class="notranslate">B</span><span class="notranslate">N</span><!--]--></div><div class="ArticleDetailsEditors__ediorInfo__info"><div class="ArticleDetailsEditors__ediorInfo__name notranslate">Bernard  Ng</div><div class="ArticleDetailsEditors__ediorInfo__affiliation notranslate">University of British Columbia, Canada</div></div></a><!--]--></div></div><div class="ArticleDetailsGlossary ArticleDetailsGlossary--open"><button class="ArticleDetailsGlossary__header"><div class="ArticleDetailsGlossary__header__title">Table of contents</div><div class="ArticleDetailsGlossary__header__arrow"></div></button><div class="ArticleDetailsGlossary__content"><ul class="flyoutJournal">
<li><a href="#h1">Abstract</a></li>
<li><a href="#h2">1. Introduction</a></li>
<li><a href="#h3">2. Materials and Methods</a></li>
<li><a href="#h4">3. Results</a></li>
<li><a href="#h5">4. Discussion</a></li>
<li><a href="#h6">Ethics Statement</a></li>
<li><a href="#h7">Author Contributions</a></li>
<li><a href="#h8">Funding</a></li>
<li><a href="#h9">Conflict of Interest Statement</a></li>
<li><a href="#h10">Acknowledgments</a></li>
<li><a href="#h11">Supplementary Material</a></li>
<li><a href="#h12">Footnotes</a></li>
<li><a href="#h13">References</a></li>
</ul>
</div></div><span></span><div class="ActionsDropDown"><button aria-label="Open dropdown" class="ActionsDropDown__button--typeOutline ActionsDropDown__button--iconQuote ActionsDropDown__button--color ActionsDropDown__button" data-event="actionsDropDown-button-toggle"><span class="ActionsDropDown__button__label">Export citation</span></button><div class="ActionsDropDown__menuWrapper"><!----><ul class="ActionsDropDown__menu"><!--[--><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/endNote" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-endNote">EndNote</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/reference" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-referenceManager">Reference Manager</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/text" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-simpleTextFile">Simple Text file</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/bibTex" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-bibTex">BibTex</a></li><!--]--></ul><button class="ActionsDropDown__mobileClose" aria-label="Close modal" data-event="actionsDropDown-button-close"></button></div></div><div class="CheckForUpdates"><button data-target="crossmark" class="CheckForUpdates__link" data-event="checkForUpdates-btn-openModal"><img class="CheckForUpdates__link__img" src="/ap-2024/images/crossmark.svg" alt="Crossmark icon"><div class="CheckForUpdates__link__text">Check for updates</div></button></div><div class="AnnouncementCard"><p class="AnnouncementCard__title">Frontiers&#39; impact</p><article class="CardA"><div class="CardA__wrapper CardA__wrapper--vertical"><figure class="FrontiersImage CardA__img"><picture class="FrontiersImage"><!--[--><source srcset="https://images-provider.frontiersin.org/api/ipx/w=440&amp;f=webp/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" media="(max-width: 563px)"><source srcset="https://images-provider.frontiersin.org/api/ipx/s=320x400&amp;fit=outside&amp;f=webp/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" media="(max-width: 1024px)"><source srcset="https://images-provider.frontiersin.org/api/ipx/s=268x280&amp;fit=outside&amp;f=webp/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" media="(max-width: 1441px)"><source srcset="https://images-provider.frontiersin.org/api/ipx/s=366x408&amp;fit=outside&amp;f=webp/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" media><source srcset="https://images-provider.frontiersin.org/api/ipx/s=366x408&amp;fit=outside&amp;f=jpg/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" media><!--]--><img src="https://images-provider.frontiersin.org/api/ipx/s=366x408&amp;fit=outside&amp;f=jpg/https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png" class="is-inside-mask" alt loading="eager"></picture><!----></figure><div class="CardA__info"><!--[--><h2 class="CardA__title">Articles published with Frontiers have received 12 million total citations</h2><p class="CardA__text">Your research is the real superpower - learn how we maximise its impact through our leading community journals</p><br><span class="Link__wrapper"><a class="Link Link--linkType Link--maincolor Link--small Link--icon Link--chevronRight Link--right" aria-label="Explore our impact metrics" href="https://www.frontiersin.org/about/impact" target="_self" data-event="customLink-linkType-a_exploreOurImpactMe"><span>Explore our impact metrics</span></a></span><!--]--></div></div></article></div><!----><!----></div><div><div class="Modal Modal--noFooter"><button aria-label="Close modal" class="Modal__overlay" data-event="modal-overlay-close"></button><div class="Modal__container"><div class="Modal__header"><p class="Modal__title">Supplementary Material</p><button aria-label="Close modal" class="Modal__close" data-event="modal-button-close"></button></div><div class="Modal__body"><!--[--><div class="SupplementalData"><ul class="SupplementalData__list"><!--[--><!--]--></ul></div><!--]--><!----></div><!----><!----></div></div></div><div><div class="FloatingButtons"><!----><div class="ActionsDropDown"><button aria-label="Open dropdown" class="ActionsDropDown__button--type ActionsDropDown__button--iconDownload ActionsDropDown__button--color ActionsDropDown__button" data-event="actionsDropDown-button-toggle"><span class="ActionsDropDown__button__label">Download article</span></button><div class="ActionsDropDown__menuWrapper"><div class="ActionsDropDown__mobileTitle">Download</div><ul class="ActionsDropDown__menu"><!--[--><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/pdf" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-pdf">Download PDF</a></li><li><a href="http://www.readcube.com/articles/10.3389/fnins.2017.00062" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-readCube">ReadCube</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/epub" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-epub">EPUB</a></li><li><a href="/journals/neuroscience/articles/10.3389/fnins.2017.00062/xml" target="_blank" rel="noopener noreferrer" class="ActionsDropDown__option" data-event="actionsDropDown-a-nlmXml">XML</a></li><!--]--></ul><button class="ActionsDropDown__mobileClose" aria-label="Close modal" data-event="actionsDropDown-button-close"></button></div></div><!----></div></div></div></aside></div><div class=""><!----></div><!--]--></div><!----><footer class="Footer"><div class="Footer__wrapper"><div class="Footer__sections"><ul class="Accordion"><!--[--><!--[--><li class="Accordion__item"><button class="Accordion__headline"><!----><!--[--><div class="Accordion__title">Guidelines</div><div class="Accordion__space"></div><!--]--><div class="Accordion__arrow"></div></button><div class="Accordion__content Accordion__content--fadeOut" style="height:0px;"><!--[--><ul><!--[--><li><a href="https://www.frontiersin.org/guidelines/author-guidelines" target="_self" data-event="footer-block_0-a_authorGuidelines">Author guidelines</a></li><li><a href="https://www.frontiersin.org/for-authors/author-services" target="_self" data-event="footer-block_0-a_servicesForAuthors">Services for authors</a></li><li><a href="https://www.frontiersin.org/guidelines/policies-and-publication-ethics" target="_self" data-event="footer-block_0-a_policiesAndPublicationE">Policies and publication ethics</a></li><li><a href="https://www.frontiersin.org/guidelines/editor-guidelines" target="_self" data-event="footer-block_0-a_editorGuidelines">Editor guidelines</a></li><li><a href="https://www.frontiersin.org/about/fee-policy" target="_self" data-event="footer-block_0-a_feePolicy">Fee policy</a></li><!--]--></ul><!--]--></div></li><li class="Accordion__item"><button class="Accordion__headline"><!----><!--[--><div class="Accordion__title">Explore</div><div class="Accordion__space"></div><!--]--><div class="Accordion__arrow"></div></button><div class="Accordion__content Accordion__content--fadeOut" style="height:0px;"><!--[--><ul><!--[--><li><a href="https://www.frontiersin.org/articles" target="_self" data-event="footer-block_1-a_articles">Articles</a></li><li><a href="https://www.frontiersin.org/research-topics" target="_self" data-event="footer-block_1-a_researchTopics">Research Topics </a></li><li><a href="https://www.frontiersin.org/journals" target="_self" data-event="footer-block_1-a_journals">Journals</a></li><li><a href="https://www.frontiersin.org/about/how-we-publish" target="_self" data-event="footer-block_1-a_howWePublish">How we publish</a></li><!--]--></ul><!--]--></div></li><li class="Accordion__item"><button class="Accordion__headline"><!----><!--[--><div class="Accordion__title">Outreach</div><div class="Accordion__space"></div><!--]--><div class="Accordion__arrow"></div></button><div class="Accordion__content Accordion__content--fadeOut" style="height:0px;"><!--[--><ul><!--[--><li><a href="https://forum.frontiersin.org/" target="_blank" data-event="footer-block_2-a_frontiersForum">Frontiers Forum </a></li><li><a href="https://policylabs.frontiersin.org/" target="_blank" data-event="footer-block_2-a_frontiersPolicyLabs">Frontiers Policy Labs </a></li><li><a href="https://kids.frontiersin.org/" target="_blank" data-event="footer-block_2-a_frontiersForYoungMinds">Frontiers for Young Minds</a></li><li><a href="https://www.frontiersin.org/about/frontiers-planet-prize" target="_self" data-event="footer-block_2-a_frontiersPlanetPrize">Frontiers Planet Prize</a></li><!--]--></ul><!--]--></div></li><li class="Accordion__item"><button class="Accordion__headline"><!----><!--[--><div class="Accordion__title">Connect</div><div class="Accordion__space"></div><!--]--><div class="Accordion__arrow"></div></button><div class="Accordion__content Accordion__content--fadeOut" style="height:0px;"><!--[--><ul><!--[--><li><a href="https://helpcenter.frontiersin.org" target="_blank" data-event="footer-block_3-a_helpCenter">Help center</a></li><li><a href="https://subscription-management.frontiersin.org/emails/preferences#block0" target="_blank" data-event="footer-block_3-a_emailsAndAlerts">Emails and alerts </a></li><li><a href="https://www.frontiersin.org/about/contact" target="_self" data-event="footer-block_3-a_contactUs">Contact us </a></li><li><a href="https://www.frontiersin.org/submission/submit" target="_self" data-event="footer-block_3-a_submit">Submit</a></li><li><a href="https://careers.frontiersin.org/" target="_blank" data-event="footer-block_3-a_careerOpportunities">Career opportunities</a></li><!--]--></ul><!--]--></div></li><!--]--><!--]--></ul><div class="Footer__socialLinks"><div class="Footer__socialLinks__title">Follow us</div><!--[--><span class="Link__wrapper"><a class="Link Link--linkType Link--grey Link--medium Link--icon Link--facebook Link--right" aria-label="Frontiers Facebook" href="https://www.facebook.com/Frontiersin" target="_blank" data-event="footer-facebook-a_true"><span></span></a></span><span class="Link__wrapper"><a class="Link Link--linkType Link--grey Link--medium Link--icon Link--twitter Link--right" aria-label="Frontiers Twitter" href="https://twitter.com/frontiersin" target="_blank" data-event="footer-twitter-a_true"><span></span></a></span><span class="Link__wrapper"><a class="Link Link--linkType Link--grey Link--medium Link--icon Link--linkedin Link--right" aria-label="Frontiers LinkedIn" href="https://www.linkedin.com/company/frontiers" target="_blank" data-event="footer-linkedIn-a_true"><span></span></a></span><span class="Link__wrapper"><a class="Link Link--linkType Link--grey Link--medium Link--icon Link--instagram Link--right" aria-label="Frontiers Instagram" href="https://www.instagram.com/frontiersin_" target="_blank" data-event="footer-instagram-a_true"><span></span></a></span><!--]--></div></div><div class="Footer__copyright"><div><span>© 2025 Frontiers Media S.A. All rights reserved</span></div><div><a href="https://www.frontiersin.org/legal/privacy-policy" target="_blank">Privacy policy</a><span> | </span><a href="https://www.frontiersin.org/legal/terms-and-conditions" target="_blank">Terms and conditions</a></div></div></div></footer><div class="SnackbarWrapper"><div class="SnackbarManager"><!--[--><!--]--></div></div></div><noscript><iframe
            src="https://tag-manager.frontiersin.org/ns.html?id=GTM-M322FV2&gtm_auth=owVbWxfaJr21yQv1fe1cAQ&gtm_preview=env-1&gtm_cookies_win=x"
            height="0"
            width="0"
            style="display: none; visibility: hidden">
          </iframe></noscript><!--]--></div><div id="teleports"></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true">[["ShallowReactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverRendered":13,"path":14,"pinia":15},["ShallowReactive",3],{},["Reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","Frontiers articles","https://article-pages-2024.frontiersin.org/",["Set"],["ShallowReactive",12],{},true,"/journals/neuroscience/articles/10.3389/fnins.2017.00062/full",["Reactive",16],{"main":17,"user":508,"article":509,"articleHub":751,"mainHeader":755},{"ibar":18,"footer":272,"newsletterComponent":-1,"snackbarItem":354,"toggleShowSnackbar":355,"contentfulJournal":356,"graphJournal":409,"settingsFeaturesSwitchers":413,"templateToggleBanner":414,"tenantConfig":474},{"tenantLogo":19,"journalLogo":19,"aboutUs":20,"submitUrl":113,"showSubmitButton":13,"journal":114,"sectionTerm":203,"aboutJournal":204,"mainLinks":253,"journalLinks":260,"helpCenterLink":269},"",[21,38,47,71,87],{"title":22,"links":23},"Who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"ariaLabel":28},"Mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"ariaLabel":28},"History","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"ariaLabel":28},"Leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"ariaLabel":28},"Awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"Impact and progress",[41,44],{"text":42,"url":43,"target":27,"ariaLabel":28},"Frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"ariaLabel":28},"Our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"Publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"ariaLabel":28},"How we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"ariaLabel":28},"Open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"ariaLabel":28},"Peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"ariaLabel":28},"Research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"ariaLabel":28},"Research Topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"ariaLabel":28},"FAIR² Data Management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"ariaLabel":28},"Fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"Services",[74,78,81,84],{"text":75,"url":76,"target":77,"ariaLabel":28},"Societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"ariaLabel":28},"National consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"ariaLabel":28},"Institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"ariaLabel":28},"Collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"More from Frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"ariaLabel":93},"Frontiers Forum","https://forum.frontiersin.org/","this link will take you to the Frontiers Forum website",{"text":95,"url":96,"target":27,"ariaLabel":28},"Frontiers Planet Prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"ariaLabel":100},"Press office","https://pressoffice.frontiersin.org/","this link will take you to the Frontiers press office website",{"text":102,"url":103,"target":27,"ariaLabel":104},"Sustainability","https://www.frontiersin.org/about/sustainability","link to information about Frontiers' sustainability",{"text":106,"url":107,"target":77,"ariaLabel":108},"Career opportunities","https://careers.frontiersin.org/","this link will take you to the Frontiers careers website",{"text":110,"url":111,"target":27,"ariaLabel":112},"Contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=1&fieldid=55&specialtyid=0&entitytype=2&entityid=1",{"id":115,"name":116,"slug":117,"sections":118},1,"Frontiers in Neuroscience","neuroscience",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195,199],{"id":120,"name":121,"slug":122},65,"Auditory Cognitive Neuroscience","auditory-cognitive-neuroscience",{"id":124,"name":125,"slug":126},157,"Autonomic Neuroscience","autonomic-neuroscience",{"id":128,"name":129,"slug":130},600,"Brain Imaging Methods","brain-imaging-methods",{"id":132,"name":133,"slug":134},33,"Decision Neuroscience","decision-neuroscience",{"id":136,"name":137,"slug":138},2416,"Gut-Brain Axis","gut-brain-axis",{"id":140,"name":141,"slug":142},1206,"Neural Technology","neural-technology",{"id":144,"name":145,"slug":146},73,"Neurodegeneration","neurodegeneration",{"id":148,"name":149,"slug":150},1944,"Neurodevelopment","neurodevelopment",{"id":152,"name":153,"slug":154},113,"Neuroendocrine Science","neuroendocrine-science",{"id":156,"name":157,"slug":158},818,"Neuroenergetics and Brain Health","neuroenergetics-and-brain-health",{"id":160,"name":161,"slug":162},25,"Neurogenesis","neurogenesis",{"id":164,"name":165,"slug":166},19,"Neurogenomics","neurogenomics",{"id":168,"name":169,"slug":170},31,"Neuromorphic Engineering","neuromorphic-engineering",{"id":172,"name":173,"slug":174},26,"Neuropharmacology","neuropharmacology",{"id":176,"name":177,"slug":178},23,"Neuroprosthetics","neuroprosthetics",{"id":180,"name":181,"slug":182},3022,"Neuroscience Methods and Techniques","neuroscience-methods-and-techniques",{"id":184,"name":185,"slug":186},41,"Perception Science","perception-science",{"id":188,"name":189,"slug":190},1409,"Sleep and Circadian Rhythms","sleep-and-circadian-rhythms",{"id":192,"name":193,"slug":194},57,"Social and Evolutionary Neuroscience","social-and-evolutionary-neuroscience",{"id":196,"name":197,"slug":198},2450,"Translational Neuroscience","translational-neuroscience",{"id":200,"name":201,"slug":202},2411,"Visual Neuroscience","visual-neuroscience","Sections",[205,229],{"title":206,"links":207},"Scope",[208,211,214,217,220,223,226],{"text":209,"url":210,"target":27,"ariaLabel":28},"Field chief editors","https://www.frontiersin.org/journals/neuroscience/about#about-editors",{"text":212,"url":213,"target":27,"ariaLabel":28},"Mission & scope","https://www.frontiersin.org/journals/neuroscience/about#about-scope",{"text":215,"url":216,"target":27,"ariaLabel":28},"Facts","https://www.frontiersin.org/journals/neuroscience/about#about-facts",{"text":218,"url":219,"target":27,"ariaLabel":28},"Journal sections","https://www.frontiersin.org/journals/neuroscience/about#about-submission",{"text":221,"url":222,"target":27,"ariaLabel":28},"Open access statement","https://www.frontiersin.org/journals/neuroscience/about#about-open",{"text":224,"url":225,"target":27,"ariaLabel":28},"Copyright statement","https://www.frontiersin.org/journals/neuroscience/about#copyright-statement",{"text":227,"url":228,"target":27,"ariaLabel":28},"Quality","https://www.frontiersin.org/journals/neuroscience/about#about-quality",{"title":230,"links":231},"For authors",[232,235,238,241,244,247,250],{"text":233,"url":234,"target":27,"ariaLabel":28},"Why submit?","https://www.frontiersin.org/journals/neuroscience/for-authors/why-submit",{"text":236,"url":237,"target":27,"ariaLabel":28},"Article types","https://www.frontiersin.org/journals/neuroscience/for-authors/article-types",{"text":239,"url":240,"target":27,"ariaLabel":28},"Author guidelines","https://www.frontiersin.org/journals/neuroscience/for-authors/author-guidelines",{"text":242,"url":243,"target":27,"ariaLabel":28},"Editor guidelines","https://www.frontiersin.org/journals/neuroscience/for-authors/editor-guidelines",{"text":245,"url":246,"target":27,"ariaLabel":28},"Publishing fees","https://www.frontiersin.org/journals/neuroscience/for-authors/publishing-fees",{"text":248,"url":249,"target":27,"ariaLabel":28},"Submission checklist","https://www.frontiersin.org/journals/neuroscience/for-authors/submission-checklist",{"text":251,"url":252,"target":27,"ariaLabel":28},"Contact editorial office","https://www.frontiersin.org/journals/neuroscience/for-authors/contact-editorial-office",[254,257],{"text":255,"url":256,"target":27,"ariaLabel":28},"All journals","https://www.frontiersin.org/journals",{"text":258,"url":259,"target":27,"ariaLabel":28},"All articles","https://www.frontiersin.org/articles",[261,264,266],{"text":262,"url":263,"target":27,"ariaLabel":28},"Articles","articles",{"text":63,"url":265,"target":27,"ariaLabel":28},"research-topics",{"text":267,"url":268,"target":27,"ariaLabel":28},"Editorial board","editors",{"text":270,"url":271,"target":77,"ariaLabel":270},"Help center","https://helpcenter.frontiersin.org",{"blocks":273,"socialLinks":327,"copyright":351,"termsAndConditionsUrl":352,"privacyPolicyUrl":353},[274,288,298,312],{"title":275,"links":276},"Guidelines",[277,279,282,285,287],{"text":239,"url":278,"target":27,"ariaLabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":280,"url":281,"target":27,"ariaLabel":28},"Services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":283,"url":284,"target":27,"ariaLabel":28},"Policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":242,"url":286,"target":27,"ariaLabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"ariaLabel":28},{"title":289,"links":290},"Explore",[291,292,295,297],{"text":262,"url":259,"target":27,"ariaLabel":28},{"text":293,"url":294,"target":27,"ariaLabel":28},"Research Topics ","https://www.frontiersin.org/research-topics",{"text":296,"url":256,"target":27,"ariaLabel":28},"Journals",{"text":51,"url":52,"target":27,"ariaLabel":28},{"title":299,"links":300},"Outreach",[301,304,307,311],{"text":302,"url":92,"target":77,"ariaLabel":303},"Frontiers Forum ","Frontiers Forum website",{"text":305,"url":306,"target":77,"ariaLabel":28},"Frontiers Policy Labs ","https://policylabs.frontiersin.org/",{"text":308,"url":309,"target":77,"ariaLabel":310},"Frontiers for Young Minds","https://kids.frontiersin.org/","Frontiers for Young Minds journal",{"text":95,"url":96,"target":27,"ariaLabel":28},{"title":313,"links":314},"Connect",[315,316,320,323,326],{"text":270,"url":271,"target":77,"ariaLabel":270},{"text":317,"url":318,"target":77,"ariaLabel":319},"Emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","Subscribe to Frontiers emails",{"text":321,"url":111,"target":27,"ariaLabel":322},"Contact us ","Subscribe to newsletter",{"text":324,"url":325,"target":27,"ariaLabel":28},"Submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"ariaLabel":28},[328,336,341,346],{"link":329,"type":332,"color":333,"icon":334,"size":335,"hiddenText":13},{"text":330,"url":331,"target":77,"ariaLabel":330},"Frontiers Facebook","https://www.facebook.com/Frontiersin","Link","Grey","Facebook","Medium",{"link":337,"type":332,"color":333,"icon":340,"size":335,"hiddenText":13},{"text":338,"url":339,"target":77,"ariaLabel":28},"Frontiers Twitter","https://twitter.com/frontiersin","Twitter",{"link":342,"type":332,"color":333,"icon":345,"size":335,"hiddenText":13},{"text":343,"url":344,"target":77,"ariaLabel":28},"Frontiers LinkedIn","https://www.linkedin.com/company/frontiers","LinkedIn",{"link":347,"type":332,"color":333,"icon":350,"size":335,"hiddenText":13},{"text":348,"url":349,"target":77,"ariaLabel":28},"Frontiers Instagram","https://www.instagram.com/frontiersin_","Instagram","Frontiers Media S.A. All rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":357,"identifier":115,"name":116,"slug":117,"banner":358,"description":402,"mission":403,"palette":404,"impactFactor":405,"citeScore":406,"citations":407,"showTagline":28,"twitter":408},"Journal",[359],{"id":360,"src":361,"name":362,"type":363,"width":364,"height":365,"idHash":366,"archive":367,"brandId":368,"limited":367,"fileSize":369,"isPublic":115,"original":370,"copyright":19,"extension":371,"thumbnails":373,"dateCreated":381,"description":19,"orientation":382,"userCreated":383,"watermarked":367,"dateModified":381,"datePublished":384,"ecsArchiveFiles":385,"propertyOptions":386,"property_Channel":391,"property_Sub-Type":393,"property_Asset_Type":395,"activeOriginalFocusPoint":397,"property_Office_Department":400},"27A044CC-44D1-4E5E-A886893A3FE656F4","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/webimage-731DCAD7-7D53-4C7A-ABED6B270359A65F.png","FNINS_Main Visual_Purple_Website","image",6788,4865,"18e4eb8ad56b508b",0,"22C10171-81B3-4DA6-99342F272A32E8BB",12200641,"https://brand.frontiersin.org/m/18e4eb8ad56b508b/original/FNINS_Main-Visual_Purple_Website.jpg",[372],"jpg",{"mini":374,"thul":375,"webimage":361,"Guidelines":376,"WebsiteJpg_XL":377,"WebsiteWebP_L":378,"WebsiteWebP_M":379,"WebsiteWebP_XL":380},"https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/mini-64E6EA95-B7B1-4005-AB72061E18A6F830.png","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/thul-38432C11-11F0-4DA5-B8C0EBF0A1603722.png","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/A72D78D9-73CD-4C75-910FB7C0D04825C0/Guidelines-FNINS_Main Visual_Purple_Website.png","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/A72D78D9-73CD-4C75-910FB7C0D04825C0/WebsiteJpg_XL-FNINS_Main Visual_Purple_Website.jpg","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/A72D78D9-73CD-4C75-910FB7C0D04825C0/WebsiteWebP_L-FNINS_Main Visual_Purple_Website.webp","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/A72D78D9-73CD-4C75-910FB7C0D04825C0/WebsiteWebP_M-FNINS_Main Visual_Purple_Website.webp","https://d2csxpduxe849s.cloudfront.net/media/E32629C6-9347-4F84-81FEAEF7BFA342B3/27A044CC-44D1-4E5E-A886893A3FE656F4/A72D78D9-73CD-4C75-910FB7C0D04825C0/WebsiteWebP_XL-FNINS_Main Visual_Purple_Website.webp","2022-06-27T10:00:29Z","landscape","Caroline Sutter","2022-06-27T09:27:09Z",[],[387,388,389,390],"414FB2D4-2283-43FD-BE14E534ECA67928","6C18119B-14BD-4951-B437696F4357BD33","7C692885-DB25-4858-B1FB4FF47B241E9B","D88C0047-EC30-4506-A7DF28A4D765E1CF",[392],"frontiersin_org",[394],"Main_Visual",[396],"Photography",{"x":398,"y":399},3394,2433,[401],"Publishing","Part of the most cited neuroscience journal series which explores the brain - from the new eras of causation and anatomical neurosciences to neuroeconomics and neuroenergetics.","\u003Cp>Frontiers in Neuroscience is a leading multidisciplinary journal that publishes research across a wide range of spectrum of specialities and disciplines in the field of neuroscience.\u003C/p>\n\n\u003Cp>Led by Field Chief Editor, Professor Idan Segev (Hebrew University of Jerusalem, Israel) and indexed in PubMed Central (PMC), Web of Science (SCIE), and Scopus among others, the journal provides a comprehensive understanding of brain functions, from genes to behavior, and aims to tighten the links between various domains of neuroscience and advance conceptual and technological developments in the field.\u003C/p>\n\n\u003Cp>Topics of interest include, but are not limited to:\u003C/p>\n\n\u003Cul>\n  \u003Cli>autonomic function and brain energy homeostasis\u003C/li>\n  \u003Cli>neural development and degeneration\u003C/li>\n  \u003Cli>neuroengineering including neuromorphic engineering and neuroprosthetics\u003C/li>\n  \u003Cli>novel brain imaging methods from the subcellular level (e.g. genetically encoded voltage- and ions indicators) to the whole brain level (e.g. large-scale micro-electrode arrays and direct imaging of neuronal activity at the cellular level by fMRI)\u003C/li>\n  \u003Cli>sensory perception and cognition.\u003C/li>\n  \u003Cli>translational neuroscience\u003C/li>\n\u003C/ul>\n\n\u003Cp>Studies on the convergence of novel molecular and optical techniques, and developments in anatomical methods, both at the whole-brain level (“connectome”) and the local circuit and synaptic level (“connectomics”) are of particular interest.  Approaches that allow us to link the structure of local circuits at specific brain regions to function are encouraged.\u003C/p>\n\n\u003Cp>The journal also welcomes submissions which support and advance the UN’s Sustainable Development Goals (SDGs), notably SDG 3: to ensure healthy lives and promote well-being for all at all ages. Studies that propose ways to promote mental health and prevent neurodegenerative diseases are of particular interest.\u003C/p>\n\n\u003Cp>Studies that focus on clinical trials, medical treatments, or the application of medical techniques without neuroscientific foundations are not within the scope of the journal. Similarly, studies that primarily investigate the effects of traditional medicine on health conditions, without exploring the underlying neurological mechanisms, fall outside of the journal scope.\u003C/p>\n\n\u003Cp>Frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. Please refer to the \u003Ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,Standards%20for%20research%20methodology,-Experiments\">Frontiers Standards for research methodology policy\u003C/a>, for more information. Manuscripts not adhering to these standards will not be considered.\u003Cp>\n\n\u003Cp>Frontiers in Neuroscience is committed to advancing developments in the field by allowing unrestricted access to research articles and communicating scientific knowledge to researchers and the public alike, to enhance scientific understanding and repairing the brain.\u003C/p>","purple","4.3","6.8","381571","@FrontNeurosci",{"id":115,"name":116,"slug":117,"abbreviation":410,"isOnline":13,"isOpenForSubmissions":13,"citeScore":411,"impactFactor":412},"fnins",6.6,3.2,{"displayTitlePillLabels":13,"displayRelatedArticlesBox":13,"showEditors":13,"showReviewers":13,"showLoopImpactLink":13,"enableFigshare":355,"useXmlImages":13},{"isPublic":13,"allowCompanyUsers":355,"whiteListEmails":415,"enableAllJournals":13,"whiteListJournals":437},[416,417,418,419,420,421,422,423,424,421,425,426,427,428,429,430,431,432,433,434,435,436],"Y2FybG9zLmxvcmNhQGZyb250aWVyc2luLm9yZw==","ZGFuaWVsLmx1ekBmcm9udGllcnNpbi5vcmc=","bGF1cmEudGVuYUBmcm9udGllcnNpbi5vcmc=","cmFmYWVsLnJpYW5jaG9AZnJvbnRpZXJzaW4ub3Jn","amFtZXMuc21hbGxib25lQGZyb250aWVyc2luLm9yZw==","ZnJhbi5tb3Jlbm9AZnJvbnRpZXJzaW4ub3Jn","c2FtdWVsLmZlcm5hbmRlekBmcm9udGllcnNpbi5vcmc=","YmFyYmFyYS5jYXJjYW5naXVAZnJvbnRpZXJzaW4ub3Jn","aXZhbi5zYW50YW1hcmlhQGZyb250aWVyc2luLm9yZw==","aHVlLnRyYW5AZnJvbnRpZXJzaW4ub3Jn","Z29uY2Fsby52YXJnYXNAZnJvbnRpZXJzaW4ub3Jn","bHVjaWUuc2VubkBmcm9udGllcnNpbi5vcmc=","bG9ybi5mcmFzZXJAZnJvbnRpZXJzaW4ub3Jn","ZWxzYS5jYXJyb25AZnJvbnRpZXJzaW4ub3Jn","bWFhcnRlbi52YW5kaWpja0Bmcm9udGllcnNpbi5vcmc=","YmluZGh1LmtyaXNobmFuQGZyb250aWVyc2luLm9yZw==","bWF0dGhldy5hdHR3YXRlcnNAZnJvbnRpZXJzaW4ub3Jn","Z2l1bGlhLnZhbHNlY2NoaUBmcm9udGllcnNpbi5vcmc=","ZmFiaWFuLmRlbGxhbW9ydGVAZnJvbnRpZXJzaW4ub3Jn","dmlqYXlhbi5wcEBwaXRzb2x1dGlvbnMuY29t","Z3VpbGxhdW1lLnNldXJhdEBmcm9udGllcnNpbi5vcmc=",[438,439,440,441,442,443,115,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473],2232,1729,2357,2456,2176,2333,1843,602,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceId":115,"name":115,"availableJournalPages":475,"announcement":478},[263,268,265,476,477],"volumes","about",{"__typename":479,"sys":480,"preHeader":42,"title":482,"description":483,"image":484,"link":506},"Announcement",{"id":481},"5ITtnTtQgAzPPGH6rX0AlM","Articles published with Frontiers have received 12 million total citations","Your research is the real superpower - learn how we maximise its impact through our leading community journals",[485],{"archive":367,"brandId":368,"copyright":28,"dateCreated":486,"dateModified":487,"datePublished":488,"description":28,"extension":489,"fileSize":491,"height":492,"id":493,"isPublic":367,"limited":367,"name":494,"orientation":382,"original":28,"thumbnails":495,"type":363,"watermarked":367,"width":502,"videoPreviewURLs":503,"tags":504,"textMetaproperties":505,"src":496},"2025-06-18T12:58:01Z","2025-06-18T14:15:34Z","2025-06-18T12:57:32Z",[490],"png",1365026,920,"7C5269C4-3C83-4591-951A74D15B95DAEA","Impact metrics banner for article pages",{"webimage":496,"thul":497,"mini":498,"WebsiteWebP_L":499,"WebsiteWebP_M":500,"Guidelines":501},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-Impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-Impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-Impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/WebsiteWebP_L/Impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/WebsiteWebP_M/Impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/Guidelines/Impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":507,"url":43,"target":27,"ariaLabel":28},"Explore our impact metrics",{"loggedUserInfo":-1},{"currentArticle":510,"isPreviewPage":355,"hasSupplementalData":355,"showCrossmarkWidget":13,"articleTemplate":636,"currentArticlePageMetaInfo":637,"xmlParsedArticleContent":-1,"xmlParsingError":-1},{"id":511,"doi":512,"title":513,"acceptanceDate":514,"receptionDate":515,"publicationDate":516,"lastModifiedDate":517,"isPublished":13,"abstract":518,"researchTopic":28,"articleType":519,"stage":522,"keywords":524,"authors":530,"editors":562,"reviewers":572,"journal":591,"section":598,"impactMetrics":600,"volume":604,"articleVolume":605,"relatedArticles":606,"isPublishedV2":355,"contents":607,"files":610,"htmlZipFileName":635},209792,"10.3389/fnins.2017.00062","Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding","2017-01-27T08:13:41.000Z","2016-06-14T10:12:32.000Z","2017-02-17T00:00:00.000Z","2025-10-05T05:01:55.993Z","Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional spatial and temporal constraints in the predictive model and carry the promise of being more interpretable than non-structured sparse methods, such as LASSO or Elastic Net methods. However, although sparsity has often been advocated as leading to more interpretable models it can also lead to unstable models under subsampling or slight changes of the experimental conditions. \n\nIn the present work we investigated the impact of using stability/reproducibility as an additional model selection criterion on several different sparse (and structured sparse) methods that have been recently applied for fMRI brain decoding. We compared three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions; (iii) classification accuracy and correlation between the solutions. The methods we considered include LASSO, Elastic Net, Total Variation, sparse Total Variation, Laplacian and Graph Laplacian Elastic Net (GraphNET).\n\nOur results show that explicitly accounting for stability/reproducibility during the model optimisation can mitigate some of the instability inherent in sparse methods. In particular, using accuracy and overlap between the solutions as a joint optimisation criterion can lead to solutions that are more similar in terms of accuracy, sparsity levels and coefficient maps even when different sparsity methods are considered.",{"id":520,"name":521},24,"Original Research",{"id":523,"name":19},18,[525,526,527,528,529],"Sparse methods","structured sparsity","Model selection","reproducibility","predictive models",[531,540,552],{"id":532,"firstName":533,"middleName":19,"lastName":534,"givenNames":535,"isCorresponding":355,"isProfilePublic":13,"userId":532,"email":-1,"affiliations":536},357845,"Luca","Baldassarre","Luca ",[537],{"organizationName":538,"countryName":539,"cityName":19,"stateName":19,"zipCode":19},"Laboratory for Information and Inference Systems, École Polytechnique Fédérale de Lausanne (EPFL)","Lausanne, Switzerland",{"id":541,"firstName":542,"middleName":19,"lastName":543,"givenNames":544,"isCorresponding":355,"isProfilePublic":13,"userId":541,"email":-1,"affiliations":545},368732,"Massimiliano","Pontil","Massimiliano ",[546,549],{"organizationName":547,"countryName":548,"cityName":19,"stateName":19,"zipCode":19},"Istituto Italiano di Tecnologia","Genoa, Italy",{"organizationName":550,"countryName":551,"cityName":19,"stateName":19,"zipCode":19},"Department of Computer Science, University College London","London, UK",{"id":553,"firstName":554,"middleName":19,"lastName":555,"givenNames":556,"isCorresponding":13,"isProfilePublic":13,"userId":553,"email":557,"affiliations":558},63987,"Janaina","Mourão-Miranda","Janaina ","j.mourao-miranda@ucl.ac.uk",[559,560],{"organizationName":550,"countryName":551,"cityName":19,"stateName":19,"zipCode":19},{"organizationName":561,"countryName":551,"cityName":19,"stateName":19,"zipCode":19},"Max Planck University College London Centre for Computational Psychiatry and Ageing Research, University College London",[563],{"id":564,"firstName":565,"middleName":19,"lastName":566,"givenNames":567,"isCorresponding":355,"isProfilePublic":13,"userId":564,"email":-1,"affiliations":568},53467,"Bertrand","Thirion","Bertrand ",[569],{"organizationName":570,"countryName":571,"cityName":19,"stateName":19,"zipCode":19},"Institut National de Recherche en Informatique et en Automatique (INRIA)","France",[573,582],{"id":574,"firstName":575,"middleName":19,"lastName":576,"givenNames":577,"isCorresponding":355,"isProfilePublic":13,"userId":574,"email":-1,"affiliations":578},49944,"Danilo","Bzdok","Danilo ",[579],{"organizationName":580,"countryName":581,"cityName":19,"stateName":19,"zipCode":19},"Julich Research Center, Helmholtz Association of German Research Centres (HZ)","Germany",{"id":583,"firstName":584,"middleName":19,"lastName":585,"givenNames":586,"isCorresponding":355,"isProfilePublic":13,"userId":583,"email":-1,"affiliations":587},77204,"Bernard","Ng","Bernard ",[588],{"organizationName":589,"countryName":590,"cityName":19,"stateName":19,"zipCode":19},"University of British Columbia","Canada",{"id":115,"slug":117,"name":116,"shortName":592,"electronicISSN":593,"field":594,"specialtyId":28,"journalSectionPaths":596},"Front. Neurosci.","1662-453X",{"id":595,"domainId":115},55,[597],{"section":598},{"id":128,"name":129,"slug":130,"specialtyId":599},1304,{"views":601,"downloads":602,"citations":603},8502,1507,39,11,"Volume 11 - 2017",[],{"titleHtml":513,"fullTextHtml":608,"menuHtml":609},"\u003Cdiv class=\"JournalAbstract\">\r\n\u003Ca id=\"h1\" name=\"h1\">\u003C/a>\r\n\u003Cdiv class=\"authors\">\u003Cspan class=\"author-wrapper notranslate\">\r\n\u003Ca href=\"https://loop.frontiersin.org/people/357845\" class=\"user-id-357845\">\u003Cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/357845/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"\r\nLuca Baldassarre\">Luca Baldassarre\u003C/a>\u003Csup>1\u003C/sup>\u003C/span>\u003Cspan class=\"author-wrapper notranslate\">\u003Ca href=\"https://loop.frontiersin.org/people/368732\" class=\"user-id-368732\">\u003Cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/368732/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"Massimiliano Pontil,\">Massimiliano Pontil\u003C/a>\u003Csup>2,3\u003C/sup>\u003C/span>\u003Cspan class=\"author-wrapper notranslate\">\u003Ca href=\"https://loop.frontiersin.org/people/63987\" class=\"user-id-63987\">\u003Cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/63987/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"Janaina Mour&#xE;o-Miranda,*\">Janaina Mour&#x000E3;o-Miranda\u003C/a>\u003Csup>3,4\u003C/sup>\u003Csup>*\u003C/sup>\u003C/span>\u003C/div>\r\n\u003Cul class=\"notes\">\r\n\u003Cli>\u003Cspan>\u003Csup>1\u003C/sup>\u003C/span>Laboratory for Information and Inference Systems, &#x000C9;cole Polytechnique F&#x000E9;d&#x000E9;rale de Lausanne (EPFL), Lausanne, Switzerland\u003C/li>\r\n\u003Cli>\u003Cspan>\u003Csup>2\u003C/sup>\u003C/span>Istituto Italiano di Tecnologia, Genoa, Italy\u003C/li>\r\n\u003Cli>\u003Cspan>\u003Csup>3\u003C/sup>\u003C/span>Department of Computer Science, University College London, London, UK\u003C/li>\r\n\u003Cli>\u003Cspan>\u003Csup>4\u003C/sup>\u003C/span>Max Planck University College London Centre for Computational Psychiatry and Ageing Research, University College London, London, UK\u003C/li>\r\n\u003C/ul>\r\n\u003Cp>Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional spatial and temporal constraints in the predictive model and carry the promise of being more interpretable than non-structured sparse methods, such as LASSO or Elastic Net methods. However, although sparsity has often been advocated as leading to more interpretable models it can also lead to unstable models under subsampling or slight changes of the experimental conditions. In the present work we investigate the impact of using stability/reproducibility as an additional model selection criterion\u003Csup id=\"footnotesuper1\">\u003Ca id=\"note1a\">\u003C/a>\u003Ca class=\"footnoteanchor\" href=\"#note1\" style=\"color:grey;\">1\u003C/a>\u003C/sup> on several different sparse (and structured sparse) methods that have been recently applied for fMRI brain decoding. We compare three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions; (iii) classification accuracy and correlation between the solutions. The methods we consider include LASSO, Elastic Net, Total Variation, sparse Total Variation, Laplacian and Graph Laplacian Elastic Net (GraphNET). Our results show that explicitly accounting for stability/reproducibility during the model optimization can mitigate some of the instability inherent in sparse methods. In particular, using accuracy and overlap between the solutions as a joint optimization criterion can lead to solutions that are more similar in terms of accuracy, sparsity levels and coefficient maps even when different sparsity methods are considered.\u003C/p>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003C/div>\r\n\u003Cdiv class=\"JournalFullText\">\r\n\u003Ca id=\"h2\" name=\"h2\">\u003C/a>\u003Ch2>1. Introduction\u003C/h2>\r\n\u003Cp class=\"mb15\">Supervised machine learning techniques are being increasingly used in neuroimaging analysis for their inherent ability to deal with multivariate data, higher sensibility and possibility of incorporating specific prior-information.\u003C/p>\r\n\u003Cp class=\"mb15\">Given the high-dimensionality of neuroimaging, and the few number of samples, regularized linear models have been applied in order to produce effective predictive models (\u003Ca href=\"#B28\">Mourao-Miranda et al., 2006\u003C/a>, \u003Ca href=\"#B27\">2007\u003C/a>; \u003Ca href=\"#B15\">Grosenick et al., 2011\u003C/a>; \u003Ca href=\"#B25\">Michel et al., 2011\u003C/a>). However, ordinary linear models, such as, the Least Squares Ridge Regression (\u003Ca href=\"#B39\">Tikhonov and Arsenin, 1977\u003C/a>) or standard Support Vector Machines (SVMs) (\u003Ca href=\"#B8\">Cortes and Vapnik, 1995\u003C/a>) employ an l2 regularization scheme, hence they are incapable of discriminating which areas (or voxels) of the brain mostly contribute to the model&#x00027;s predictions. In other words, these models are dense, in the sense that they use the information contained in the entire voxel set to generate a predictive function.\u003C/p>\r\n\u003Cp class=\"mb15\">Sparse methods, like the LASSO (\u003Ca href=\"#B38\">Tibshirani, 1996\u003C/a>) or the Elastic Net (\u003Ca href=\"#B43\">Zou and Hastie, 2005\u003C/a>), are able to estimate solutions for which only few voxels are deemed relevant, therefore aiding interpretation. However, often these models provide overly sparse solutions, where the non-zero coefficients are assigned to disparate regions across the brain, without exploiting any spatial or temporal prior information (\u003Ca href=\"#B15\">Grosenick et al., 2011\u003C/a>; \u003Ca href=\"#B25\">Michel et al., 2011\u003C/a>; \u003Ca href=\"#B31\">Rasmussen et al., 2012\u003C/a>).\u003C/p>\r\n\u003Cp class=\"mb0\">Structured sparsity models (\u003Ca href=\"#B7\">Chambolle, 2004\u003C/a>; \u003Ca href=\"#B2\">Bach et al., 2011\u003C/a>; \u003Ca href=\"#B3\">Baldassarre et al., 2012a\u003C/a>; \u003Ca href=\"#B24\">Micchelli et al., 2013\u003C/a>) extend the well-known methods of LASSO by encouraging models which are sparse in some preferred way, e.g., the non-zero regression coefficients may be preferred to be associated to the same brain region or nearby voxels. Furthermore, the coefficients may be encouraged to be constant or vary smoothly within regions of the brain. Despite sparsity has traditionally been connected with interpretability, in the sense that sparser models are easier to interpret, these new structured sparsity models promise an even greater ease of interpretation of the coefficient maps, because the active voxels are grouped together in possibly few clusters, which fits well with our knowledge about the brain&#x00027;s specialized regions and networks. These method hence have the potential to further improve out-of-sample performance in comparison to standard sparsity methods such as the LASSO.\u003C/p>\r\n\u003Ch3>1.1. Structured Sparse Models in Neuroimaging\u003C/h3>\r\n\u003Cp class=\"mb15\">Recently, (structured) sparsity methods have received significant attention in neuroimaging, see \u003Ca href=\"#B13\">Gramfort et al. (2013)\u003C/a>, \u003Ca href=\"#B26\">Mohr et al. (2015)\u003C/a>, \u003Ca href=\"#B5\">Belilovsky et al. (2015)\u003C/a>, \u003Ca href=\"#B21\">Jenatton et al. (2012)\u003C/a>, \u003Ca href=\"#B19\">Hoyos-Idrobo et al. (2015)\u003C/a>, \u003Ca href=\"#B9\">Dohmatob et al. (2014)\u003C/a>, and \u003Ca href=\"#B14\">Grosenick et al. (2013)\u003C/a> and references therein. For example \u003Ca href=\"#B20\">Jenatton et al. (2011)\u003C/a> investigated the benefits of using hierarchical structured sparsity for brain decoding, taking into account the spatial and multi-scale structure of the fMRI data. Their proposed approach yielded similar or higher prediction accuracy than the compared approaches (l1 and squared l2 regularization penalties), and the obtained map of weights or coefficients exhibited a cluster-like structure. \u003Ca href=\"#B12\">Fiot et al. (2014)\u003C/a> compared a number of structured sparse methods (Sobolev, total variation, fused LASSO) with regularization methods which do no take into account the spatial structure (LASSO, Ridge and Elastic-Net) on a clinical classification problem. Their results showed that the structured sparse approaches can lead to coherent and improved coefficient maps with better classification performance than the ones obtained with the standard regularization methods.\u003C/p>\r\n\u003Cp class=\"mb15\">\u003Ca href=\"#B26\">Mohr et al. (2015)\u003C/a> presented a comparison of different sparse and non sparse regularization methods for brain decoding. They focused on a classification problem and use the Logistic Loss or Hinge Loss (SVMs). The authors argued that l1 regularization can improve classification performance over l2 approaches (using SVM as an example of an l2 approach) as well as improve model interpretability. In addition, by considering the 3D structure of fMRI data, even better interpretability of the weights or coefficient maps could be possible. For this purpose, one more promising method which was not considered in \u003Ca href=\"#B26\">Mohr et al. (2015)\u003C/a> is sparse total variation. This method has been suggested in the context of fMRI by \u003Ca href=\"#B4\">Baldassarre et al. (2012b)\u003C/a> as means to learn interpretable and more stable brain maps. Further work investigating applications of sparse total variation in this context include \u003Ca href=\"#B13\">Gramfort et al. (2013)\u003C/a>, \u003Ca href=\"#B9\">Dohmatob et al. (2014)\u003C/a>, and \u003Ca href=\"#B10\">Eickenberg et al. (2015)\u003C/a>.\u003C/p>\r\n\u003Cp class=\"mb15\">Despite of all the evidence that sparsity and structured sparsity can lead to predictive models that are easier to interpret, sparsity alone is not sufficient for making reasonable inferences as sparse models can be unstable under subsampling or slight changes of the experimental conditions. One key source of instability is correlation between features, a problem specific to multivariate methods but not univariate methods. However, univariate methods are often too simplistic and may be suboptimal. Another difficulty with sparse models is that there are many possible ways of imposing sparsity or structured sparsity in predictive models. Finding the ideal sparsity for a specific problem is therefore a model selection problem. A common difficulty in neuroimaging applications is that often different models lead to very similar generalization performance (e.g., accuracy), then it becomes difficult to choose the best model and identify the &#x0201C;true brain map&#x0201D; of informative or predictive regions. Some authors have used the capacity to recover the &#x0201C;best brain regions&#x0201D; as alternative criterion to evaluate the models. In theses cases the &#x0201C;best regions&#x0201D; are based either on prior knowledge about the problem or univariate statistical tests applied to the data, both of which might not correspond to the ground truth. In fact, in most neuroimaging applications we do not know a-priori which regions are expected to be relevant for prediction therefore alternative approaches for model comparison are necessary.\u003C/p>\r\n\u003Cp class=\"mb15\">One way to increase the stability or reproducibility of sparse models is to explicitly account for it during the model selection procedure. The use of a tradeoff between accuracy and reproducibility as a model selection criterion has been previously proposed in neuroimaging (e.g., \u003Ca href=\"#B35\">Strother et al., 2002\u003C/a>; \u003Ca href=\"#B31\">Rasmussen et al., 2012\u003C/a>). For example, in \u003Ca href=\"#B31\">Rasmussen et al. (2012)\u003C/a>, the authors investigated the relative influence of model regularization parameter choices on both the model generalization and the reliability of the spatial patterns (coefficient maps) extracted from a classification model. Building upon their work, we advocate stability/reproducibility as the natural counterpart of sparsity in order to obtain interpretable inferences from sparse supervised learning methods.\u003C/p>\r\n\u003Cp class=\"mb0\">The issue of improving interpretability and stability of predictive brain maps has also been studied from a different perspective by \u003Ca href=\"#B19\">Hoyos-Idrobo et al. (2015)\u003C/a> and \u003Ca href=\"#B41\">Wang et al. (2014)\u003C/a>. In \u003Ca href=\"#B19\">Hoyos-Idrobo et al. (2015)\u003C/a> the authors focused on feature clustering and bagging as a means to improve stability of l1 regularization and interpretability of the associated brain maps. In \u003Ca href=\"#B41\">Wang et al. (2014)\u003C/a> the authors proposed a &#x0201C;randomized structural sparsity,&#x0201D; incorporating the idea of structural sparsity in the stability selection framework. They demonstrated that their proposed approach can achieve better control of false positives and false negatives than alternative methods.\u003C/p>\r\n\u003Ch3>1.2. Our Contribution\u003C/h3>\r\n\u003Cp class=\"mb15\">In this paper, we investigate the role of model selection criteria on different sparsity (and structured sparsity) methods that have been recently applied for decoding fMRI data, including one we proposed in a previous work (\u003Ca href=\"#B4\">Baldassarre et al., 2012b\u003C/a>), and assess their performance with respect to accuracy, sparsity and reproducibility. In order to investigate the impact of using reproducibility as an additional criterion for model selection, we compare three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions (or coefficient maps); (iii) classification accuracy and correlation between the solutions (or coefficient maps). The methods we consider include LASSO (\u003Ca href=\"#B38\">Tibshirani, 1996\u003C/a>), Elastic Net (\u003Ca href=\"#B43\">Zou and Hastie, 2005\u003C/a>), Total Variation (\u003Ca href=\"#B25\">Michel et al., 2011\u003C/a>), Graph Laplacian Elastic Net (GraphNET) (\u003Ca href=\"#B15\">Grosenick et al., 2011\u003C/a>) and sparse Total Variation (\u003Ca href=\"#B4\">Baldassarre et al., 2012b\u003C/a>). For our comparison, we use a dataset of fMRI scans collected from 16 healthy volunteers while watching pleasant or unpleasant images (\u003Ca href=\"#B28\">Mourao-Miranda et al., 2006\u003C/a>, \u003Ca href=\"#B27\">2007\u003C/a>; \u003Ca href=\"#B16\">Hardoon et al., 2007\u003C/a>).\u003C/p>\r\n\u003Cp class=\"mb15\">Model selection is performed by a Leave-One-Subject-Out Cross-Validation (LOSO-CV) scheme, which we describe in detail in the methods section. Although regularization helps to reduce model variance, the value of the regularization parameter(s) which yield a maximal accuracy model varies across the cross-validation folds, resulting in models with varying degree of sparsity and sets of selected variables (voxels). A main point of this paper is to show that this instability effect can be substantially reduced by employing a different model selection criterion which involves accuracy and &#x0201C;reproducibility&#x0201D; simultaneously. Specifically, we discuss the relevance of our findings with respect to using classification accuracy as a proxy for statistical significance of a given model. Our results suggest that the model selection criterion plays a more important role than the choice of the sparsity or structured sparsity. When using sparsity and overlap between the solutions as a joint optimization criterion the solutions for different methods became very similar in terms of accuracy, sparsity levels and coefficient maps. These results demonstrate the added value of accounting for reproducibility/stability in addition to generalization performance during model selection in supervising learning models.\u003C/p>\r\n\u003Cp class=\"mb0\">The paper is organized in the following manner. In Section 2 we present the sparse (and structured) methods, experimental protocol, model selection criteria and dataset. We present the results in Section 3 and the discussion in Section 4.\u003C/p>\r\n\u003Ca id=\"h3\" name=\"h3\">\u003C/a>\u003Ch2>2. Materials and Methods\u003C/h2>\r\n\u003Ch3 class=\"pt0\">2.1. Supervised Learning for Classification\u003C/h3>\r\n\u003Cp class=\"mb15\">Given a training set of input-output pairs \u003Cmath>\u003Cmrow>\u003Cmi mathvariant=\"-tex-caligraphic\">D\u003C/mi>\u003C/mrow>\u003Cmo>=\u003C/mo>\u003Cmsubsup>\u003Cmrow>\u003Cmrow>\u003Cmo>{\u003C/mo>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi>x\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>,\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>y\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmo>}\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi>m\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003C/math>, with \u003Cmath>\u003Cmsub>\u003Cmrow>\u003Cmi>x\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>&#x02208;\u003C/mo>\u003Cmsup>\u003Cmrow>\u003Cmi>&#x0211D;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>p\u003C/mi>\u003C/mrow>\u003C/msup>\u003C/math> and \u003Ci>y\u003C/i>\u003Csub>\u003Ci>i\u003C/i>\u003C/sub> &#x02208; &#x0211D;, a supervised learning method infers the relationship between \u003Ci>x\u003C/i> and \u003Ci>y\u003C/i> by estimating a function \u003Ci>f\u003C/i> : &#x0211D;\u003Csup>\u003Ci>p\u003C/i>\u003C/sup> &#x02192; &#x0211D; such that, for every \u003Ci>x\u003C/i> &#x02208; &#x0211D;\u003Csup>\u003Ci>p\u003C/i>\u003C/sup>, \u003Ci>f\u003C/i>(\u003Ci>x\u003C/i>) provides the prediction of \u003Ci>y\u003C/i> given \u003Ci>x\u003C/i>.\u003C/p>\r\n\u003Cp class=\"mb15\">In neuroimaging studies, the input \u003Ci>x\u003C/i>\u003Csub>\u003Ci>i\u003C/i>\u003C/sub> represents the brain scans in vector format and the number of variables \u003Ci>p\u003C/i> corresponds to the number of recorded voxels. In the present paper we consider a binary classification task, so that \u003Ci>y\u003C/i> &#x02208; {&#x02212;1, 1}, but our results can easily be extended to the regression or the multi-class setting. Furthermore, we limit our analysis to linear models, so that the decision function can be written as \u003Ci>f\u003C/i>(\u003Ci>x\u003C/i>) = sign(\u003Ci>x\u003C/i>\u003Csup>\u003Ci>T\u003C/i>\u003C/sup>&#x003B2;), where &#x003B2; &#x02208; &#x0211D;\u003Csup>\u003Ci>p\u003C/i>\u003C/sup> is a vector of coefficients to be estimated, one associated to each voxel.\u003C/p>\r\n\u003Cp class=\"mb15\">The aim of a machine learning algorithm is to find a coefficient vector &#x003B2; able to classify new examples and with specific properties such as sparsity (i.e., few non-zero coefficients) or smoothness. Regularization methods find &#x003B2; by minimizing an objective function consisting of a data fit term \u003Ci>E\u003C/i>(&#x003B2;) and a penalty term &#x003A9;(&#x003B2;) that favors certain properties and improves the generalization over unseen examples (outside the training set \u003Cmath>\u003Cmrow>\u003Cmi mathvariant=\"-tex-caligraphic\">D\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/math>.\u003C/p>\r\n\u003Cp class=\"mb0\">As data fitting term we consider the square loss that can be concisely written as\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M1\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">E\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">m\u003C/mi>\u003C/mrow>\u003C/mfrac>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">X\u003C/mi>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">Y\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsubsup>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msubsup>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">where \u003Ci>X\u003C/i> &#x02208; &#x0211D;\u003Csup>\u003Ci>m\u003C/i>&#x000D7;\u003Ci>p\u003C/i>\u003C/sup> is the matrix that contains the training examples as rows and \u003Cmath>\u003Cmi>Y\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi>y\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo>,\u003C/mo>\u003Cmo>&#x02026;\u003C/mo>\u003Cmo>,\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>y\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>m\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi>T\u003C/mi>\u003C/mrow>\u003C/msup>\u003C/math> is the column vector formed by the target variables.\u003C/p>\r\n\u003Ch3>2.2. Structured Sparsity Models\u003C/h3>\r\n\u003Cp class=\"mb0\">Note that, since for a linear model each regression coefficient is associated to a voxel, the vector &#x003B2; can also be interpreted as 3D matrix of the same size as the brain scans and we use this 3D structure to define particular penalty functions &#x003B2; &#x021A6; &#x003A9;(&#x003B2;). We define the &#x02113;\u003Csub>1\u003C/sub> norm of &#x003B2; as \u003Cmath>\u003Cmo>|\u003C/mo>\u003Cmo>|\u003C/mo>\u003Cmi>&#x003B2;\u003C/mi>\u003Cmo>|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo>|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo>=\u003C/mo>\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo>&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi>p\u003C/mi>\u003C/mrow>\u003C/munderover>\u003Cmo>|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>|\u003C/mo>\u003C/math>; the discrete gradient of &#x003B2; in 3 dimensions as &#x02207;&#x003B2;, with\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M2\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmsubsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02207;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003Cmtr>\u003Cmtd>\u003Cmsubsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02207;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003Cmtr>\u003Cmtd>\u003Cmsubsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02207;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">3\u003C/mn>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">k\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">and \u003Cmath>\u003Cmsubsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo>&#x02207;\u003C/mo>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>,\u003C/mo>\u003Cmi>j\u003C/mi>\u003Cmo>,\u003C/mo>\u003Cmi>k\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>&#x02113;\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003Cmo>=\u003C/mo>\u003Cmn>0\u003C/mn>\u003C/math> if (\u003Ci>i, j, k\u003C/i>) is on the boundary w.r.t. the direction &#x02113;. Finally, \u003Cmath>\u003Cmunder class=\"msub\">\u003Cmrow>\u003Cmo>&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>&#x0007E;\u003C/mo>\u003Cmi>j\u003C/mi>\u003C/mrow>\u003C/munder>\u003Cmsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>-\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>j\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmn>2\u003C/mn>\u003C/mrow>\u003C/msup>\u003C/math> means that the sum is only for neighboring voxels \u003Ci>i\u003C/i> and \u003Ci>j\u003C/i>.\u003C/p>\r\n\u003Cp class=\"mb0\">For each method, the model \u003Cmath>\u003Cmover accent=\"true\">\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo>^\u003C/mo>\u003C/mover>\u003C/math> is estimated by solving the optimization problem\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M3\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmrow>\u003Cmunder>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">min\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02208;\u003C/mo>\u003Cmsup>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">R\u003C/mi>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">p\u003C/mi>\u003C/msup>\u003C/mrow>\u003C/munder>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">{\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">E\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">+\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">}\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">where &#x003A9;(&#x003B2;) is defined as follows.\u003C/p>\r\n\u003Ch4>2.2.1. Elastic Net (ENET) and LASSO\u003C/h4>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M4\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#43;\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsubsup>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">This regularizer entails a tradeoff between variable selection and coefficient shrinkage. For &#x003BB;\u003Csub>2\u003C/sub> = 0, we obtain the LASSO, while &#x003BB;\u003Csub>2\u003C/sub> &#x02260; 0 allows for correlated features to be selected together. Notice also that unlike the structured sparsity regularizers described below, the location of the non-zero components is not constrained in any manner.\u003C/p>\r\n\u003Ch4>2.2.2. Total Variation (TV)\u003C/h4>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M5\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02207;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">This regularizer favors solutions that have constant value in contiguous regions and has its origins in image de-noising applications (\u003Ca href=\"#B33\">Rudin et al., 1992\u003C/a>), however it does not enforce any coefficient to be exactly zero.\u003C/p>\r\n\u003Ch4>2.2.3. Sparse Total Variation (STV)\u003C/h4>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M6\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02207;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#43;\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">By adding a &#x02113;\u003Csub>1\u003C/sub>-penalty term to the Total Variation functional, this regularize favors solutions whose coefficients are constant within contiguous regions, but also promotes sparsity. This hybrid method has been proposed in other domains, such as image de-noising using Fourier or wavelet representations (see e.g., \u003Ca href=\"#B23\">Ma et al., 2008\u003C/a>) and was applied to brain decoding in our previous work (\u003Ca href=\"#B4\">Baldassarre et al., 2012b\u003C/a>). Notice also that (Sparse) Total Variation reduces to a fused Lasso in 3D space (\u003Ca href=\"#B9\">Dohmatob et al., 2014\u003C/a>).\u003C/p>\r\n\u003Ch4>2.2.4. Laplacian (LAP)\u003C/h4>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M7\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/mfrac>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003Cmstyle displaystyle=\"true\">\u003Cmunder class=\"msub\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x0007E;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003C/mrow>\u003C/munder>\u003C/mstyle>\u003Cmsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">This regularizer relaxes the constancy requirement of the Total Variation method, allowing for smooth variations within regions. It is called &#x0201C;Laplacian&#x0201D; since the regularizer can be rewritten as \u003Cmath>\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo>&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>,\u003C/mo>\u003Cmi>j\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi>p\u003C/mi>\u003C/mrow>\u003C/munderover>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>j\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmsub>\u003Cmrow>\u003Cmi>L\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmi>j\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/math>, where the matrix \u003Ci>L\u003C/i> is the Laplacian associated to a 3D grid graph modeling neighboring voxels.\u003C/p>\r\n\u003Ch4>2.2.5. Sparse Laplacian (SLAP)\u003C/h4>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M8\">\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003A9;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/mfrac>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B1;\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmstyle displaystyle=\"true\">\u003Cmunder class=\"msub\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x0007E;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003C/mrow>\u003C/munder>\u003C/mstyle>\u003Cmsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">j\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003C/mrow>\u003C/msup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#43;\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003BB;\u003C/mi>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B1;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B2;\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003C/msub>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">where &#x003B1; &#x02208; [0, 1]. This regularizer encourages both smooth variations within regions and sparsity of the regression vector. The corresponding method is similar to GraphNET (\u003Ca href=\"#B15\">Grosenick et al., 2011\u003C/a>), with &#x003BB;\u003Csub>1\u003C/sub> = &#x003BB;&#x003B1; and &#x003BB;\u003Csub>\u003Ci>G\u003C/i>\u003C/sub> = &#x003BB;(1 &#x02212; &#x003B1;). Note also that LAP corresponds to the special case that &#x003B1; = 0. In all cases, &#x003BB; and &#x003B1; are hyper-parameters (often referred to as regularization parameters) that control the trade-off between the data fitting term, typically measured by classification accuracy, and the degree of regularization, which measures the parsimony (sparsity) of the model. These hyper-parameters must be chosen in an unbiased way during learning. The numerical algorithm employed to solve the optimization problem (Equation 1) is outlined in Appendix 1 (Supplementary Material).\u003C/p>\r\n\u003Ch3>2.3. Experimental Protocol and Assessment\u003C/h3>\r\n\u003Cp class=\"mb15\">In this section we present details about the experimental protocol used, including criteria for model selection and measures used to assess the performance of the different methods.\u003C/p>\r\n\u003Cp class=\"mb0\">Our aim is to provide a consistent and unbiased procedure in order to best compare different supervised learning methods that goes beyond the simple prediction accuracy performance measure. For this purpose, we introduce two measures of model reproducibility/stability and study their impact for model selection and model assessment.\u003C/p>\r\n\u003Ch4>2.3.1. Nested Cross-Validation\u003C/h4>\r\n\u003Cp class=\"mb0\">We perform two nested loops of Leave-One-Subject-Out Cross-Validation (LOSO-CV). The external loop is used for assessing the classification accuracy, the sparsity and the stability of the methods; the internal loop is used for selecting the hyper-parameter(s) in each method (e.g., &#x003BB;\u003Csub>1\u003C/sub> and &#x003BB;\u003Csub>2\u003C/sub> for Elastic Net). Hence, for each method, we train \u003Ci>N\u003C/i> different models, where \u003Ci>N\u003C/i> is the number of subjects in the dataset. Note that each subject has many examples of each class, therefore the LOSO-CV used in the present work does not correspond to the commonly used Leave-One-Out Cross-Validation (LOO-CV) procedure, where only one example is left for test in each cross-validation fold.\u003C/p>\r\n\u003Ch4>2.3.2. Thresholding\u003C/h4>\r\n\u003Cp class=\"mb0\">Although the sparse methods should yield sparse coefficient vectors, due to numerical approximations during optimization some of the estimated coefficients might not have been set exactly to zero. Therefore, we adopt the heuristic of setting to zero the smallest components of the regression vector which contribute to only 0.01% to the ||&#x003B2;||\u003Csub>1\u003C/sub>. Specifically we reorder the components of &#x003B2; so that |&#x003B2;\u003Csub>1\u003C/sub>| &#x02265; |&#x003B2;\u003Csub>2\u003C/sub>| &#x02265; &#x022EF; &#x02265; |&#x003B2;\u003Csub>\u003Ci>p\u003C/i>\u003C/sub>|, choose the smallest integer \u003Ci>r\u003C/i> such \u003Cmath>\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo>&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi>k\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi>r\u003C/mi>\u003C/mrow>\u003C/munderover>\u003Cmo>|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>k\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>|\u003C/mo>\u003Cmo>&#x02265;\u003C/mo>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmn>1\u003C/mn>\u003Cmo>-\u003C/mo>\u003Cmn>1\u003C/mn>\u003Cmsup>\u003Cmrow>\u003Cmn>0\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmo>-\u003C/mo>\u003Cmn>4\u003C/mn>\u003C/mrow>\u003C/msup>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo>|\u003C/mo>\u003Cmo>|\u003C/mo>\u003Cmi>&#x003B2;\u003C/mi>\u003Cmo>|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmo>|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003C/msub>\u003C/math> and set to zero the components &#x003B2;\u003Csub>\u003Ci>r\u003C/i>&#43;1\u003C/sub>, &#x02026;, &#x003B2;\u003Csub>\u003Ci>p\u003C/i>\u003C/sub>.\u003C/p>\r\n\u003Ch4>2.3.3. Performance Measures\u003C/h4>\r\n\u003Cp class=\"mb0\">Let &#x003B2;(\u003Ci>s\u003C/i>) (the \u003Ci>signature\u003C/i>) be the coefficient vector estimated when the data for subject \u003Ci>s\u003C/i> is left out for testing. We define the model or signature support \u003Ci>I\u003C/i>\u003Csub>\u003Ci>s\u003C/i>\u003C/sub>: = {\u003Ci>i\u003C/i> | &#x003B2;(\u003Ci>s\u003C/i>)\u003Csub>\u003Ci>i\u003C/i>\u003C/sub> &#x02260; 0} the index set of the locations of the non-zero coefficients (or sparsity pattern), the model \u003Ci>sparsity\u003C/i> \u003Cmath>\u003Cmi>S\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi>s\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo>:\u003C/mo>\u003Cmo>=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmo>|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi>I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo>|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi>p\u003C/mi>\u003C/mrow>\u003C/mfrac>\u003C/math> as the relative number of non-zero coefficients and the \u003Ci>pairwise relative overlap\u003C/i> as\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M9\">\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02229;\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmo class=\"qopname\">max\u003C/mo>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsubsup>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mfrac>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">We then define the \u003Ci>corrected pairwise relative overlap\u003C/i> as\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M10\">\u003Cmsubsup>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">c\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02229;\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">E\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmo class=\"qopname\">max\u003C/mo>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003Cmsubsup>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">I\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy=\"false\">|\u003C/mo>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mfrac>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">where \u003Ci>E\u003C/i> is the expected overlap between the support of two random vectors with sparsity \u003Ci>S\u003C/i>(\u003Ci>s\u003C/i>) and \u003Ci>S\u003C/i>(\u003Ci>s\u003C/i>&#x02032;), respectively, given by the formula\u003Csup id=\"footnotesuper2\">\u003Ca id=\"note2a\">\u003C/a>\u003Ca class=\"footnoteanchor\" href=\"#note2\">2\u003C/a>\u003C/sup>\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M11\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">E\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">p\u003C/mi>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">S\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">S\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">.\u003C/mo>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">2\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">The correction term \u003Ci>E\u003C/i> compensates the fact that the pairwise relative overlap increases with the size of the sparsity pattern of the models, see \u003Ca href=\"#B31\">Rasmussen et al. (2012)\u003C/a> for a discussion; note also that in that paper model sparsity is defined as the number of non-zero coefficients.\u003C/p>\r\n\u003Cp class=\"mb0\">Next we define the \u003Cstrong>average pairwise overlap\u003C/strong>\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M12\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmover accent=\"false\" class=\"mml-overline\">\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmo accent=\"true\">&#x000AF;\u003C/mo>\u003C/mover>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mfrac>\u003Cmstyle displaystyle=\"true\">\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02260;\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003C/mrow>\u003C/munderover>\u003C/mstyle>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003C/msub>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">3\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">and the \u003Cstrong>average corrected pairwise overlap\u003C/strong>\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M13\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmsup>\u003Cmrow>\u003Cmover accent=\"false\" class=\"mml-overline\">\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmo accent=\"true\">&#x000AF;\u003C/mo>\u003C/mover>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">c\u003C/mi>\u003C/mrow>\u003C/msup>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mfrac>\u003Cmstyle displaystyle=\"true\">\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02260;\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003C/mrow>\u003C/munderover>\u003C/mstyle>\u003Cmsubsup>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">O\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">c\u003C/mi>\u003C/mrow>\u003C/msubsup>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">4\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">as measures of \u003Ci>stability\u003C/i> and \u003Ci>corrected stability\u003C/i>, respectively.\u003C/p>\r\n\u003Cp class=\"mb0\">As a further measure of stability we also use the \u003Cstrong>average pairwise correlation\u003C/strong> defined as\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M14\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmover accent=\"false\" class=\"mml-overline\">\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">C\u003C/mi>\u003C/mrow>\u003Cmo accent=\"true\">&#x000AF;\u003C/mo>\u003C/mover>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">:\u003C/mo>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">-\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003C/mfrac>\u003Cmstyle displaystyle=\"true\">\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02260;\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003C/mrow>\u003C/munderover>\u003C/mstyle>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">C\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x02032;\u003C/mi>\u003C/mrow>\u003C/mrow>\u003C/msub>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">,\u003C/mo>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">5\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb15\">where \u003Ci>C\u003C/i>(\u003Ci>s, s\u003C/i>&#x02032;) is the sample Pearson&#x00027;s correlation between &#x003B2;(\u003Ci>s\u003C/i>) and &#x003B2;(\u003Ci>s\u003C/i>&#x02032;).\u003C/p>\r\n\u003Cp class=\"mb0\">The \u003Cstrong>accuracy\u003C/strong> of a method is the average percentage of correctly classified examples over all the LOSO folds, namely\u003C/p>\r\n\u003Cdiv class=\"equationImageholder\">\u003Cmath id=\"M15\">\u003Cmtable columnalign=\"left\">\u003Cmtr>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext class=\"textrm\" mathvariant=\"normal\">Accuracy\u003C/mtext>\u003C/mstyle>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003C/mrow>\u003C/mfrac>\u003Cmstyle displaystyle=\"true\">\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">N\u003C/mi>\u003C/mrow>\u003C/munderover>\u003C/mstyle>\u003Cmfrac>\u003Cmrow>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">m\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003C/mfrac>\u003Cmstyle displaystyle=\"true\">\u003Cmunderover accentunder=\"false\" accent=\"false\">\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">&#x02211;\u003C/mo>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">m\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003C/munderover>\u003C/mstyle>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">&#x003B4;\u003C/mi>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">f\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">x\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\">=\u003C/mo>\u003Cmsub>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">y\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi mathsize=\"10.5pt\" mathcolor=\"black\">i\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003Cmtd>\u003Cmstyle class=\"text\" mathsize=\"10.5pt\" mathcolor=\"black\">\u003Cmtext>&#x000A0;&#x000A0;&#x000A0;&#x000A0;\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>(\u003C/mo>\u003Cmn mathsize=\"10.5pt\" mathcolor=\"black\">6\u003C/mn>\u003Cmo mathsize=\"10.5pt\" mathcolor=\"black\" stretchy='false'>)\u003C/mo>\u003C/mrow>\u003C/mtd>\u003C/mtr>\u003C/mtable>\u003C/math>\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\u003Cp class=\"mb0\">where \u003Cmath>\u003Cmsub>\u003Cmrow>\u003Cmi>f\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>s\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmrow>\u003Cmi>x\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cmo>=\u003C/mo>\u003Cmstyle class=\"text\">\u003Cmtext class=\"textrm\" mathvariant=\"normal\">sign\u003C/mtext>\u003C/mstyle>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi>&#x003B2;\u003C/mi>\u003Cmsup>\u003Cmrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmrow>\u003Cmi>s\u003C/mi>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/mrow>\u003Cmrow>\u003Cmi>T\u003C/mi>\u003C/mrow>\u003C/msup>\u003Cmsub>\u003Cmrow>\u003Cmi>x\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003C/mrow>\u003C/msub>\u003C/mrow>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/math> and \u003Ci>m\u003C/i>\u003Csub>\u003Ci>s\u003C/i>\u003C/sub> is the number of examples for subject \u003Ci>s\u003C/i>.\u003C/p>\r\n\u003Ch3>2.4. Model Selection\u003C/h3>\r\n\u003Cp class=\"mb15\">Since we are interested in evaluating methods not only according to classification accuracy, but also with respect to measures of reproducibility/stability such as correlation and corrected overlap, it behooves us to consider these measures also during model selection. Obviously, the stability measures by themselves cannot directly be used for model selection, because selecting the model&#x00027;s hyper-parameters that only maximize stability will yield highly biased models that do not actually learn from data. For instance, a model with just one constant non-zero coefficient will maximize both correlation and corrected overlap, but won&#x00027;t be able to accurately predict.\u003C/p>\r\n\u003Cp class=\"mb0\">Henceforth, adopting and extending the procedure proposed by \u003Ca href=\"#B31\">Rasmussen et al. (2012)\u003C/a>, we consider both prediction accuracy and either correlation or corrected overlap simultaneously\u003Csup id=\"footnotesuper3\">\u003Ca id=\"note3a\">\u003C/a>\u003Ca class=\"footnoteanchor\" href=\"#note3\">3\u003C/a>\u003C/sup>. We can use a diagram to visualize the dependency between accuracy and one of the stability measures: by varying the model&#x00027;s hyper-parameters values we obtain different points on this diagram. Ideally, we would like to find the values that yield exactly the point (1, 1), that is perfect accuracy and perfect stability. However, since this hardly happens in practice, we are satisfied with the hyper-parameters values that yield the point closest (with respect to the Euclidean distance) to (1, 1) in either the accuracy vs. correlation or accuracy vs. corrected overlap diagrams. An example of these diagram is reported in Figure \u003Ca href=\"#F1\">1\u003C/a> for the LASSO.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 1\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" name=\"figure1\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg\" alt=\"www.frontiersin.org\" id=\"F1\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 1. Mean accuracy vs. mean corrected overlap (left)\u003C/strong> and mean accuracy vs. mean correlation \u003Cstrong>(right)\u003C/strong> for the first external LOSO fold for the LASSO model. The curves are obtained by varying the regularization parameter and computing the measures across the internal LOSO folds.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine mb15\">\u003C/div>\r\n\u003Cp class=\"mb15\">Summarizing, we consider three model selection criteria:\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left\">1. \u003Cstrong>Accuracy-based\u003C/strong>. The model hyper-parameters are selected to maximize the classification accuracy over the internal LOSO-CV.\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left\">2. \u003Cstrong>Corrected overlap based\u003C/strong>. The hyper-parameters are selected in order to minimize the distance to (1, 1) in the mean accuracy vs. mean corrected overlap diagram. Note that this criteria was only applied to the sparse methods (LASSO, ENET, STV, and SLAP).\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;text-align:left\">3. \u003Cstrong>Correlation-based\u003C/strong>. The hyper-parameters are selected in order to minimize the distance to (1, 1) in the mean accuracy vs. mean correlation diagram.\u003C/p>\r\n\u003Ch3>2.5. Multi-Measure Assessment\u003C/h3>\r\n\u003Cp class=\"mb0\">The accuracy vs. stability diagrams introduced in the previous section for model selection can also be used for model assessment. In fact, when training a model and selecting its hyper-parameters in order to maximize both accuracy and stability, it is appropriate to compare its performance to other methods with respect to the same criterion used for model selection. In this case, each method yields a single point in the accuracy vs. stability diagram and we can both visually assess the differences in the methods&#x02014;which is the most accurate, which is the most stable and which obtains the best balance between accuracy and stability&#x02014;but also quantitatively compute their distances to the ideal (1, 1) point. In Figure \u003Ca href=\"#F2\">2\u003C/a> we use these diagrams to visualize the performance of the various methods on the dataset considered in this paper.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 2\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" name=\"figure2\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g002.jpg\" alt=\"www.frontiersin.org\" id=\"F2\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 2. Summary results for different models when the model selection criteria Acc/Corr and Acc/OC are employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Ch3>2.6. Dataset\u003C/h3>\r\n\u003Cp class=\"mb15\">We used fMRI data from 16 male healthy US college students (age 20&#x02013;25) (\u003Ca href=\"#B28\">Mourao-Miranda et al., 2006\u003C/a>, \u003Ca href=\"#B27\">2007\u003C/a>; \u003Ca href=\"#B16\">Hardoon et al., 2007\u003C/a>). Participants did not have any history of neurological or psychiatric illness, had normal vision and had given written informed consent to participate in the study after the study was explained to them.\u003C/p>\r\n\u003Cp class=\"mb0\">The fMRI data were acquired on a 3T Allegra Head-only MRI system, using a T2* sequence with 43 axial slices (slice thickness, 3 mm; gap between slices, 0 mm; \u003Ci>TR\u003C/i> = 3 s; \u003Ci>TE\u003C/i> = 30 ms; \u003Ci>FA\u003C/i> = 80&#x000B0;; FOV = 192 &#x000D7; 192 mm; matrix, 64 &#x000D7; 64; voxel dimensions, 3 &#x000D7; 3 &#x000D7; 3 mm).\u003C/p>\r\n\u003Ch4>2.6.1. fMRI Experimental Design\u003C/h4>\r\n\u003Cp class=\"mb0\">There were three different active conditions: viewing unpleasant (dermatological diseases), neutral (people) and pleasant images (pretty girls in swimsuits), and a control condition (fixation). In each run, there were 6 blocks of the active condition (each consisting of 7 brain scans) alternating with control blocks (fixation) of 7 brain scans. The six blocks of each of the 3 stimuli were presented in random order. Here we focus the analyses on two active conditions: viewing unpleasant and pleasant images. The fMRI scans acquired during the pleasant and unpleasant conditions (considering an hemodynamic delay of 3 s) defined the input patterns.\u003C/p>\r\n\u003Ch4>2.6.2. Preprocessing\u003C/h4>\r\n\u003Cp class=\"mb0\">The data were pre-processed using SPM2\u003Csup id=\"footnotesuper4\">\u003Ca id=\"note4a\">\u003C/a>\u003Ca class=\"footnoteanchor\" href=\"#note4\">4\u003C/a>\u003C/sup>. All the scans were realigned to remove residual motion effects and transformed into standard space (\u003Ca href=\"#B37\">Talairach and Tournoux, 1988\u003C/a>). The data were de-trended and smoothed in space using an 8 mm Gaussian filter. Finally, a mask was applied to select voxels that have probability 0.5 or higher of being located in gray matter. This operation nearly halves the number of voxels from 219, 727 to 122, 128. The preprocessed dataset consists of 1344 scans of size 122, 128 voxels, with 42 scans per subject per active condition.\u003C/p>\r\n\u003Ch3>2.7. Summarization of the Coefficient Maps\u003C/h3>\r\n\u003Cp class=\"mb0\">In order to summarize the coefficient maps for the sparse methods (LASSO, ENET, STV and SLAP) we listed the clusters according to their extension using the script 3dclust from AFNI (\u003Ca href=\"https://afni.nimh.nih.gov/afni/\">https://afni.nimh.nih.gov/afni/\u003C/a>) and found the brain regions correspondent to the maximum coefficient within each cluster using the software Talairach Daemon (\u003Ca href=\"http://www.talairach.org/daemon.html\">http://www.talairach.org/daemon.html\u003C/a>).\u003C/p>\r\n\u003Ca id=\"h4\" name=\"h4\">\u003C/a>\u003Ch2>3. Results\u003C/h2>\r\n\u003Cp class=\"mb15\">In this section, we describe the experimental results obtained applying the different sparsity regularization methods as well as non sparse ones to decode the mental state (i.e., viewing pleasant or unpleasant images) of the subject left out of the LOSO-CV as described in the methods section. The Matlab code one may use to reproduce our results is available at \u003Ca href=\"https://github.com/lucabaldassarre/neurosparse\">https://github.com/lucabaldassarre/neurosparse\u003C/a>.\u003C/p>\r\n\u003Cp class=\"mb15\">The main aim of the experiments is to compare three different model selection criteria: (i) classification accuracy, (ii) classification accuracy and overlap between the solutions, (iii) classification accuracy and correlation between the solutions; and investigate their impact on the different performance measures: \u003Ci>Accuracy, Sparsity, Correlation, Overlap\u003C/i>, and \u003Ci>Corrected Overlap (OC)\u003C/i>. As we noted in the previous section, the last three quantities are stability/reproducibility measures which indicate the extent to which maps of coefficients or sparsity patterns associated with a learning method are stable across LOSO-CV folds and hence reproducible.\u003C/p>\r\n\u003Cp class=\"mb0\">Table \u003Ca href=\"#T1\">1\u003C/a> reports the average and standard deviation for the five performance measures computed on the external LOSO-CV (test error) of each learning method and model selection criterion. Each row in the table refers to one learning method trained with one of the three model selection criteria: &#x0201C;Acc,&#x0201D; &#x0201C;Acc/OC,&#x0201D; and &#x0201C;Acc/Corr.&#x0201D; For example, in the table,&#x0201C;LASSO - Acc&#x0201D; means that we run LASSO and selected its regularization parameter according to best accuracy, whereas &#x0201C;LASSO - Acc/OC&#x0201D; means that we run LASSO and selected the regularization parameter which minimizes the distance in the Accuracy/Corrected Overlap diagram. Likewise, &#x0201C;LASSO - Acc/Corr&#x0201D; means that we run LASSO and selected the regularization parameter which minimizes the distance in the Accuracy/Correlation diagram. As expected when test performance is measured according to accuracy, the most effective model selection criterion is accuracy itself. Similarly, when test performance accounts for correlation or corrected overlap, the best performance tends to be obtained by using Acc/Correlation or Acc/OC as the model selection criterion, respectively. In Figure \u003Ca href=\"#F1\">1\u003C/a>, we show an example of &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; and of &#x0201C;Mean Accuracy vs. Mean Correlation&#x0201D; plot for the LASSO model trained for the first external LOSO fold. Note that for each learning method, there is significant discrepancy between the different optimization criteria used.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">TABLE 1\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" name=\"Table1\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t001.jpg\" alt=\"www.frontiersin.org\" id=\"T1\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Table 1. Model performance\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cp class=\"mb15 w100pc float_left mt15\">One interesting observation from Table \u003Ca href=\"#T1\">1\u003C/a> is the fact that using accuracy and stability (measured by OC) as a joint criterion for model selection leads to solutions that are more similar across different sparsity models in terms of accuracy, sparsity levels and corrected overlap, with respect to using only accuracy as optimization criterion. For example, when using the criterion Acc/OC the accuracy across different sparsity models varies from 81.03% (STV) to 84.08% (E-NET), the sparsity varies from 0.25 (LASSO) to 3 (E-NET) and the corrected overlap (OC) varies from 52 (SLAP) to 82 (E-NET). These variations are much smaller than the ones observed for model selection based on accuracy only. In this case the accuracy varies from 83.71% (LAP) to 88.02% (E-NET), the sparsity varies from 0.64 (LASSO) to 84.14 (E-NET) and the corrected overlap (OC) varies from 2 (E-NET) to 35 (SLAP). Interestingly, when using the criterion Acc/Corr this effect is not observed.\u003C/p>\r\n\u003Cp class=\"mb15\">In Figure \u003Ca href=\"#F2\">2\u003C/a>, we present the results for the different methods in the planes &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; and &#x0201C;Mean Accuracy vs. Mean Correlation.&#x0201D; Overall the best performing method is the Elastic Net, achieving an average accuracy of over 84% when the model selection criterion Acc/OC is employed, yielding at the same time a highly stable sparsity pattern. The LASSO gives the most sparse coefficient vectors (maps), however these are less stable than those obtained by Elastic Net.\u003C/p>\r\n\u003Cp class=\"mb0\">Figures \u003Ca href=\"#F3\">3\u003C/a>&#x02013;\u003Ca href=\"#F5\">5\u003C/a> show the coefficient maps for the different methods and different optimization criteria (averaged across the external LOSO folds). Figure \u003Ca href=\"#F3\">3\u003C/a> shows the coefficient maps when accuracy was employed as a model selection criterion. It is possible to notice that the coefficient maps present very different levels of sparsity and smoothness even though the accuracy for the different methods varies less than 5% (from 83.71 to 88.02%). These results illustrate the effect of different sparsity constraints on the coefficient maps. As expected the LASSO solution is extremely sparse regardless of the model selection criterion. The coefficient maps for ENET are not sparse and show a smooth variation over the voxels/regions. Not surprisingly, the coefficient maps for Total Variation (TV) and Laplacian (LAP) methods led to non-sparse solutions, however the TV coefficients show large regions with constant values while the LAP coefficients show a smooth variation across the brain voxels/regions, presenting a similar pattern as the ENET. Finally, the coefficient maps for Sparse Total Variation (STV) and Sparse Laplacian (SLAP) are sparser versions of the TV and LAP. Including correlation across the LOSO solutions as an additional model selection criterion leads to coefficient maps similar to the ones obtained using only accuracy (Figure \u003Ca href=\"#F4\">4\u003C/a>), with STV showing a pattern similar to TV.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 3\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" name=\"figure3\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g003.jpg\" alt=\"www.frontiersin.org\" id=\"F3\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 3. Coefficient maps for different models when the model selection criterion Acc is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine mb15\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 4\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" name=\"figure4\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g004.jpg\" alt=\"www.frontiersin.org\" id=\"F4\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 4. Coefficient maps for different models when the model selection criterion ACC/Corr is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cp class=\"mt15 w100pc float_left\">In Figure \u003Ca href=\"#F5\">5\u003C/a>, we can see the coefficient maps when accuracy and corrected overlap (OC) were employed as model selection criteria for the sparse methods (LASSO, ENET, STV, and SLAP). It is interesting to see that in this case all maps became very similar both in terms of sparsity and smoothness. In all cases the coefficient maps are very sparse with well localized clusters and peaks. Overall, the Acc/OC model selection criterion seems to lead to solutions that are the most sparse and stable (according to the overlap and corrected overlap measures), while the observed decrease in accuracy performance is not significant (according to the Welch&#x00027;s \u003Ci>t\u003C/i>-test).\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 5\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" name=\"figure5\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g005.jpg\" alt=\"www.frontiersin.org\" id=\"F5\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 5. Coefficient maps for different sparse models when the model selection criterion Acc/OC is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cp class=\"mt15 w100pc float_left\">In order to illustrate the impact of the model selection criteria on the stability of the coefficients across folds, in Figure \u003Ca href=\"#F6\">6\u003C/a> we present the coefficient maps for the first and second LOSO folds for the STV method using the different model section criteria. As we can see there is a lot of variation between the coefficients when the regularization parameters are selected according to accuracy, whereas when distance in the &#x0201C;Mean Accuracy vs. Mean Corrected Overlap&#x0201D; diagram is used the coefficients become very similar which indicates that the solutions become more reproducible/stable.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">FIGURE 6\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" name=\"figure6\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g006.jpg\" alt=\"www.frontiersin.org\" id=\"F6\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Figure 6. Coefficient maps for the first two LOSO folds for the STV method using different model selection criteria (Accuracy, Accuracy and Correlation, Accuracy and Corrected Overlap)\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cp class=\"mt15 w100pc float_left\">A more objective description of the coefficient maps is provided in Tables \u003Ca href=\"#T2\">2\u003C/a>&#x02013;\u003Ca href=\"#T4\">4\u003C/a> with a list of the five top clusters found by each method and each model selection criterion. This description was not done for the non sparse approaches as in this case all voxels within the image are included in a single cluster. The Tables show the total number of clusters found and the brain regions (including the corresponding Brodman Area - BA) corresponding to the five top clusters ranked according to the maximum coefficient within the cluster. It is possible to see that although different methods find very different numbers of clusters depending on the sparsity constraint and model selection criteria, there is a good agreement between the main clusters found by the different methods. In particular when the optimization criteria Acc/OC was used the different sparse methods (LASSO, ENET, STV, and SLAP) identified the same regions (Table \u003Ca href=\"#T4\">4\u003C/a>), with some differences in the ranking order. As expected, considering the fMRI experimental task (visualization of pleasant or unpleasant pictures), the main clusters include visual areas (e.g., left and right middle occipital gyrus), areas often associated with emotional processing (e.g., right medial frontal gyrus, right anterior cingulate) and cerebellum (left cummen). A visual inspection of the non-sparse approaches shows that their peaks are also in similar regions selected by the sparse approaches.\u003C/p>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">TABLE 2\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" name=\"Table2\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t002.jpg\" alt=\"www.frontiersin.org\" id=\"T2\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Table 2. List of clusters for sparse methods when the model selection criterion Acc is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine mb15\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">TABLE 3\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" name=\"Table3\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t003.jpg\" alt=\"www.frontiersin.org\" id=\"T3\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Table 3. List of clusters for sparse methods when the model selection criterion Acc/Corr is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine mb15\">\u003C/div>\r\n\u003Cdiv class=\"Imageheaders\">TABLE 4\u003C/div>\r\n\u003Cdiv class=\"FigureDesc\">\r\n\u003Ca href=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" name=\"Table4\" target=\"_blank\">\r\n\n  \u003Cpicture>\n    \u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" media=\"(max-width: 563px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" media=\"(max-width: 1024px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" media=\"(max-width: 1441px)\">\u003Csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" media=\"\">\u003Csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" media=\"\"> \u003Cimg src=\"https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-t004.jpg\" alt=\"www.frontiersin.org\" id=\"T4\" loading=\"lazy\">\n  \u003C/picture>\n\u003C/a>\r\n\u003Cp>\u003Cstrong>Table 4. List of clusters for sparse methods when the model selection criterion Acc/OC is employed\u003C/strong>.\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"clear\">\u003C/div>\r\n\u003Cdiv class=\"DottedLine\">\u003C/div>\r\n\u003Ca id=\"h5\" name=\"h5\">\u003C/a>\u003Ch2>4. Discussion\u003C/h2>\r\n\u003Cp class=\"mb15\">During the last years there has been a huge increase in the application of machine learning methods to analyse neuroimaging data (see \u003Ca href=\"#B29\">Pereira et al., 2009\u003C/a>; \u003Ca href=\"#B17\">Haynes, 2015\u003C/a>, and references therein), varying from neuroscience applications for decoding mental or cognitive states (e.g., \u003Ca href=\"#B30\">Polyn et al., 2005\u003C/a>; \u003Ca href=\"#B28\">Mourao-Miranda et al., 2006\u003C/a>; \u003Ca href=\"#B18\">Haynes et al., 2007\u003C/a>; \u003Ca href=\"#B34\">Schrouff et al., 2012\u003C/a>) to clinical applications for diagnoses and prognoses (e.g., \u003Ca href=\"#B22\">Kloppel et al., 2012\u003C/a>). Despite their inherent ability to deal with multivariate data and their predictive framework which enables decisions at the single subject level, one of their main limitations is the interpretability issue. For linear machine learning models, the vector of coefficients (also known as weight vector) can be plotted and visualized as a brain image showing the contribution of each voxel in the image to the decision function. The main issue is that, for non sparse approaches (e.g., Kernel Ridge Regression, Support Vector Machines) all voxels within the image will have some contribution to the decision function, making it difficult to decide which voxels contribute the most. A number of approaches have been proposed to ease the interpretability issue, such as feature selection (e.g., Martino et al., 2008; Langs et al., 2011; Rondina et al., 2014), searchlight (Kriegeskorte et al., 2006) and sparse models (see references in the introduction). Sparsity has often been advocated as a proxy for interpretability, however sparsity can be imposed by very different penalties or constraints which should be related to prior knowledge about the problem considered.\u003C/p>\r\n\u003Cp class=\"mb15\">Our previous work (\u003Ca href=\"#B4\">Baldassarre et al., 2012b\u003C/a>) showed that different sparsity constraints can lead to similar performance in terms of accuracy, but the resulting models differ in term of sparsity and stability. In the present work, we investigated the impact of the model selection criteria (parameter optimization criteria) on models with different sparsity penalties. Our results show that having a second criterion (in addition to accuracy) for model selection improves the stability/reproducibility (measured by OC or correlation across LOSO solutions) of the sparse models, i.e., the instability of the sparse models decreases by including reproducibility as an additional model selection criterion.\u003C/p>\r\n\u003Cp class=\"mb15\">When trying to interpret brain maps resulting from sparse models it is important to have in mind that the properties of the maps, such as sparsity and smoothness, are strongly driven by the choice of the penalty term in the objective function. The effect of the chosen penalty on the map of coefficients can be clearly seen in Figure \u003Ca href=\"#F3\">3\u003C/a>. It is possible to observe that when accuracy is used for model selection, methods with different penalties can have similar performance and very different coefficient maps. However, when reproducibility (measured by OC) is used in addition to accuracy for models selection, the solutions or maps became more similar even across the different sparse methods (Figure \u003Ca href=\"#F5\">5\u003C/a>). Interestingly the same effect is not observed when reproducibility (measured by correlation) is used as additional model selection criterion (Figure \u003Ca href=\"#F4\">4\u003C/a>). One possible explanation for the difference observed on the results when using OC or correlation representing stability is the fact that correlation is significantly affected, i.e., reduced, by differences in models&#x00027; supports. Therefore, correlation between models can be very high when the models are both very sparse or both very dense, leading to choosing such models during model selection, as evidenced by Figure \u003Ca href=\"#F4\">4\u003C/a>. We also noticed that the criteria Acc/OC tended to select higher sparsity regularization parameters, because corrected overlap (due to its correction term) favors highly overlapping, but not dense models. This might explain the reason why the models using the criteria Acc/OC are very sparse (Figure \u003Ca href=\"#F5\">5\u003C/a>). Although a sparse solution seems the most stable for the considered data set, the sparsity of the learned solution is likely to be dataset dependent. Different fMRI datasets might have different levels of sparsity depending on the cognitive task. If a cognitive task only engages a very small network of few regions, then very sparse solutions will probably show the best performance in terms of accuracy and stability. On the other hand, if a cognitive task engages a large network, then less sparse solutions will probably lead to best overall performance. The stability or reproducibility of the model is also an important aspect to be considered for the interpretation as sparsity in itself can produce highly unstable models. Figure \u003Ca href=\"#F6\">6\u003C/a> illustrates the impact of including reproducibility as a second criterion for model selection for STV. The STV solutions for two different cross validations folds of the LOSO are extremely different when accuracy is used for model selection and become much more similar/stable when correlation or OC is included as a second criterion for model selection.\u003C/p>\r\n\u003Cp class=\"mb15\">If we compare the clusters&#x00027; location for different sparse methods it is interesting to observe that the solutions of LASSO, ENET, STV, and SLAP include basically the same top five regions (with some differences in the ranking order) when accuracy and OC are used as model selection criteria. The top clusters include left middle occipital gyrus (BA 37), right middle occipital gyrus (BA19), left culmen, right middle frontal gyrus (BA 11/10), and right anterior cingulate (BA 24). The fist two regions are known to be involved in visual processing (e.g., \u003Ca href=\"#B40\">Wandell et al., 2007\u003C/a>) and the last two have been associated with emotional processing (e.g., \u003Ca href=\"#B11\">Etkin et. al., 2011\u003C/a>). The involvement of these regions would be expected in the problem considered, i.e., decoding visualization of emotional pictures.\u003C/p>\r\n\u003Cp class=\"mb15\">The potential gains of unstructured vs. structured sparse models for neuroimaging applications will depend on how well the model assumptions (or sparsity penalty) agree with the data structure. Structured sparse models can incorporate more prior knowledge about the data structure and therefore can potentially lead to models with higher performance. However, since neuroimage data, in general, has very high dimensionality and complex structure it is not certain that structured sparse models will have the highest performance when compared with other types of sparsity, as was the case in the present work. Among the penalties considered in the present work, the SLAP penalty seems closer to our beliefs about how the brain works, i.e., the brain is organized in regions and the activities within these regions are expected to vary smoothly. Nevertheless, ENET presented the best performance in terms of accuracy and reproducibility. Our results show that SLAP can lead to very noisy maps with hundreds of cluster, many of them being very small and more likely to be related to noise than brain activity. One difficulty to choose the optimal penalty is the lack of an absolute ground truth in terms of informative or predictive regions in the brain, making it difficult to define an objective criterion for model comparison. Some studies have used results from mass univariate statistical tests between the classes (e.g., \u003Ci>t\u003C/i>-test) as a proxy for the ground truth, however such tests would fail to capture multivariate properties (e.g., subtle differences observed when a set of voxels is considered jointly). Here we investigate the use of two criteria for model selection, decoding accuracy and stability/reproducibility (measured by OC or correlation across LOSO folds). Although these criteria do not embed a metric of distance to the ground truth solution, the combination of decoding accuracy and overlap between the solutions leads to similar solutions across different learning methods.\u003C/p>\r\n\u003Cp class=\"mb15\">\u003Ca href=\"#B31\">Rasmussen et al. (2012)\u003C/a> have previously investigated the impact of choices of model regularization parameters on the generalization and the stability/reproducibility of spatial patterns extracted from classification models in neuroimaging. The authors evaluate the models using the NPAIRS resampling scheme (i.e., half-splits resamples \u003Ca href=\"#B35\">Strother et al., 2002\u003C/a>) and constructed performance-vs.-reproducibility curves (pr-curves) for three classifiers: Support Vector Machine, Fisher Discriminant Analyses and Logistic Regression. For each classifier type, they compared the models that optimized the prediction accuracy, joint prediction accuracy and reproducibility (measured by Pearson correlation coefficient between the models&#x00027; coefficients), and only reproducibility. The authors observed a trade-off between prediction accuracy and reproducibility and argued that regularization parameters must be selected to balance this trade-off in order to provide a more accurate representation of the underlying brain networks. They also investigated how performance and stability/reproducibility (measured by overlap and mutual information between the solution) varied for the logistic regression with ENET penalty as function of the regularization parameters, however in this case the stability/reproducibility metrics were only used to access the models and not for parameter optimization. Other studies also reported a tradeoff between prediction vs. reproducibility using a penalized Fishers discriminant analysis (FDA) on PCA basis (\u003Ca href=\"#B36\">Strother et al., 2004\u003C/a>; \u003Ca href=\"#B42\">Yourganov et al., 2011\u003C/a>).\u003C/p>\r\n\u003Cp class=\"mb15\">Our work builds upon \u003Ca href=\"#B31\">Rasmussen et al. (2012)\u003C/a>, as we also investigate the trade-off between prediction accuracy and reproducibility as model selection criteria, but differs from it in many aspects. First, our goal was to investigate the role of model selection criteria on several different sparse methods (LASSO, ENET, TV, LAP, STV, and SLAP). Second, we used a LOSO framework with nested cross-validation for parameter optimization instead of a half-split framework. Third, we investigated two stability/reproducibility metrics, the Pearson correlation coefficient and the pairwise corrected overlap across the LOSO solutions. Using our framework, we observed that when using prediction accuracy and corrected overlap as joint optimization criterion the solutions for different sparse methods become very similar in terms of performance and brain regions identified as relevant. These results suggest that the choice of model regularization parameters might be more important than the choice of the sparsity constraint.\u003C/p>\r\n\u003Cp class=\"mb0\">One limitation of our work is to use the LOSO cross-validation framework, i.e., the LOSO framework is known to have high variance and the solutions for different cross-validation folds are not independent. Nevertheless, considering the sample size of 16 subjects, it would be difficult to explore other cross-validation frameworks. It should be noted that since each subject has 42 scans of each active condition, leaving one subject out corresponds to leaving 84 examples out for test. Future work, using larger sample sizes should be performed to investigate the impact of adding stability/reproducibility as model selection criteria in other cross-validation frameworks. A possible future direction could be to explore multitask learning methods, in which the subjects are treated as distinct classification or regression tasks, which are related by means of a joint regularizer (see, for example, \u003Ca href=\"#B1\">Argyriou et al., 2008\u003C/a>; \u003Ca href=\"#B32\">Romera-Paredes et al., 2013\u003C/a>, and references therein). Ideas from \u003Ca href=\"#B6\">Bzdok et al. (2015)\u003C/a> may also prove valuable in this direction.\u003C/p>\r\n\u003Ca id=\"h6\" name=\"h6\">\u003C/a>\u003Ch2>Ethics Statement\u003C/h2>\r\n\u003Cp class=\"mb0\">The study was performed in accordance with the local Ethics Committee of the University of North Carolina where the data was originally acquired. Participants had given written informed consent to participate in the study after the study was explained to them.\u003C/p>\r\n\u003Ca id=\"h7\" name=\"h7\">\u003C/a>\u003Ch2>Author Contributions\u003C/h2>\r\n\u003Cp class=\"mb0\">LB contributed to designing the experiments, implementing and running the models and writing the paper. JMM and MP contributed to designing the experiments, interpreting the results and writing the paper.\u003C/p>\r\n\u003Ca id=\"h8\" name=\"h8\">\u003C/a>\u003Ch2>Funding\u003C/h2>\r\n\u003Cp class=\"mb0\">JMM was supported by the Wellcome Trust under grant no. WT102845/Z/13/Z. MP was partially supported by EPSRC grants EP/P009069/1 and EP/M006093/1.\u003C/p>\r\n\u003Ca id=\"h9\" name=\"h9\">\u003C/a>\u003Ch2>Conflict of Interest Statement\u003C/h2>\r\n\u003Cp class=\"mb0\">The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003C/p>\r\n\u003Ca id=\"h10\" name=\"h10\">\u003C/a>\u003Ch2>Acknowledgments\u003C/h2>\r\n\u003Cp class=\"mb0\">The authors thank Professor Michael Brammer from the Institute of Psychiatry, Psychology and Neuroscience at King&#x00027;s College London for providing the fMRI dataset. This work is a longer version of our conference paper (\u003Ca href=\"#B3\">Baldassarre et al., 2012a\u003C/a>). It contains a novel model selection criterion and extended experimental study. Furthermore, we discuss the coefficient maps obtained by the different models and model selection criteria considered.\u003C/p>\r\n\u003Ca id=\"h11\" name=\"h11\">\u003C/a>\u003Ch2>Supplementary Material\u003C/h2>\r\n\u003Cp class=\"mb0\">The Supplementary Material for this article can be found online at: \u003Ca href=\"http://journal.frontiersin.org/article/10.3389/fnins.2017.00062/full#supplementary-material\">http://journal.frontiersin.org/article/10.3389/fnins.2017.00062/full#supplementary-material\u003C/a>\u003C/p>\r\n\u003Ca id=\"h12\" name=\"h12\">\u003C/a>\u003Ch2>Footnotes\u003C/h2>\r\n\u003Cdiv id=\"footnotetext\" class=\"fulltextdescription\">\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;\" id=\"note1\">1. \u003Ca class=\"footnotetextanchor\" href=\"#note1a\" title=\"\">^\u003C/a>Model selection is a procedure through which, one among many possible statistical models is selected. The prototypical case is when each model corresponds to a different hyper-parameter, e.g., the regularization parameter in ridge regression, SVMs, or LASSO.\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;\" id=\"note2\">2. \u003Ca class=\"footnotetextanchor\" href=\"#note2a\" title=\"\">^\u003C/a>We remark that there is a typo in the definition of \u003Ci>E\u003C/i> in \u003Ca href=\"#B4\" style=\"color:grey;\">Baldassarre et al. (2012b)\u003C/a>, which should coincide with Equation (2) hereafter.\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;\" id=\"note3\">3. \u003Ca class=\"footnotetextanchor\" href=\"#note3a\" title=\"\">^\u003C/a>Specifically, \u003Ca href=\"#B31\" style=\"color:grey;\">Rasmussen et al. (2012)\u003C/a> has not employed the accuracy&#x02014;reproducibility diagram as model selection criterion for sparse models. They have only used it to assess the ENET performance. Whereas in this paper these measures are used both for model selection and assessment of different sparse methods.\u003C/p>\r\n\u003Cp style=\"margin-top:0em;margin-bottom:0em;margin-left:1em;text-indent:-1em;\" id=\"note4\">4. \u003Ca class=\"footnotetextanchor\" href=\"#note4a\" title=\"\">^\u003C/a>Wellcome Department of Imaging Neuroscience, \u003Ca href=\"http://www.fil.ion.ucl.ac.uk/spm/\" style=\"color:grey;\">http://www.fil.ion.ucl.ac.uk/spm/\u003C/a>.\u003C/p>\r\n\u003C/div>\r\n\u003Ca id=\"h13\" name=\"h13\">\u003C/a>\u003Ch2>References\u003C/h2>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B1\" id=\"B1\">\u003C/a> Argyriou, A., Evgeniou, T., and Pontil, M. (2008). Convex multi-task feature learning. \u003Ci>J. Mach. Learn.\u003C/i> 73, 243&#x02013;272. doi: 10.1007/s10994-007-5040-8\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1007/s10994-007-5040-8\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+Argyriou&#x00026;author=T.+Evgeniou&#x00026;author=M.+Pontil+&#x00026;publication_year=2008&#x00026;title=Convex+multi-task+feature+learning&#x00026;journal=J.+Mach.+Learn.&#x00026;volume=73&#x00026;pages=243-272\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\" style=\"margin-bottom:0.5em;\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B2\" id=\"B2\">\u003C/a> Bach, F., Jenatton, R., Mairal, J., and Obozinski, G. (2011). \u003Ci>Structured Sparsity through Convex Optimization.\u003C/i> Technical Report. \u003Ci>Arxiv preprint:1109.2397\u003C/i>.\u003C/p>\r\n\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B3\" id=\"B3\">\u003C/a> Baldassarre, L., Morales, J. M., Argyriou, A., and Pontil, M. (2012a). &#x0201C;A general framework for structured sparsity via proximal optimization,&#x0201D; in \u003Ci>International Conference on Artificial Intelligence and Statistics\u003C/i> (La Palma), 82&#x02013;90.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=L.+Baldassarre&#x00026;author=J.+M.+Morales&#x00026;author=A.+Argyriou&#x00026;author=M.+Pontil+&#x00026;publication_year=2012a&#x00026;title=&#x0201C;A+general+framework+for+structured+sparsity+via+proximal+optimization,&#x0201D;&#x00026;pages=82-90\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B4\" id=\"B4\">\u003C/a> Baldassarre, L., Mourao-Miranda, J., and Pontil, M. (2012b). &#x0201C;Structured sparsity models for brain decoding from fMRI data,&#x0201D; in \u003Ci>International Workshop on Pattern Recognition in NeuroImaging\u003C/i> (London), 5&#x02013;8. doi: 10.1109/prni.2012.31\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1109/prni.2012.31\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=L.+Baldassarre&#x00026;author=J.+Mourao-Miranda&#x00026;author=M.+Pontil+&#x00026;publication_year=2012b&#x00026;title=&#x0201C;Structured+sparsity+models+for+brain+decoding+from+fMRI+data,&#x0201D;&#x00026;pages=5-8\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B5\" id=\"B5\">\u003C/a> Belilovsky, E., Argyriou, A., Varoquaux, G., and Blaschko, M. (2015). Convex relaxations of penalties for sparse correlated variables with bounded total variation. \u003Ci>Mach. Learn.\u003C/i> 100, 533&#x02013;553. doi: 10.1007/s10994-015-5511-2\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1007/s10994-015-5511-2\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=E.+Belilovsky&#x00026;author=A.+Argyriou&#x00026;author=G.+Varoquaux&#x00026;author=M.+Blaschko+&#x00026;publication_year=2015&#x00026;title=Convex+relaxations+of+penalties+for+sparse+correlated+variables+with+bounded+total+variation&#x00026;journal=Mach.+Learn.&#x00026;volume=100&#x00026;pages=533-553\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B6\" id=\"B6\">\u003C/a> Bzdok, D., Eickenberg, M., Grisel, O., Thirion, B., and Varoquaux, G. (2015). Semi-supervised factored logistic regression for high-dimensional neuroimaging data. \u003Ci>Adv. Neural Inform. Process. Syst.\u003C/i> 28, 3348&#x02013;3356. Available online at: \u003Ca href=\"http://papers.nips.cc/paper/5646-semi-supervised-factored-logistic-regression-for-high-dimensional-neuroimaging-data.pdf\">http://papers.nips.cc/paper/5646-semi-supervised-factored-logistic-regression-for-high-dimensional-neuroimaging-data.pdf\u003C/a>\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=D.+Bzdok&#x00026;author=M.+Eickenberg&#x00026;author=O.+Grisel&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2015&#x00026;title=Semi-supervised+factored+logistic+regression+for+high-dimensional+neuroimaging+data&#x00026;journal=Adv.+Neural+Inform.+Process.+Syst.&#x00026;volume=28&#x00026;pages=3348-3356\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B7\" id=\"B7\">\u003C/a> Chambolle, A. (2004). An algorithm for total variation minimization and applications. \u003Ci>J. Math. Imaging Vis.\u003C/i> 20, 89&#x02013;97. doi: 10.1023/B:JMIV.0000011321.19549.88\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1023/B:JMIV.0000011321.19549.88\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+Chambolle+&#x00026;publication_year=2004&#x00026;title=An+algorithm+for+total+variation+minimization+and+applications&#x00026;journal=J.+Math.+Imaging+Vis.&#x00026;volume=20&#x00026;pages=89-97\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B8\" id=\"B8\">\u003C/a> Cortes, C., and Vapnik, V. (1995). Support vector networks. \u003Ci>Mach. Learn.\u003C/i> 20, 273&#x02013;297. doi: 10.1007/BF00994018\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1007/BF00994018\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=C.+Cortes&#x00026;author=V.+Vapnik+&#x00026;publication_year=1995&#x00026;title=Support+vector+networks&#x00026;journal=Mach.+Learn.&#x00026;volume=20&#x00026;pages=273-297\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B9\" id=\"B9\">\u003C/a> Dohmatob, E., Gramfort, A., Thirion, B., and Varoquaux, G. (2014). &#x0201C;Benchmarking solvers for TV-l1 least-squares and logistic regression in brain imaging,&#x0201D; in \u003Ci>International Workshop on Pattern Recognition in Neuroimaging (PRNI)\u003C/i> (T&#x000FC;bingen: IEEE), 1&#x02013;4.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=E.+Dohmatob&#x00026;author=A.+Gramfort&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2014&#x00026;title=&#x0201C;Benchmarking+solvers+for+TV-l1+least-squares+and+logistic+regression+in+brain+imaging,&#x0201D;&#x00026;pages=1-4\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B10\" id=\"B10\">\u003C/a> Eickenberg, M., Dohmatob, E., Thirion, B., and Varoquaux, G. (2015). &#x0201C;Grouping total variation and sparsity: statistical learning with segmenting penalties,&#x0201D; in \u003Ci>Medical Image Computing and Computer-Assisted Intervention &#x02013; MICCAI 2015: 18th International Conference, October 5-9, Proceedings, Part I\u003C/i> (Munich), 685&#x02013;693.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=M.+Eickenberg&#x00026;author=E.+Dohmatob&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2015&#x00026;title=&#x0201C;Grouping+total+variation+and+sparsity%3A+statistical+learning+with+segmenting+penalties,&#x0201D;&#x00026;pages=685-693\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B11\" id=\"B11\">\u003C/a> Etkin, A. (2011). Emotional processing in anterior cingulate and medial prefrontal. \u003Ci>Trends Cogn. Sci.\u003C/i> 15, 85&#x02013;93. doi: 10.1016/j.tics.2010.11.004\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=21167765\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.tics.2010.11.004\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+Etkin+&#x00026;publication_year=2011&#x00026;title=Emotional+processing+in+anterior+cingulate+and+medial+prefrontal&#x00026;journal=Trends+Cogn.+Sci.&#x00026;volume=15&#x00026;pages=85-93\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B12\" id=\"B12\">\u003C/a> Fiot, J. B., Raguet, H., Risser, L., Cohen, L. D., Fripp, J., and Vialard, F. X. (2014). Longitudinal deformation models, spatial regularizations and learning strategies to quantify alzheimer&#x00027;s disease progression. \u003Ci>Neuroimage\u003C/i> 4, 718&#x02013;729. doi: 10.1016/j.nicl.2014.02.002\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=24936423\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.nicl.2014.02.002\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+B.+Fiot&#x00026;author=H.+Raguet&#x00026;author=L.+Risser&#x00026;author=L.+D.+Cohen&#x00026;author=J.+Fripp&#x00026;author=F.+X.+Vialard+&#x00026;publication_year=2014&#x00026;title=Longitudinal+deformation+models,+spatial+regularizations+and+learning+strategies+to+quantify+alzheimer&#x00027;s+disease+progression&#x00026;journal=Neuroimage&#x00026;volume=4&#x00026;pages=718-729\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B13\" id=\"B13\">\u003C/a> Gramfort, A., Thirion, B., and Varoquaux, G. (2013). &#x0201C;Identifying predictive regions from fMRI with TV-l1 prior,&#x0201D; in \u003Ci>International Workshop on Pattern Recognition in Neuroimaging (PRNI)\u003C/i> (Philadelphia, PA), 17&#x02013;20. doi: 10.1109/prni.2013.14\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1109/prni.2013.14\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+Gramfort&#x00026;author=B.+Thirion&#x00026;author=G.+Varoquaux+&#x00026;publication_year=2013&#x00026;title=&#x0201C;Identifying+predictive+regions+from+fMRI+with+TV-l1+prior,&#x0201D;&#x00026;pages=17-20\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B14\" id=\"B14\">\u003C/a> Grosenick, L., Klingenberg, B., Katovich, K., Knutson, B., and Taylor, J. (2013). Interpretable whole-brain prediction analysis with graphnet. \u003Ci>Neuroimage\u003C/i> 72, 304&#x02013;321. doi: 10.1016/j.neuroimage.2012.12.062\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=23298747\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2012.12.062\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=L.+Grosenick&#x00026;author=B.+Klingenberg&#x00026;author=K.+Katovich&#x00026;author=B.+Knutson&#x00026;author=J.+Taylor+&#x00026;publication_year=2013&#x00026;title=Interpretable+whole-brain+prediction+analysis+with+graphnet&#x00026;journal=Neuroimage&#x00026;volume=72&#x00026;pages=304-321\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B15\" id=\"B15\">\u003C/a> Grosenick, L., Klingenberg, B., Katovich, K., Knutson, B., and Taylor, J. E. (2011). A family of interpretable multivariate models for regression and classification of whole-brain fMRI data. \u003Ci>ArXiv e-prints 1110.4139\u003C/i>.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=L.+Grosenick&#x00026;author=B.+Klingenberg&#x00026;author=K.+Katovich&#x00026;author=B.+Knutson&#x00026;author=J.+E.+Taylor+&#x00026;publication_year=2011&#x00026;title=A+family+of+interpretable+multivariate+models+for+regression+and+classification+of+whole-brain+fMRI+data&#x00026;journal=ArXiv+e-prints+1110.4139\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B16\" id=\"B16\">\u003C/a> Hardoon, D., Mourao-Miranda, J., Brammer, M., and Shawe-Taylor, J. (2007). Unsupervised analysis of fMRI data using kernel canonical correlation. \u003Ci>Neuroimage\u003C/i> 37, 1250&#x02013;1259. doi: 10.1016/j.neuroimage.2007.06.017\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17686634\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2007.06.017\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=D.+Hardoon&#x00026;author=J.+Mourao-Miranda&#x00026;author=M.+Brammer&#x00026;author=J.+Shawe-Taylor+&#x00026;publication_year=2007&#x00026;title=Unsupervised+analysis+of+fMRI+data+using+kernel+canonical+correlation&#x00026;journal=Neuroimage&#x00026;volume=37&#x00026;pages=1250-1259\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B17\" id=\"B17\">\u003C/a> Haynes, J. (2015). A primer on pattern-based approaches to fMRI: principles, pitfalls, and perspectives. \u003Ci>Neuron\u003C/i> 85, 257&#x02013;270. doi: 10.1016/j.neuron.2015.05.025\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1016/j.neuron.2015.05.025\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+Haynes+&#x00026;publication_year=2015&#x00026;title=A+primer+on+pattern-based+approaches+to+fMRI%3A+principles,+pitfalls,+and+perspectives&#x00026;journal=Neuron&#x00026;volume=85&#x00026;pages=257-270\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B18\" id=\"B18\">\u003C/a> Haynes, J., Sakai, K., Rees, G., Gilbert, S., Frith, C., and Passingham, R. E. (2007). Reading hidden intentions in the human brain. \u003Ci>Curr. Biol.\u003C/i> 17, 323&#x02013;328. doi: 10.1016/j.cub.2006.11.072\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17291759\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.cub.2006.11.072\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+Haynes&#x00026;author=K.+Sakai&#x00026;author=G.+Rees&#x00026;author=S.+Gilbert&#x00026;author=C.+Frith&#x00026;author=R.+E.+Passingham+&#x00026;publication_year=2007&#x00026;title=Reading+hidden+intentions+in+the+human+brain&#x00026;journal=Curr.+Biol.&#x00026;volume=17&#x00026;pages=323-328\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B19\" id=\"B19\">\u003C/a> Hoyos-Idrobo, A., Schwartz, Y., Varoquaux, G., and Thirion, B. (2015). &#x0201C;Improving sparse recovery on structured images with bagged clustering,&#x0201D; in \u003Ci>International Workshop on Pattern Recognition In Neuroimaging (PRNI)\u003C/i> (Palo Alto, CA), 73&#x02013;76.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+Hoyos-Idrobo&#x00026;author=Y.+Schwartz&#x00026;author=G.+Varoquaux&#x00026;author=B.+Thirion+&#x00026;publication_year=2015&#x00026;title=&#x0201C;Improving+sparse+recovery+on+structured+images+with+bagged+clustering,&#x0201D;&#x00026;pages=73-76\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B20\" id=\"B20\">\u003C/a> Jenatton, R., Gramfort, A., Michel, V., Obozinski, G., Eger, E., Bach, F., et al. (2011). Multi-scale mining of fMRI data with hierarchical structured sparsity. \u003Ci>ArXiv e-prints 1105.0363\u003C/i>.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=R.+Jenatton&#x00026;author=A.+Gramfort&#x00026;author=V.+Michel&#x00026;author=G.+Obozinski&#x00026;author=E.+Eger&#x00026;author=F.+Bach+&#x00026;publication_year=2011&#x00026;title=Multi-scale+mining+of+fMRI+data+with+hierarchical+structured+sparsity&#x00026;journal=ArXiv+e-prints+1105.0363\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B21\" id=\"B21\">\u003C/a> Jenatton, R., Gramfort, A., Michel, V., Obozinski, G., Eger, E., Bach, F., et al. (2012). Multiscale mining of fMRI data with hierarchical structured sparsity. \u003Ci>SIAM J. Imaging Sci.\u003C/i> 5, 835&#x02013;856. doi: 10.1137/110832380\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1137/110832380\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=R.+Jenatton&#x00026;author=A.+Gramfort&#x00026;author=V.+Michel&#x00026;author=G.+Obozinski&#x00026;author=E.+Eger&#x00026;author=F.+Bach+&#x00026;publication_year=2012&#x00026;title=Multiscale+mining+of+fMRI+data+with+hierarchical+structured+sparsity&#x00026;journal=SIAM+J.+Imaging+Sci.&#x00026;volume=5&#x00026;pages=835-856\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B22\" id=\"B22\">\u003C/a> Kloppel, S., Abdulkadir, A., Jack, C. R. J., Koutsouleris, N., Mourao-Miranda, J., and Vemur, J. (2012). Diagnostic neuroimaging across diseases. \u003Ci>Neuroimage\u003C/i> 61, 457&#x02013;463. doi: 10.1016/j.neuroimage.2011.11.002\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=22094642\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2011.11.002\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=S.+Kloppel&#x00026;author=A.+Abdulkadir&#x00026;author=C.+R.+J.+Jack&#x00026;author=N.+Koutsouleris&#x00026;author=J.+Mourao-Miranda&#x00026;author=J.+Vemur+&#x00026;publication_year=2012&#x00026;title=Diagnostic+neuroimaging+across+diseases&#x00026;journal=Neuroimage&#x00026;volume=61&#x00026;pages=457-463\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B23\" id=\"B23\">\u003C/a> Ma, S., Yin, W., Zhang, Y., and Chakraborty, A. (2008). &#x0201C;An efficient algorithm for compressed MR imaging using total variation and wavelets,&#x0201D; in \u003Ci>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on (IEEE)\u003C/i> (Anchorage, AK), 1&#x02013;8.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=S.+Ma&#x00026;author=W.+Yin&#x00026;author=Y.+Zhang&#x00026;author=A.+Chakraborty+&#x00026;publication_year=2008&#x00026;title=&#x0201C;An+efficient+algorithm+for+compressed+MR+imaging+using+total+variation+and+wavelets,&#x0201D;&#x00026;pages=1-8\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B24\" id=\"B24\">\u003C/a> Micchelli, C. A., Morales, J. M., and Pontil, M. (2013). Regularizers for structured sparsity. \u003Ci>Adv. Comput. Math.\u003C/i> 38, 455&#x02013;489. doi: 10.1007/s10444-011-9245-9\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1007/s10444-011-9245-9\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=C.+A.+Micchelli&#x00026;author=J.+M.+Morales&#x00026;author=M.+Pontil+&#x00026;publication_year=2013&#x00026;title=Regularizers+for+structured+sparsity&#x00026;journal=Adv.+Comput.+Math.&#x00026;volume=38&#x00026;pages=455-489\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B25\" id=\"B25\">\u003C/a> Michel, V., Gramfort, A., Varoquaux, G., Eger, E., and Thirion, B. (2011). Total variation regularization for fMRI-based prediction of behavior. \u003Ci>IEEE Trans. Med. Imaging\u003C/i> 30, 1328&#x02013;1340. doi: 10.1109/TMI.2011.2113378\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=21317080\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1109/TMI.2011.2113378\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=V.+Michel&#x00026;author=A.+Gramfort&#x00026;author=G.+Varoquaux&#x00026;author=E.+Eger&#x00026;author=B.+Thirion+&#x00026;publication_year=2011&#x00026;title=Total+variation+regularization+for+fMRI-based+prediction+of+behavior&#x00026;journal=IEEE+Trans.+Med.+Imaging&#x00026;volume=30&#x00026;pages=1328-1340\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B26\" id=\"B26\">\u003C/a> Mohr, H., Wolfensteller, U., Frimmel, S., and Ruge, H. (2015). Sparse regularization techniques provide novel insights into outcome integration processes. \u003Ci>Neuroimage\u003C/i> 104, 163&#x02013;176. doi: 10.1016/j.neuroimage.2014.10.025\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=25467302\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2014.10.025\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=H.+Mohr&#x00026;author=U.+Wolfensteller&#x00026;author=S.+Frimmel&#x00026;author=H.+Ruge+&#x00026;publication_year=2015&#x00026;title=Sparse+regularization+techniques+provide+novel+insights+into+outcome+integration+processes&#x00026;journal=Neuroimage&#x00026;volume=104&#x00026;pages=163-176\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B27\" id=\"B27\">\u003C/a> Mourao-Miranda, J., Friston, K., and Brammer, M. (2007). Dynamic discrimination analysis: a spatial-temporal svm. \u003Ci>Neuroimage\u003C/i> 36, 88&#x02013;99. doi: 10.1016/j.neuroimage.2007.02.020\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17400479\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2007.02.020\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+Mourao-Miranda&#x00026;author=K.+Friston&#x00026;author=M.+Brammer+&#x00026;publication_year=2007&#x00026;title=Dynamic+discrimination+analysis%3A+a+spatial-temporal+svm&#x00026;journal=Neuroimage&#x00026;volume=36&#x00026;pages=88-99\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B28\" id=\"B28\">\u003C/a> Mourao-Miranda, J., Reynaud, E., McGlone, F., Calvert, G., and Brammer, M. (2006). The impact of temporal compression and space selection on svm analysis of single-subject and multi-subject fMRI data. \u003Ci>Neuroimage\u003C/i> 33, 1055&#x02013;1065. doi: 10.1016/j.neuroimage.2006.08.016\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17010645\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2006.08.016\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+Mourao-Miranda&#x00026;author=E.+Reynaud&#x00026;author=F.+McGlone&#x00026;author=G.+Calvert&#x00026;author=M.+Brammer+&#x00026;publication_year=2006&#x00026;title=The+impact+of+temporal+compression+and+space+selection+on+svm+analysis+of+single-subject+and+multi-subject+fMRI+data&#x00026;journal=Neuroimage&#x00026;volume=33&#x00026;pages=1055-1065\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B29\" id=\"B29\">\u003C/a> Pereira, F., Mitchell, T., and Botvinick, M. (2009). Machine learning classifiers and fMRI: a tutorial overview. \u003Ci>Neuroimage\u003C/i> 45, S199&#x02013;S209. doi: 10.1016/j.neuroimage.2008.11.007\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=19070668\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2008.11.007\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=F.+Pereira&#x00026;author=T.+Mitchell&#x00026;author=M.+Botvinick+&#x00026;publication_year=2009&#x00026;title=Machine+learning+classifiers+and+fMRI%3A+a+tutorial+overview&#x00026;journal=Neuroimage&#x00026;volume=45&#x00026;pages=S199-S209\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B30\" id=\"B30\">\u003C/a> Polyn, S. M., Natu, V. S., Cohen, J. D., and Norman, K. A. (2005). Category-specific cortical activity precedes retrieval during memory search. \u003Ci>Science\u003C/i> 310, 1963&#x02013;1966. doi: 10.1126/science.1117645\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=16373577\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1126/science.1117645\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=S.+M.+Polyn&#x00026;author=V.+S.+Natu&#x00026;author=J.+D.+Cohen&#x00026;author=K.+A.+Norman+&#x00026;publication_year=2005&#x00026;title=Category-specific+cortical+activity+precedes+retrieval+during+memory+search&#x00026;journal=Science&#x00026;volume=310&#x00026;pages=1963-1966\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B31\" id=\"B31\">\u003C/a> Rasmussen, P. M., Hansen, L. K., Madsen, K. H., Churchill, N. W., and Strother, S. C. (2012). Model sparsity and brain pattern interpretation of classification models in neuroimaging. \u003Ci>Patt. Recogn\u003C/i>. 45, 2085&#x02013;2100. doi: 10.1016/j.patcog.2011.09.011\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1016/j.patcog.2011.09.011\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=P.+M.+Rasmussen&#x00026;author=L.+K.+Hansen&#x00026;author=K.+H.+Madsen&#x00026;author=N.+W.+Churchill&#x00026;author=S.+C.+Strother+&#x00026;publication_year=2012&#x00026;title=Model+sparsity+and+brain+pattern+interpretation+of+classification+models+in+neuroimaging&#x00026;journal=Patt.+Recogn&#x00026;volume=45&#x00026;pages=2085-2100\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B32\" id=\"B32\">\u003C/a> Romera-Paredes, B., Aung, M. H., Bianchi-Berthouze, N., and Pontil, M. (2013). &#x0201C;Multilinear multitask learning,&#x0201D; in \u003Ci>Proceedings of the 30th International Conference on Machine Learning (ICML)\u003C/i> (Atlanta, GA), 1444&#x02013;1452.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=B.+Romera-Paredes&#x00026;author=M.+H.+Aung&#x00026;author=N.+Bianchi-Berthouze&#x00026;author=M.+Pontil+&#x00026;publication_year=2013&#x00026;title=&#x0201C;Multilinear+multitask+learning,&#x0201D;&#x00026;pages=1444-1452\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B33\" id=\"B33\">\u003C/a> Rudin, L., Osher, S., and Fatemi, E. (1992). Nonlinear total variation based noise removal algorithms. \u003Ci>Physica D\u003C/i> 60, 259&#x02013;268. doi: 10.1016/0167-2789(92)90242-F\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1016/0167-2789(92)90242-F\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=L.+Rudin&#x00026;author=S.+Osher&#x00026;author=E.+Fatemi+&#x00026;publication_year=1992&#x00026;title=Nonlinear+total+variation+based+noise+removal+algorithms&#x00026;journal=Physica+D&#x00026;volume=60&#x00026;pages=259-268\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B34\" id=\"B34\">\u003C/a> Schrouff, J., Kusse, C., Wehenkel, L., Maquet, P., and Phillips, C. (2012). ecoding semi-constrained brain activity from fMRI using support vector machines and gaussian processes. \u003Ci>PLoS ONE\u003C/i> 7:e35860. doi: 10.1371/journal.pone.0035860\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=22563410\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1371/journal.pone.0035860\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=J.+Schrouff&#x00026;author=C.+Kusse&#x00026;author=L.+Wehenkel&#x00026;author=P.+Maquet&#x00026;author=C.+Phillips+&#x00026;publication_year=2012&#x00026;title=ecoding+semi-constrained+brain+activity+from+fMRI+using+support+vector+machines+and+gaussian+processes&#x00026;journal=PLoS+ONE\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B35\" id=\"B35\">\u003C/a> Strother, S., Anderson, J., Hansen, L., Kjems, U., Kustra, R., Sidtis, J., et al. (2002). The quantitative evaluation of functional neuroimaging experiments: the npairs data analysis framework. \u003Ci>Neuroimage\u003C/i> 15, 747&#x02013;771. doi: 10.1006/nimg.2001.1034\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=11906218\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1006/nimg.2001.1034\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=S.+Strother&#x00026;author=J.+Anderson&#x00026;author=L.+Hansen&#x00026;author=U.+Kjems&#x00026;author=R.+Kustra&#x00026;author=J.+Sidtis+&#x00026;publication_year=2002&#x00026;title=The+quantitative+evaluation+of+functional+neuroimaging+experiments%3A+the+npairs+data+analysis+framework&#x00026;journal=Neuroimage&#x00026;volume=15&#x00026;pages=747-771\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B36\" id=\"B36\">\u003C/a> Strother, S., Conte, S. L., Hansen, L. K., Anderson, J., Zhang, J., Pulapura, S., et al. (2004). Optimizing the fMRI data-processing pipeline using prediction and reproducibility performance metrics: I. A preliminary group analysis. \u003Ci>Neuroimage\u003C/i> 23(Suppl. 1), S196&#x02013;S207. doi: 10.1016/j.neuroimage.2004.07.022\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=15501090\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2004.07.022\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=S.+Strother&#x00026;author=S.+L.+Conte&#x00026;author=L.+K.+Hansen&#x00026;author=J.+Anderson&#x00026;author=J.+Zhang&#x00026;author=S.+Pulapura+&#x00026;publication_year=2004&#x00026;title=Optimizing+the+fMRI+data-processing+pipeline+using+prediction+and+reproducibility+performance+metrics%3A+I.+A+preliminary+group+analysis&#x00026;journal=Neuroimage&#x00026;volume=23&#x00026;pages=S196-S207\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\" style=\"margin-bottom:0.5em;\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B37\" id=\"B37\">\u003C/a> Talairach, P., and Tournoux, J. (1988). \u003Ci>A Stereotactic Coplanar Atlas of the Human Brain\u003C/i>. Stuttgart: Thieme.\u003C/p>\r\n\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B38\" id=\"B38\">\u003C/a> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. \u003Ci>J. R. Stat. Soc. Ser. B\u003C/i> 58, 267&#x02013;288.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=R.+Tibshirani+&#x00026;publication_year=1996&#x00026;title=Regression+shrinkage+and+selection+via+the+lasso&#x00026;journal=J.+R.+Stat.+Soc.+Ser.+B&#x00026;volume=58&#x00026;pages=267-288\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B39\" id=\"B39\">\u003C/a> Tikhonov, A. N., and Arsenin, V. Y. (1977). \u003Ci>Solutions of Ill-Posed Problems\u003C/i>. Washington, DC: John Wiley.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://scholar.google.com/scholar_lookup?author=A.+N.+Tikhonov&#x00026;author=V.+Y.+Arsenin+&#x00026;publication_year=1977&#x00026;title=Solutions+of+Ill-Posed+Problems\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B40\" id=\"B40\">\u003C/a> Wandell, B. A., Dumoulin, S. O., and Brewer, A. A. (2007). Visual field maps in human cortex. \u003Ci>Neuron\u003C/i> 56, 366&#x02013;383. doi: 10.1016/j.neuron.2007.10.012\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=17964252\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuron.2007.10.012\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=B.+A.+Wandell&#x00026;author=S.+O.+Dumoulin&#x00026;author=A.+A.+Brewer+&#x00026;publication_year=2007&#x00026;title=Visual+field+maps+in+human+cortex&#x00026;journal=Neuron&#x00026;volume=56&#x00026;pages=366-383\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B41\" id=\"B41\">\u003C/a> Wang, Y., Zheng, J., Zhang, S., Duan, X., and Chen, H. (2014). Randomized structural sparsity via constrained block subsampling for improved sensitivity of discriminative voxel identification. \u003Ci>ArXiv e-prints 1410.4650\u003C/i>.\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=26027884\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=Y.+Wang&#x00026;author=J.+Zheng&#x00026;author=S.+Zhang&#x00026;author=X.+Duan&#x00026;author=H.+Chen+&#x00026;publication_year=2014&#x00026;title=Randomized+structural+sparsity+via+constrained+block+subsampling+for+improved+sensitivity+of+discriminative+voxel+identification&#x00026;journal=ArXiv+e-prints+1410.4650\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B42\" id=\"B42\">\u003C/a> Yourganov, G., Chen, X., Lukic, A. S., Grady, C. L., Small, S. L., Wernick, M. N., et al. (2011). Dimensionality estimation for optimal detection of functional networks in bold fMRI data. \u003Ci>Neuroimage\u003C/i> 56, 531&#x02013;543. doi: 10.1016/j.neuroimage.2010.09.034\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&#x00026;Cmd=ShowDetailView&#x00026;TermToSearch=20858546\" target=\"_blank\">PubMed Abstract\u003C/a> | \u003Ca href=\"https://doi.org/10.1016/j.neuroimage.2010.09.034\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=G.+Yourganov&#x00026;author=X.+Chen&#x00026;author=A.+S.+Lukic&#x00026;author=C.+L.+Grady&#x00026;author=S.+L.+Small&#x00026;author=M.+N.+Wernick+&#x00026;publication_year=2011&#x00026;title=Dimensionality+estimation+for+optimal+detection+of+functional+networks+in+bold+fMRI+data&#x00026;journal=Neuroimage&#x00026;volume=56&#x00026;pages=531-543\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003Cdiv class=\"References\">\r\n\u003Cp class=\"ReferencesCopy1\">\u003Ca name=\"B43\" id=\"B43\">\u003C/a> Zou, H., and Hastie, T. (2005). Regularization and variable selection via the elastic net. \u003Ci>J. R. Stat. Soc. Ser. B (Stat. Methodol.)\u003C/i> 67, 301&#x02013;320. doi: 10.1111/j.1467-9868.2005.00503.x\u003C/p>\r\n\u003Cp class=\"ReferencesCopy2\">\u003Ca href=\"https://doi.org/10.1111/j.1467-9868.2005.00503.x\" target=\"_blank\">CrossRef Full Text\u003C/a> | \u003Ca href=\"http://scholar.google.com/scholar_lookup?author=H.+Zou&#x00026;author=T.+Hastie+&#x00026;publication_year=2005&#x00026;title=Regularization+and+variable+selection+via+the+elastic+net&#x00026;journal=J.+R.+Stat.+Soc.+Ser.+B+(Stat.+Methodol.)&#x00026;volume=67&#x00026;pages=301-320\" target=\"_blank\">Google Scholar\u003C/a>\u003C/p>\u003C/div>\r\n\u003C/div>\r\n\u003Cdiv class=\"thinLineM20\">\u003C/div>\r\n\u003Cdiv class=\"AbstractSummary\">\r\n\u003Cp>\u003Cspan>Keywords:\u003C/span> sparse methods, structured sparsity, model selection, reproducibility, predictive models\u003C/p>\r\n\u003Cp>\u003Cspan>Citation:\u003C/span> Baldassarre L, Pontil M and Mour&#x000E3;o-Miranda J (2017) Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding. \u003Ci>Front. Neurosci\u003C/i>. 11:62. doi: 10.3389/fnins.2017.00062\u003C/p>\r\n\u003Cp id=\"timestamps\">\u003Cspan>Received:\u003C/span> 14 June 2016; \u003Cspan>Accepted:\u003C/span> 27 January 2017;\u003Cbr> \u003Cspan>Published:\u003C/span> 17 February 2017.\u003C/p>\r\n\u003Cdiv>\u003Cp>Edited by:\u003C/p> \u003Ca href=\"http://loop.frontiersin.org/people/53467/overview\">Bertrand Thirion\u003C/a>, Institut National de Recherche en Informatique et en Automatique (INRIA), France\u003C/div>\r\n\u003Cdiv>\u003Cp>Reviewed by:\u003C/p> \u003Ca href=\"http://loop.frontiersin.org/people/49944/overview\">Danilo Bzdok\u003C/a>, Research Center J&#x000FC;lich, Germany\u003Cbr> \u003Ca href=\"http://loop.frontiersin.org/people/77204/overview\">Bernard Ng\u003C/a>, University of British Columbia, Canada\u003C/div>\r\n\u003Cp>\u003Cspan>Copyright\u003C/span> &#x000A9; 2017 Baldassarre, Pontil and Mour&#x000E3;o-Miranda. This is an open-access article distributed under the terms of the \u003Ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">Creative Commons Attribution License (CC BY)\u003C/a>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\u003C/p>\r\n\u003Cp>\u003Cspan>*Correspondence:\u003C/span> Janaina Mour&#x000E3;o-Miranda, \u003Ca id=\"encmail\">ai5tb3VyYW8tbWlyYW5kYUB1Y2wuYWMudWs=\u003C/a>\u003C/p>\r\n\u003Cdiv class=\"clear\">\u003C/div>\u003C/div>\r\n\r\n","\u003Cul class=\"flyoutJournal\">\r\n\u003Cli>\u003Ca href=\"#h1\">Abstract\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h2\">1. Introduction\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h3\">2. Materials and Methods\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h4\">3. Results\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h5\">4. Discussion\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h6\">Ethics Statement\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h7\">Author Contributions\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h8\">Funding\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h9\">Conflict of Interest Statement\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h10\">Acknowledgments\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h11\">Supplementary Material\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h12\">Footnotes\u003C/a>\u003C/li>\r\n\u003Cli>\u003Ca href=\"#h13\">References\u003C/a>\u003C/li>\r\n\u003C/ul>\r\n",[611,616,622,625,631],{"name":612,"fileServerPackageEntryId":19,"fileServerId":613,"fileServerVersionNumber":115,"type":614},"EPUB.epub","209792/epub",{"code":615,"name":615},"EPUB",{"name":617,"fileServerPackageEntryId":618,"fileServerId":619,"fileServerVersionNumber":115,"type":620},"fnins-11-00062.pdf","fnins-11-00062/fnins-11-00062.pdf","209792/pubmed-zip",{"code":621,"name":621},"PDF",{"name":617,"fileServerPackageEntryId":19,"fileServerId":623,"fileServerVersionNumber":115,"type":624},"209792/publishers-proof/pdf",{"code":621,"name":621},{"name":626,"fileServerPackageEntryId":627,"fileServerId":619,"fileServerVersionNumber":115,"type":628},"fnins-11-00062.xml","fnins-11-00062/fnins-11-00062.xml",{"code":629,"name":630},"NLM_XML","XML",{"name":632,"fileServerPackageEntryId":19,"fileServerId":633,"fileServerVersionNumber":115,"type":634},"Provisional PDF.pdf","209792/provisional-pdf",{"code":621,"name":621},"fnins-11-00062-HTML","v3",{"title":638,"link":639,"meta":643,"script":739},"Frontiers | Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding",[640],{"rel":641,"href":642},"canonical","https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/full",[644,647,650,652,655,659,662,666,669,672,675,677,679,681,683,685,688,691,693,696,699,701,704,707,710,713,716,720,724,727,730,733,736],{"hid":645,"property":645,"name":645,"content":646},"description","Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional s...",{"hid":648,"property":648,"name":649,"content":638},"og:title","title",{"hid":651,"property":651,"name":645,"content":646},"og:description",{"hid":653,"name":653,"content":654},"keywords","Sparse methods,structured sparsity,Model selection,reproducibility,predictive models",{"hid":656,"property":656,"name":657,"content":658},"og:site_name","site_name","Frontiers",{"hid":660,"property":660,"name":363,"content":661},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/Articles/209792/fnins-11-00062-HTML/image_m/fnins-11-00062-g001.jpg",{"hid":663,"property":663,"name":664,"content":665},"og:type","type","article",{"hid":667,"property":667,"name":668,"content":642},"og:url","url",{"hid":670,"name":670,"content":671},"twitter:card","summary_large_image",{"hid":673,"name":673,"content":674},"citation_volume","11",{"hid":676,"name":676,"content":116},"citation_journal_title",{"hid":678,"name":678,"content":658},"citation_publisher",{"hid":680,"name":680,"content":592},"citation_journal_abbrev",{"hid":682,"name":682,"content":593},"citation_issn",{"hid":684,"name":684,"content":512},"citation_doi",{"hid":686,"name":686,"content":687},"citation_firstpage","209792",{"hid":689,"name":689,"content":690},"citation_language","English",{"hid":692,"name":692,"content":513},"citation_title",{"hid":694,"name":694,"content":695},"citation_keywords","Sparse methods; structured sparsity; Model selection; reproducibility; predictive models",{"hid":697,"name":697,"content":698},"citation_abstract","Structured sparse methods have received significant attention in neuroimaging. These methods allow the incorporation of domain knowledge through additional spatial and temporal constraints in the predictive model and carry the promise of being more interpretable than non-structured sparse methods, such as LASSO or Elastic Net methods. However, although sparsity has often been advocated as leading to more interpretable models it can also lead to unstable models under subsampling or slight changes of the experimental conditions. In the present work we investigated the impact of using stability/reproducibility as an additional model selection criterion on several different sparse (and structured sparse) methods that have been recently applied for fMRI brain decoding. We compared three different model selection criteria: (i) classification accuracy alone; (ii) classification accuracy and overlap between the solutions; (iii) classification accuracy and correlation between the solutions. The methods we considered include LASSO, Elastic Net, Total Variation, sparse Total Variation, Laplacian and Graph Laplacian Elastic Net (GraphNET).Our results show that explicitly accounting for stability/reproducibility during the model optimisation can mitigate some of the instability inherent in sparse methods. In particular, using accuracy and overlap between the solutions as a joint optimisation criterion can lead to solutions that are more similar in terms of accuracy, sparsity levels and coefficient maps even when different sparsity methods are considered.",{"hid":700,"name":700,"content":521},"citation_article_type",{"hid":702,"name":702,"content":703},"citation_pdf_url","https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/pdf",{"hid":705,"name":705,"content":706},"citation_xml_url","https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00062/xml",{"hid":708,"name":708,"content":709},"citation_fulltext_world_readable","yes",{"hid":711,"name":711,"content":712},"citation_online_date","2017/01/27",{"hid":714,"name":714,"content":715},"citation_publication_date","2017/02/17",{"hid":717,"name":718,"content":719},"citation_author_0","citation_author","Baldassarre, Luca ",{"hid":721,"name":722,"content":723},"citation_author_institution_0","citation_author_institution","Laboratory for Information and Inference Systems, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland",{"hid":725,"name":718,"content":726},"citation_author_1","Pontil, Massimiliano ",{"hid":728,"name":722,"content":729},"citation_author_institution_1","Istituto Italiano di Tecnologia, Genoa, Italy",{"hid":731,"name":718,"content":732},"citation_author_2","Mourão-Miranda, Janaina ",{"hid":734,"name":722,"content":735},"citation_author_institution_2","Department of Computer Science, University College London, London, UK",{"hid":737,"name":737,"content":738},"dc.identifier","doi:10.3389/fnins.2017.00062",[740,743,745,747,749],{"src":741,"body":13,"type":742,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":744,"body":13,"type":742,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML",{"src":746,"body":13,"type":742,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":748,"body":13,"type":742,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fnins.2017.00062?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":750,"body":13,"type":742,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articleHubSlug":19,"articleHubPage":752,"articleHubArticlesList":753,"canJournalHasArticleHub":355,"articleDoiList":754},{},[],[],{"title":19,"image":-1,"breadcrumbs":756,"linksCollection":757,"metricsCollection":759},[],{"total":367,"items":758},[],{"total":367,"items":760},[]]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{isDevMode:false,appName:"article-pages-2024",baseUrl:"https://www.frontiersin.org",domain:"frontiersin.org",loopUrl:"https://loop.frontiersin.org",ssMainDomain:"frontiersin.org",contentfulUrl:"https://graphql.contentful.com/content/v1/spaces",spaceId:1,spaceName:"Frontiers",liveSpaceId:1,tenantLogoUrl:"",frontiersGraphUrl:"https://apollo-federation-gateway.frontiersin.org",registrationApiUrl:"https://onboarding-ui.frontiersin.org",emailDigestApiUrl:"https://api-email-digest.frontiersin.org",journalFilesApiUrl:"https://files-journal-api.frontiersin.org",searchApiUrl:"https://search-api.frontiersin.org",productionForumApiUrl:"https://production-forum-api-v2.frontiersin.org",gtmServerUrl:"https://tag-manager.frontiersin.org",gtmId:"GTM-M322FV2",gtmAuth:"owVbWxfaJr21yQv1fe1cAQ",gtmPreview:"env-1",figsharePluginUrl:"https://widgets.figshare.com/static/figshare.js",figshareApiUrl:"https://api.figshare.com/v2/collections/search",figshareTimeout:3000,crossmarkPublishedDate:"2015/08/24",googleRecaptchaSiteKey:"6LdG3i0UAAAAAOC4qUh35ubHgJotEHp_STXHgr_v",googleRecaptchaKeyName:"FrontiersRecaptchaV2",faviconSize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantFavicon-Frontiers.png",faviconSize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantFavicon-Frontiers.png",faviconSize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantFavicon-Frontiers.png",faviconSize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantFavicon-Frontiers.png",faviconSize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantFavicon-Frontiers.png",socialMediaImg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/Guidelines-Frontiers_Logo_1200x628_1-91to1.png",linkedArticleCopyText:"'{\"articleTypeCopyText\":[{\"articleTypeId\":0,\"originalArticleCopyText\":\"Part of this article's content has been mentioned in:\",\"linkedArticleCopyText\":\"This article mentions parts of:\"},{\"articleTypeId\":122,\"originalArticleCopyText\":\"Parts of this article's content have been modified or rectified in:\",\"linkedArticleCopyText\":\"This article is an erratum on:\"},{\"articleTypeId\":129,\"originalArticleCopyText\":\"Parts of this article's content have been modified or rectified in:\",\"linkedArticleCopyText\":\"This article is an addendum to:\"},{\"articleTypeId\":128,\"originalArticleCopyText\":\"A correction has been applied to this article in:\",\"linkedArticleCopyText\":\"This article is a correction to:\"},{\"articleTypeId\":134,\"originalArticleCopyText\":\"A retraction of this article was approved in:\",\"linkedArticleCopyText\":\"This article is a retraction of:\"},{\"articleTypeId\":29,\"originalArticleCopyText\":\"A commentary has been posted on this article:\",\"linkedArticleCopyText\":\"This article is a commentary on:\"},{\"articleTypeId\":30,\"originalArticleCopyText\":\"A commentary has been posted on this article:\",\"linkedArticleCopyText\":\"This article is a commentary on:\"}],\"articleIdCopyText\":[]}'\n",acceptedArticleExcludedJournalIds:"'[2766,979]'\n",articleTypeConfigurableLabel:"\u003C\u003Carticle-type:uppercase>> article",settingsFeaturesSwitchers:"'{\"displayTitlePillLabels\":true,\"displayRelatedArticlesBox\":true,\"showEditors\":true,\"showReviewers\":true,\"showLoopImpactLink\":true,\"enableFigshare\":false,\"useXmlImages\":true}'\n",journalsWithArticleHub:"'{\"strings\":[\"science\"]}'\n",terminologySettings:"'{\"terms\":[{\"sequenceNumber\":1,\"key\":\"frontiers\",\"tenantTerm\":\"Frontiers\",\"frontiersDefaultTerm\":\"Frontiers\",\"category\":\"Customer\"},{\"sequenceNumber\":2,\"key\":\"submission_system\",\"tenantTerm\":\"submission system\",\"frontiersDefaultTerm\":\"submission system\",\"category\":\"Product\"},{\"sequenceNumber\":3,\"key\":\"public_pages\",\"tenantTerm\":\"public pages\",\"frontiersDefaultTerm\":\"public pages\",\"category\":\"Product\"},{\"sequenceNumber\":4,\"key\":\"my_frontiers\",\"tenantTerm\":\"my frontiers\",\"frontiersDefaultTerm\":\"my frontiers\",\"category\":\"Product\"},{\"sequenceNumber\":5,\"key\":\"digital_editorial_office\",\"tenantTerm\":\"digital editorial office\",\"frontiersDefaultTerm\":\"digital editorial office\",\"category\":\"Product\"},{\"sequenceNumber\":6,\"key\":\"deo\",\"tenantTerm\":\"DEO\",\"frontiersDefaultTerm\":\"DEO\",\"category\":\"Product\"},{\"sequenceNumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantTerm\":\"digital editorial office for chiefs\",\"frontiersDefaultTerm\":\"digital editorial office for chiefs\",\"category\":\"Product\"},{\"sequenceNumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantTerm\":\"digital editorial office for eof\",\"frontiersDefaultTerm\":\"digital editorial office for eof\",\"category\":\"Product\"},{\"sequenceNumber\":9,\"key\":\"editorial_office\",\"tenantTerm\":\"editorial office\",\"frontiersDefaultTerm\":\"editorial office\",\"category\":\"Product\"},{\"sequenceNumber\":10,\"key\":\"eof\",\"tenantTerm\":\"EOF\",\"frontiersDefaultTerm\":\"EOF\",\"category\":\"Product\"},{\"sequenceNumber\":11,\"key\":\"research_topic_management\",\"tenantTerm\":\"research topic management\",\"frontiersDefaultTerm\":\"research topic management\",\"category\":\"Product\"},{\"sequenceNumber\":12,\"key\":\"review_forum\",\"tenantTerm\":\"review forum\",\"frontiersDefaultTerm\":\"review forum\",\"category\":\"Product\"},{\"sequenceNumber\":13,\"key\":\"accounting_office\",\"tenantTerm\":\"accounting office\",\"frontiersDefaultTerm\":\"accounting office\",\"category\":\"Product\"},{\"sequenceNumber\":14,\"key\":\"aof\",\"tenantTerm\":\"AOF\",\"frontiersDefaultTerm\":\"AOF\",\"category\":\"Product\"},{\"sequenceNumber\":15,\"key\":\"publishing_office\",\"tenantTerm\":\"publishing office\",\"frontiersDefaultTerm\":\"publishing office\",\"category\":\"Product\"},{\"sequenceNumber\":16,\"key\":\"production_office\",\"tenantTerm\":\"production office forum\",\"frontiersDefaultTerm\":\"production office forum\",\"category\":\"Product\"},{\"sequenceNumber\":17,\"key\":\"pof\",\"tenantTerm\":\"POF\",\"frontiersDefaultTerm\":\"POF\",\"category\":\"Product\"},{\"sequenceNumber\":18,\"key\":\"book_office_forum\",\"tenantTerm\":\"book office forum\",\"frontiersDefaultTerm\":\"book office forum\",\"category\":\"Product\"},{\"sequenceNumber\":19,\"key\":\"bof\",\"tenantTerm\":\"BOF\",\"frontiersDefaultTerm\":\"BOF\",\"category\":\"Product\"},{\"sequenceNumber\":20,\"key\":\"aira\",\"tenantTerm\":\"AIRA\",\"frontiersDefaultTerm\":\"AIRA\",\"category\":\"Product\"},{\"sequenceNumber\":21,\"key\":\"editorial_board_management\",\"tenantTerm\":\"editorial board management\",\"frontiersDefaultTerm\":\"editorial board management\",\"category\":\"Product\"},{\"sequenceNumber\":22,\"key\":\"ebm\",\"tenantTerm\":\"EBM\",\"frontiersDefaultTerm\":\"EBM\",\"category\":\"Product\"},{\"sequenceNumber\":23,\"key\":\"domain\",\"tenantTerm\":\"domain\",\"frontiersDefaultTerm\":\"domain\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":24,\"key\":\"journal\",\"tenantTerm\":\"journal\",\"frontiersDefaultTerm\":\"journal\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":25,\"key\":\"section\",\"tenantTerm\":\"section\",\"frontiersDefaultTerm\":\"section\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":26,\"key\":\"domains\",\"tenantTerm\":\"domains\",\"frontiersDefaultTerm\":\"domains\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":27,\"key\":\"specialty_section\",\"tenantTerm\":\"specialty section\",\"frontiersDefaultTerm\":\"specialty section\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":28,\"key\":\"specialty_journal\",\"tenantTerm\":\"specialty journal\",\"frontiersDefaultTerm\":\"specialty journal\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":29,\"key\":\"journals\",\"tenantTerm\":\"journals\",\"frontiersDefaultTerm\":\"journals\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":30,\"key\":\"sections\",\"tenantTerm\":\"sections\",\"frontiersDefaultTerm\":\"sections\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":31,\"key\":\"specialty_sections\",\"tenantTerm\":\"specialty sections\",\"frontiersDefaultTerm\":\"specialty sections\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":32,\"key\":\"specialty_journals\",\"tenantTerm\":\"specialty journals\",\"frontiersDefaultTerm\":\"specialty journals\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":33,\"key\":\"manuscript\",\"tenantTerm\":\"manuscript\",\"frontiersDefaultTerm\":\"manuscript\",\"category\":\"Core\"},{\"sequenceNumber\":34,\"key\":\"manuscripts\",\"tenantTerm\":\"manuscripts\",\"frontiersDefaultTerm\":\"manuscripts\",\"category\":\"Core\"},{\"sequenceNumber\":35,\"key\":\"article\",\"tenantTerm\":\"article\",\"frontiersDefaultTerm\":\"article\",\"category\":\"Core\"},{\"sequenceNumber\":36,\"key\":\"articles\",\"tenantTerm\":\"articles\",\"frontiersDefaultTerm\":\"articles\",\"category\":\"Core\"},{\"sequenceNumber\":37,\"key\":\"article_type\",\"tenantTerm\":\"article type\",\"frontiersDefaultTerm\":\"article type\",\"category\":\"Core\"},{\"sequenceNumber\":38,\"key\":\"article_types\",\"tenantTerm\":\"article types\",\"frontiersDefaultTerm\":\"article types\",\"category\":\"Core\"},{\"sequenceNumber\":39,\"key\":\"author\",\"tenantTerm\":\"author\",\"frontiersDefaultTerm\":\"author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":40,\"key\":\"authors\",\"tenantTerm\":\"authors\",\"frontiersDefaultTerm\":\"authors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":41,\"key\":\"authoring\",\"tenantTerm\":\"authoring\",\"frontiersDefaultTerm\":\"authoring\",\"category\":\"Core\"},{\"sequenceNumber\":42,\"key\":\"authored\",\"tenantTerm\":\"authored\",\"frontiersDefaultTerm\":\"authored\",\"category\":\"Core\"},{\"sequenceNumber\":43,\"key\":\"accept\",\"tenantTerm\":\"accept\",\"frontiersDefaultTerm\":\"accept\",\"category\":\"Process\"},{\"sequenceNumber\":44,\"key\":\"accepted\",\"tenantTerm\":\"accepted\",\"frontiersDefaultTerm\":\"accepted\",\"category\":\"Process\"},{\"sequenceNumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantTerm\":\"Assistant Field Chief Editor\",\"frontiersDefaultTerm\":\"Assistant Field Chief Editor\",\"description\":\"An editorial role on a Field Journal that a Registered User may hold. This gives them rights to different functionality and parts of the platform\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantTerm\":\"Assistant Specialty Chief Editor\",\"frontiersDefaultTerm\":\"Assistant Specialty Chief Editor\",\"description\":\"An editorial role on a specialty that a Registered User may hold. This gives them rights to different functionality and parts of the platform\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantTerm\":\"Assistant Specialty Chief Editors\",\"frontiersDefaultTerm\":\"Assistant Specialty Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":48,\"key\":\"associate_editor\",\"tenantTerm\":\"Associate Editor\",\"frontiersDefaultTerm\":\"Associate Editor\",\"description\":\"An editorial role on a specialty that a Registered User may hold. This gives them rights to different functionality and parts of the platform\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":49,\"key\":\"specialty_chief_editor\",\"tenantTerm\":\"Specialty Chief Editor\",\"frontiersDefaultTerm\":\"Specialty Chief Editor\",\"description\":\"An editorial role on a specialty that a Registered User may hold. This gives them rights to different functionality and parts of the platform\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":50,\"key\":\"specialty_chief_editors\",\"tenantTerm\":\"Specialty Chief Editors\",\"frontiersDefaultTerm\":\"Specialty Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":51,\"key\":\"chief_editor\",\"tenantTerm\":\"Chief Editor\",\"frontiersDefaultTerm\":\"Chief Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":52,\"key\":\"chief_editors\",\"tenantTerm\":\"Chief Editors\",\"frontiersDefaultTerm\":\"Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":53,\"key\":\"call_for_participation\",\"tenantTerm\":\"call for participation\",\"frontiersDefaultTerm\":\"call for participation\",\"category\":\"Process\"},{\"sequenceNumber\":54,\"key\":\"citation\",\"tenantTerm\":\"citation\",\"frontiersDefaultTerm\":\"citation\",\"category\":\"Misc.\"},{\"sequenceNumber\":55,\"key\":\"citations\",\"tenantTerm\":\"citations\",\"frontiersDefaultTerm\":\"citations\",\"category\":\"Misc.\"},{\"sequenceNumber\":56,\"key\":\"contributor\",\"tenantTerm\":\"contributor\",\"frontiersDefaultTerm\":\"contributor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":57,\"key\":\"contributors\",\"tenantTerm\":\"contributors\",\"frontiersDefaultTerm\":\"contributors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":58,\"key\":\"corresponding_author\",\"tenantTerm\":\"corresponding author\",\"frontiersDefaultTerm\":\"corresponding author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":59,\"key\":\"corresponding_authors\",\"tenantTerm\":\"corresponding authors\",\"frontiersDefaultTerm\":\"corresponding authors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":60,\"key\":\"decline\",\"tenantTerm\":\"decline\",\"frontiersDefaultTerm\":\"decline\",\"category\":\"Process\"},{\"sequenceNumber\":61,\"key\":\"declined\",\"tenantTerm\":\"declined\",\"frontiersDefaultTerm\":\"declined\",\"category\":\"Process\"},{\"sequenceNumber\":62,\"key\":\"reject\",\"tenantTerm\":\"reject\",\"frontiersDefaultTerm\":\"reject\",\"category\":\"Process\"},{\"sequenceNumber\":63,\"key\":\"rejected\",\"tenantTerm\":\"rejected\",\"frontiersDefaultTerm\":\"rejected\",\"category\":\"Process\"},{\"sequenceNumber\":64,\"key\":\"publish\",\"tenantTerm\":\"publish\",\"frontiersDefaultTerm\":\"publish\",\"category\":\"Core\"},{\"sequenceNumber\":65,\"key\":\"published\",\"tenantTerm\":\"published\",\"frontiersDefaultTerm\":\"published\",\"category\":\"Core\"},{\"sequenceNumber\":66,\"key\":\"publication\",\"tenantTerm\":\"publication\",\"frontiersDefaultTerm\":\"publication\",\"category\":\"Core\"},{\"sequenceNumber\":67,\"key\":\"peer_review\",\"tenantTerm\":\"peer review\",\"frontiersDefaultTerm\":\"peer review\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":68,\"key\":\"peer_reviewed\",\"tenantTerm\":\"peer reviewed\",\"frontiersDefaultTerm\":\"peer reviewed\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":69,\"key\":\"initial_validation\",\"tenantTerm\":\"initial validation\",\"frontiersDefaultTerm\":\"initial validation\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":70,\"key\":\"editorial_assignment\",\"tenantTerm\":\"editorial assignment\",\"frontiersDefaultTerm\":\"editorial assignment\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":71,\"key\":\"independent_review\",\"tenantTerm\":\"independent review\",\"frontiersDefaultTerm\":\"independent review\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":72,\"key\":\"interactive_review\",\"tenantTerm\":\"interactive review\",\"frontiersDefaultTerm\":\"interactive review\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":73,\"key\":\"review\",\"tenantTerm\":\"review\",\"frontiersDefaultTerm\":\"review\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":74,\"key\":\"reviewing\",\"tenantTerm\":\"reviewing\",\"frontiersDefaultTerm\":\"reviewing\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":75,\"key\":\"reviewer\",\"tenantTerm\":\"reviewer\",\"frontiersDefaultTerm\":\"reviewer\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":76,\"key\":\"reviewers\",\"tenantTerm\":\"reviewers\",\"frontiersDefaultTerm\":\"reviewers\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":77,\"key\":\"review_finalized\",\"tenantTerm\":\"review finalized\",\"frontiersDefaultTerm\":\"review finalized\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":78,\"key\":\"final_decision\",\"tenantTerm\":\"final decision\",\"frontiersDefaultTerm\":\"final decision\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":79,\"key\":\"final_validation\",\"tenantTerm\":\"final validation\",\"frontiersDefaultTerm\":\"final validation\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantTerm\":\"recommend to accept manuscript\",\"frontiersDefaultTerm\":\"accept manuscript\",\"category\":\"Process\"},{\"sequenceNumber\":81,\"key\":\"fee\",\"tenantTerm\":\"fee\",\"frontiersDefaultTerm\":\"fee\",\"category\":\"Accounting\"},{\"sequenceNumber\":82,\"key\":\"fees\",\"tenantTerm\":\"fees\",\"frontiersDefaultTerm\":\"fees\",\"category\":\"Accounting\"},{\"sequenceNumber\":83,\"key\":\"guest_associate_editor\",\"tenantTerm\":\"Guest Associate Editor\",\"frontiersDefaultTerm\":\"Guest Associate Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":84,\"key\":\"guest_associate_editors\",\"tenantTerm\":\"Guest Associate Editors\",\"frontiersDefaultTerm\":\"Guest Associate Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":85,\"key\":\"in_review\",\"tenantTerm\":\"in review\",\"frontiersDefaultTerm\":\"in review\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":86,\"key\":\"institutional_member\",\"tenantTerm\":\"institutional partner\",\"frontiersDefaultTerm\":\"institutional partner\",\"category\":\"Accounting\"},{\"sequenceNumber\":87,\"key\":\"institutional_membership\",\"tenantTerm\":\"institutional partnership\",\"frontiersDefaultTerm\":\"institutional partnership\",\"category\":\"Accounting\"},{\"sequenceNumber\":88,\"key\":\"article_processing_charge\",\"tenantTerm\":\"article processing charge\",\"frontiersDefaultTerm\":\"article processing charge\",\"category\":\"Accounting\"},{\"sequenceNumber\":89,\"key\":\"article_processing_charges\",\"tenantTerm\":\"article processing charges\",\"frontiersDefaultTerm\":\"article processing charges\",\"category\":\"Accounting\"},{\"sequenceNumber\":90,\"key\":\"apcs\",\"tenantTerm\":\"APCs\",\"frontiersDefaultTerm\":\"APCs\",\"category\":\"Accounting\"},{\"sequenceNumber\":91,\"key\":\"apc\",\"tenantTerm\":\"APC\",\"frontiersDefaultTerm\":\"APC\",\"category\":\"Accounting\"},{\"sequenceNumber\":92,\"key\":\"received\",\"tenantTerm\":\"received\",\"frontiersDefaultTerm\":\"received\",\"description\":\"Date manuscript was received on.\",\"category\":\"Core\"},{\"sequenceNumber\":93,\"key\":\"transferred\",\"tenantTerm\":\"transferred\",\"frontiersDefaultTerm\":\"transferred\",\"category\":\"Core\"},{\"sequenceNumber\":94,\"key\":\"transfer\",\"tenantTerm\":\"transfer\",\"frontiersDefaultTerm\":\"transfer\",\"category\":\"Core\"},{\"sequenceNumber\":95,\"key\":\"research_topic\",\"tenantTerm\":\"research topic\",\"frontiersDefaultTerm\":\"research topic\",\"category\":\"Core\"},{\"sequenceNumber\":96,\"key\":\"research_topics\",\"tenantTerm\":\"research topics\",\"frontiersDefaultTerm\":\"research topics\",\"category\":\"Core\"},{\"sequenceNumber\":97,\"key\":\"topic_editor\",\"tenantTerm\":\"Topic Editor\",\"frontiersDefaultTerm\":\"Topic Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":98,\"key\":\"review_editor\",\"tenantTerm\":\"Review Editor\",\"frontiersDefaultTerm\":\"Review Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":99,\"key\":\"title\",\"tenantTerm\":\"title\",\"frontiersDefaultTerm\":\"title\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":100,\"key\":\"running_title\",\"tenantTerm\":\"running title\",\"frontiersDefaultTerm\":\"running title\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":101,\"key\":\"submit\",\"tenantTerm\":\"submit\",\"frontiersDefaultTerm\":\"submit\",\"category\":\"Process\"},{\"sequenceNumber\":102,\"key\":\"submitted\",\"tenantTerm\":\"submitted\",\"frontiersDefaultTerm\":\"submitted\",\"category\":\"Process\"},{\"sequenceNumber\":103,\"key\":\"submitting\",\"tenantTerm\":\"submitting\",\"frontiersDefaultTerm\":\"submitting\",\"category\":\"Process\"},{\"sequenceNumber\":104,\"key\":\"t_e\",\"tenantTerm\":\"TE\",\"frontiersDefaultTerm\":\"TE\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":105,\"key\":\"topic\",\"tenantTerm\":\"topic\",\"frontiersDefaultTerm\":\"topic\",\"category\":\"Process\"},{\"sequenceNumber\":106,\"key\":\"topic_summary\",\"tenantTerm\":\"topic summary\",\"frontiersDefaultTerm\":\"topic summary\",\"category\":\"Process\"},{\"sequenceNumber\":107,\"key\":\"figure\",\"tenantTerm\":\"figure\",\"frontiersDefaultTerm\":\"figure\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":108,\"key\":\"figures\",\"tenantTerm\":\"figures\",\"frontiersDefaultTerm\":\"figures\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":109,\"key\":\"editorial_file\",\"tenantTerm\":\"editorial file\",\"frontiersDefaultTerm\":\"editorial file\",\"category\":\"Core\"},{\"sequenceNumber\":110,\"key\":\"editorial_files\",\"tenantTerm\":\"editorial files\",\"frontiersDefaultTerm\":\"editorial files\",\"category\":\"Core\"},{\"sequenceNumber\":111,\"key\":\"e_book\",\"tenantTerm\":\"e-book\",\"frontiersDefaultTerm\":\"e-book\",\"category\":\"Core\"},{\"sequenceNumber\":112,\"key\":\"organization\",\"tenantTerm\":\"organization\",\"frontiersDefaultTerm\":\"organization\",\"category\":\"Core\"},{\"sequenceNumber\":113,\"key\":\"institution\",\"tenantTerm\":\"institution\",\"frontiersDefaultTerm\":\"institution\",\"category\":\"Core\"},{\"sequenceNumber\":114,\"key\":\"reference\",\"tenantTerm\":\"reference\",\"frontiersDefaultTerm\":\"reference\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":115,\"key\":\"references\",\"tenantTerm\":\"references\",\"frontiersDefaultTerm\":\"references\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":116,\"key\":\"sce\",\"tenantTerm\":\"SCE\",\"frontiersDefaultTerm\":\"SCE\",\"description\":\"Abbreviation for Specialty Chief Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":117,\"key\":\"submission\",\"tenantTerm\":\"submission\",\"frontiersDefaultTerm\":\"submission\",\"category\":\"Process\"},{\"sequenceNumber\":118,\"key\":\"submissions\",\"tenantTerm\":\"submissions\",\"frontiersDefaultTerm\":\"submissions\",\"category\":\"Process\"},{\"sequenceNumber\":119,\"key\":\"editing\",\"tenantTerm\":\"editing\",\"frontiersDefaultTerm\":\"editing\",\"category\":\"Process\"},{\"sequenceNumber\":120,\"key\":\"in_preparation\",\"tenantTerm\":\"in preparation\",\"frontiersDefaultTerm\":\"in preparation\",\"category\":\"Process\"},{\"sequenceNumber\":121,\"key\":\"country_region\",\"tenantTerm\":\"country/region\",\"frontiersDefaultTerm\":\"country/region\",\"description\":\"Because of political issues, some of the country listings are actually classified as `regions` and we need to include this. However other clients may not want to do this.\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":122,\"key\":\"countries_regions\",\"tenantTerm\":\"countries/regions\",\"frontiersDefaultTerm\":\"countries/regions\",\"description\":\"Because of political issues, some of the country listings are actually classified as `regions` and we need to include this. However other clients may not want to do this.\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":123,\"key\":\"specialty\",\"tenantTerm\":\"specialty\",\"frontiersDefaultTerm\":\"specialty\",\"category\":\"Core\"},{\"sequenceNumber\":124,\"key\":\"specialties\",\"tenantTerm\":\"specialties\",\"frontiersDefaultTerm\":\"specialties\",\"category\":\"Core\"},{\"sequenceNumber\":125,\"key\":\"associate_editors\",\"tenantTerm\":\"Associate Editors\",\"frontiersDefaultTerm\":\"Associate Editors\",\"description\":\"An editorial role on a specialty that a Registered User may hold. This gives them rights to different functionality and parts of the platform\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":126,\"key\":\"reviewed\",\"tenantTerm\":\"reviewed\",\"frontiersDefaultTerm\":\"reviewed\",\"category\":\"Peer Review Process\"},{\"sequenceNumber\":127,\"key\":\"institutional_members\",\"tenantTerm\":\"institutional partners\",\"frontiersDefaultTerm\":\"institutional partners\",\"category\":\"Accounting\"},{\"sequenceNumber\":128,\"key\":\"institutional_memberships\",\"tenantTerm\":\"institutional partnerships\",\"frontiersDefaultTerm\":\"institutional partnerships\",\"category\":\"Accounting\"},{\"sequenceNumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantTerm\":\"Assistant Field Chief Editors\",\"frontiersDefaultTerm\":\"Assistant Field Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":130,\"key\":\"publications\",\"tenantTerm\":\"publications\",\"frontiersDefaultTerm\":\"publications\",\"category\":\"Process\"},{\"sequenceNumber\":131,\"key\":\"ae_accepted\",\"tenantTerm\":\"recommended acceptance\",\"frontiersDefaultTerm\":\"accepted\",\"category\":\"Process\"},{\"sequenceNumber\":132,\"key\":\"field_journal\",\"tenantTerm\":\"field journal\",\"frontiersDefaultTerm\":\"field journal\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":133,\"key\":\"field_journals\",\"tenantTerm\":\"field journals\",\"frontiersDefaultTerm\":\"field journals\",\"category\":\"Taxonomy\"},{\"sequenceNumber\":134,\"key\":\"program_manager\",\"tenantTerm\":\"program manager\",\"frontiersDefaultTerm\":\"program manager\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":135,\"key\":\"journal_manager\",\"tenantTerm\":\"journal manager\",\"frontiersDefaultTerm\":\"journal manager\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":136,\"key\":\"journal_specialist\",\"tenantTerm\":\"journal specialist\",\"frontiersDefaultTerm\":\"journal specialist\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":137,\"key\":\"program_managers\",\"tenantTerm\":\"program managers\",\"frontiersDefaultTerm\":\"program managers\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":138,\"key\":\"journal_managers\",\"tenantTerm\":\"journal managers\",\"frontiersDefaultTerm\":\"journal managers\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":139,\"key\":\"journal_specialists\",\"tenantTerm\":\"journal specialists\",\"frontiersDefaultTerm\":\"journal specialists\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":140,\"key\":\"cover_letter\",\"tenantTerm\":\"manuscript contribution to the field\",\"frontiersDefaultTerm\":\"manuscript contribution to the field\",\"category\":\"Process\"},{\"sequenceNumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantTerm\":\"recommended to accept manuscript\",\"frontiersDefaultTerm\":\"accepted manuscript\",\"category\":\"Process\"},{\"sequenceNumber\":142,\"key\":\"recommend_for_rejection\",\"tenantTerm\":\"recommend for rejection\",\"frontiersDefaultTerm\":\"recommend for rejection\",\"category\":\"Process\"},{\"sequenceNumber\":143,\"key\":\"recommended_for_rejection\",\"tenantTerm\":\"recommended for rejection\",\"frontiersDefaultTerm\":\"recommended for rejection\",\"category\":\"Process\"},{\"sequenceNumber\":144,\"key\":\"ae\",\"tenantTerm\":\"AE\",\"frontiersDefaultTerm\":\"AE\",\"description\":\"Associate Editor - board member\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":145,\"key\":\"re\",\"tenantTerm\":\"RE\",\"frontiersDefaultTerm\":\"RE\",\"description\":\"Review Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":146,\"key\":\"rev\",\"tenantTerm\":\"REV\",\"frontiersDefaultTerm\":\"REV\",\"description\":\"Reviewer\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":147,\"key\":\"aut\",\"tenantTerm\":\"AUT\",\"frontiersDefaultTerm\":\"AUT\",\"description\":\"Author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":148,\"key\":\"coraut\",\"tenantTerm\":\"CORAUT\",\"frontiersDefaultTerm\":\"CORAUT\",\"description\":\"Corresponding author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":149,\"key\":\"saut\",\"tenantTerm\":\"SAUT\",\"frontiersDefaultTerm\":\"SAUT\",\"description\":\"Submitting author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":150,\"key\":\"coaut\",\"tenantTerm\":\"COAUT\",\"frontiersDefaultTerm\":\"COAUT\",\"description\":\"co-author\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":151,\"key\":\"tsof\",\"tenantTerm\":\"TSOF\",\"frontiersDefaultTerm\":\"TSOF\",\"description\":\"Typesetter\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":152,\"key\":\"typesetting_office\",\"tenantTerm\":\"typesetting office\",\"frontiersDefaultTerm\":\"typesetting office\",\"category\":\"Product\"},{\"sequenceNumber\":153,\"key\":\"config\",\"tenantTerm\":\"CONFIG\",\"frontiersDefaultTerm\":\"CONFIG\",\"description\":\"Configuration office role\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":154,\"key\":\"jm\",\"tenantTerm\":\"JM\",\"frontiersDefaultTerm\":\"JM\",\"description\":\"Journal Manager\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":155,\"key\":\"rte\",\"tenantTerm\":\"RTE\",\"frontiersDefaultTerm\":\"RTE\",\"description\":\"Research topic editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":156,\"key\":\"organizations\",\"tenantTerm\":\"organizations\",\"frontiersDefaultTerm\":\"organizations\",\"category\":\"Core\"},{\"sequenceNumber\":157,\"key\":\"publishing\",\"tenantTerm\":\"publishing\",\"frontiersDefaultTerm\":\"publishing\",\"category\":\"Core\"},{\"sequenceNumber\":158,\"key\":\"acceptance\",\"tenantTerm\":\"acceptance\",\"frontiersDefaultTerm\":\"acceptance\",\"category\":\"Process\"},{\"sequenceNumber\":159,\"key\":\"preferred_associate_editor\",\"tenantTerm\":\"preferred associate editor\",\"frontiersDefaultTerm\":\"preferred associate editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":160,\"key\":\"topic_editors\",\"tenantTerm\":\"Topic Editors\",\"frontiersDefaultTerm\":\"Topic Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":161,\"key\":\"institutions\",\"tenantTerm\":\"institutions\",\"frontiersDefaultTerm\":\"institutions\",\"category\":\"Core\"},{\"sequenceNumber\":162,\"key\":\"author(s)\",\"tenantTerm\":\"author(s)\",\"frontiersDefaultTerm\":\"author(s)\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":163,\"key\":\"figure(s)\",\"tenantTerm\":\"figure(s)\",\"frontiersDefaultTerm\":\"figure(s)\",\"category\":\"Manuscript Metadata\"},{\"sequenceNumber\":164,\"key\":\"co-authors\",\"tenantTerm\":\"co-authors\",\"frontiersDefaultTerm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":165,\"key\":\"editorial_board_members\",\"tenantTerm\":\"editorial board members\",\"frontiersDefaultTerm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":166,\"key\":\"editorial_board\",\"tenantTerm\":\"editorial board\",\"frontiersDefaultTerm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"Product\"},{\"sequenceNumber\":167,\"key\":\"co-authorship\",\"tenantTerm\":\"co-authorship\",\"frontiersDefaultTerm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"Misc.\"},{\"sequenceNumber\":168,\"key\":\"role_id_1\",\"tenantTerm\":\"registration office\",\"frontiersDefaultTerm\":\"registration office\",\"category\":\"User Role\"},{\"sequenceNumber\":169,\"key\":\"role_id_2\",\"tenantTerm\":\"editorial office\",\"frontiersDefaultTerm\":\"editorial office\",\"category\":\"User Role\"},{\"sequenceNumber\":170,\"key\":\"role_id_7\",\"tenantTerm\":\"field chief editor\",\"frontiersDefaultTerm\":\"field chief editor\",\"category\":\"User Role\"},{\"sequenceNumber\":171,\"key\":\"role_id_8\",\"tenantTerm\":\"assistant field chief editor\",\"frontiersDefaultTerm\":\"assistant field chief editor\",\"category\":\"User Role\"},{\"sequenceNumber\":172,\"key\":\"role_id_9\",\"tenantTerm\":\"specialty chief editor\",\"frontiersDefaultTerm\":\"specialty chief editor\",\"category\":\"User Role\"},{\"sequenceNumber\":173,\"key\":\"role_id_10\",\"tenantTerm\":\"assistant specialty chief editor\",\"frontiersDefaultTerm\":\"assistant specialty chief editor\",\"category\":\"User Role\"},{\"sequenceNumber\":174,\"key\":\"role_id_11\",\"tenantTerm\":\"associate editor\",\"frontiersDefaultTerm\":\"associate editor\",\"category\":\"User Role\"},{\"sequenceNumber\":175,\"key\":\"role_id_12\",\"tenantTerm\":\"guest associate editor\",\"frontiersDefaultTerm\":\"guest associate editor\",\"category\":\"User Role\"},{\"sequenceNumber\":176,\"key\":\"role_id_13\",\"tenantTerm\":\"review editor\",\"frontiersDefaultTerm\":\"review editor\",\"category\":\"User Role\"},{\"sequenceNumber\":177,\"key\":\"role_id_14\",\"tenantTerm\":\"reviewer\",\"frontiersDefaultTerm\":\"reviewer\",\"category\":\"User Role\"},{\"sequenceNumber\":178,\"key\":\"role_id_15\",\"tenantTerm\":\"author\",\"frontiersDefaultTerm\":\"author\",\"category\":\"User Role\"},{\"sequenceNumber\":179,\"key\":\"role_id_16\",\"tenantTerm\":\"corresponding author\",\"frontiersDefaultTerm\":\"corresponding author\",\"category\":\"User Role\"},{\"sequenceNumber\":180,\"key\":\"role_id_17\",\"tenantTerm\":\"submitting author\",\"frontiersDefaultTerm\":\"submitting author\",\"category\":\"User Role\"},{\"sequenceNumber\":181,\"key\":\"role_id_18\",\"tenantTerm\":\"co-author\",\"frontiersDefaultTerm\":\"co-author\",\"category\":\"User Role\"},{\"sequenceNumber\":182,\"key\":\"role_id_20\",\"tenantTerm\":\"production office\",\"frontiersDefaultTerm\":\"production office\",\"category\":\"User Role\"},{\"sequenceNumber\":183,\"key\":\"role_id_22\",\"tenantTerm\":\"typesetting office (typesetter)\",\"frontiersDefaultTerm\":\"typesetting office (typesetter)\",\"category\":\"User Role\"},{\"sequenceNumber\":184,\"key\":\"role_id_24\",\"tenantTerm\":\"registered user\",\"frontiersDefaultTerm\":\"registered user\",\"category\":\"User Role\"},{\"sequenceNumber\":185,\"key\":\"role_id_35\",\"tenantTerm\":\"job office\",\"frontiersDefaultTerm\":\"job office\",\"category\":\"User Role\"},{\"sequenceNumber\":186,\"key\":\"role_id_41\",\"tenantTerm\":\"special event administrator\",\"frontiersDefaultTerm\":\"special event administrator\",\"category\":\"User Role\"},{\"sequenceNumber\":187,\"key\":\"role_id_42\",\"tenantTerm\":\"special event reviewer\",\"frontiersDefaultTerm\":\"special event reviewer\",\"category\":\"User Role\"},{\"sequenceNumber\":188,\"key\":\"role_id_43\",\"tenantTerm\":\"submit abstract\",\"frontiersDefaultTerm\":\"submit abstract\",\"category\":\"User Role\"},{\"sequenceNumber\":189,\"key\":\"role_id_52\",\"tenantTerm\":\"events office\",\"frontiersDefaultTerm\":\"events office\",\"category\":\"User Role\"},{\"sequenceNumber\":190,\"key\":\"role_id_53\",\"tenantTerm\":\"event administrator\",\"frontiersDefaultTerm\":\"event administrator\",\"category\":\"User Role\"},{\"sequenceNumber\":191,\"key\":\"role_id_89\",\"tenantTerm\":\"content management office\",\"frontiersDefaultTerm\":\"content management office\",\"category\":\"User Role\"},{\"sequenceNumber\":192,\"key\":\"role_id_98\",\"tenantTerm\":\"accounting office\",\"frontiersDefaultTerm\":\"accounting office\",\"category\":\"User Role\"},{\"sequenceNumber\":193,\"key\":\"role_id_99\",\"tenantTerm\":\"projects\",\"frontiersDefaultTerm\":\"projects\",\"category\":\"User Role\"},{\"sequenceNumber\":194,\"key\":\"role_id_103\",\"tenantTerm\":\"configuration office\",\"frontiersDefaultTerm\":\"configuration office\",\"category\":\"User Role\"},{\"sequenceNumber\":195,\"key\":\"role_id_104\",\"tenantTerm\":\"beta user\",\"frontiersDefaultTerm\":\"beta user\",\"category\":\"User Role\"},{\"sequenceNumber\":196,\"key\":\"role_id_106\",\"tenantTerm\":\"wfconf\",\"frontiersDefaultTerm\":\"wfconf\",\"category\":\"User Role\"},{\"sequenceNumber\":197,\"key\":\"role_id_107\",\"tenantTerm\":\"rt management beta user\",\"frontiersDefaultTerm\":\"rt management beta user\",\"category\":\"User Role\"},{\"sequenceNumber\":198,\"key\":\"role_id_108\",\"tenantTerm\":\"deo beta user\",\"frontiersDefaultTerm\":\"deo beta user\",\"category\":\"User Role\"},{\"sequenceNumber\":199,\"key\":\"role_id_109\",\"tenantTerm\":\"search beta user\",\"frontiersDefaultTerm\":\"search beta user\",\"category\":\"User Role\"},{\"sequenceNumber\":200,\"key\":\"role_id_110\",\"tenantTerm\":\"journal manager\",\"frontiersDefaultTerm\":\"journal manager\",\"category\":\"User Role\"},{\"sequenceNumber\":201,\"key\":\"role_id_111\",\"tenantTerm\":\"myfrontiers beta user\",\"frontiersDefaultTerm\":\"myfrontiers beta user\",\"category\":\"User Role\"},{\"sequenceNumber\":202,\"key\":\"role_id_21\",\"tenantTerm\":\"copy editor\",\"frontiersDefaultTerm\":\"copy editor\",\"category\":\"User Role\"},{\"sequenceNumber\":203,\"key\":\"role_id_1_abr\",\"tenantTerm\":\"ROF\",\"frontiersDefaultTerm\":\"ROF\",\"category\":\"User Role\"},{\"sequenceNumber\":204,\"key\":\"role_id_2_abr\",\"tenantTerm\":\"EOF\",\"frontiersDefaultTerm\":\"EOF\",\"category\":\"User Role\"},{\"sequenceNumber\":205,\"key\":\"role_id_7_abr\",\"tenantTerm\":\"FCE\",\"frontiersDefaultTerm\":\"FCE\",\"category\":\"User Role\"},{\"sequenceNumber\":206,\"key\":\"role_id_8_abr\",\"tenantTerm\":\"AFCE\",\"frontiersDefaultTerm\":\"AFCE\",\"category\":\"User Role\"},{\"sequenceNumber\":207,\"key\":\"role_id_9_abr\",\"tenantTerm\":\"SCE\",\"frontiersDefaultTerm\":\"SCE\",\"category\":\"User Role\"},{\"sequenceNumber\":208,\"key\":\"role_id_10_abr\",\"tenantTerm\":\"ASCE\",\"frontiersDefaultTerm\":\"ASCE\",\"category\":\"User Role\"},{\"sequenceNumber\":209,\"key\":\"role_id_11_abr\",\"tenantTerm\":\"AE\",\"frontiersDefaultTerm\":\"AE\",\"category\":\"User Role\"},{\"sequenceNumber\":210,\"key\":\"role_id_12_abr\",\"tenantTerm\":\"GAE\",\"frontiersDefaultTerm\":\"GAE\",\"category\":\"User Role\"},{\"sequenceNumber\":211,\"key\":\"role_id_13_abr\",\"tenantTerm\":\"RE\",\"frontiersDefaultTerm\":\"RE\",\"category\":\"User Role\"},{\"sequenceNumber\":212,\"key\":\"role_id_14_abr\",\"tenantTerm\":\"REV\",\"frontiersDefaultTerm\":\"REV\",\"category\":\"User Role\"},{\"sequenceNumber\":213,\"key\":\"role_id_15_abr\",\"tenantTerm\":\"AUT\",\"frontiersDefaultTerm\":\"AUT\",\"category\":\"User Role\"},{\"sequenceNumber\":214,\"key\":\"role_id_16_abr\",\"tenantTerm\":\"CORAUT\",\"frontiersDefaultTerm\":\"CORAUT\",\"category\":\"User Role\"},{\"sequenceNumber\":215,\"key\":\"role_id_17_abr\",\"tenantTerm\":\"SAUT\",\"frontiersDefaultTerm\":\"SAUT\",\"category\":\"User Role\"},{\"sequenceNumber\":216,\"key\":\"role_id_18_abr\",\"tenantTerm\":\"COAUT\",\"frontiersDefaultTerm\":\"COAUT\",\"category\":\"User Role\"},{\"sequenceNumber\":217,\"key\":\"role_id_20_abr\",\"tenantTerm\":\"POF\",\"frontiersDefaultTerm\":\"POF\",\"category\":\"User Role\"},{\"sequenceNumber\":218,\"key\":\"role_id_22_abr\",\"tenantTerm\":\"TSOF\",\"frontiersDefaultTerm\":\"TSOF\",\"category\":\"User Role\"},{\"sequenceNumber\":219,\"key\":\"role_id_24_abr\",\"tenantTerm\":\"RU\",\"frontiersDefaultTerm\":\"RU\",\"category\":\"User Role\"},{\"sequenceNumber\":220,\"key\":\"role_id_35_abr\",\"tenantTerm\":\"JOF\",\"frontiersDefaultTerm\":\"JOF\",\"category\":\"User Role\"},{\"sequenceNumber\":221,\"key\":\"role_id_41_abr\",\"tenantTerm\":\"SE-ADM\",\"frontiersDefaultTerm\":\"SE-ADM\",\"category\":\"User Role\"},{\"sequenceNumber\":222,\"key\":\"role_id_42_abr\",\"tenantTerm\":\"SE-REV\",\"frontiersDefaultTerm\":\"SE-REV\",\"category\":\"User Role\"},{\"sequenceNumber\":223,\"key\":\"role_id_43_abr\",\"tenantTerm\":\"SE-AUT\",\"frontiersDefaultTerm\":\"SE-AUT\",\"category\":\"User Role\"},{\"sequenceNumber\":224,\"key\":\"role_id_52_abr\",\"tenantTerm\":\"EVOF\",\"frontiersDefaultTerm\":\"EVOF\",\"category\":\"User Role\"},{\"sequenceNumber\":225,\"key\":\"role_id_53_abr\",\"tenantTerm\":\"EV-ADM\",\"frontiersDefaultTerm\":\"EV-ADM\",\"category\":\"User Role\"},{\"sequenceNumber\":226,\"key\":\"role_id_89_abr\",\"tenantTerm\":\"COMOF\",\"frontiersDefaultTerm\":\"COMOF\",\"category\":\"User Role\"},{\"sequenceNumber\":227,\"key\":\"role_id_98_abr\",\"tenantTerm\":\"AOF\",\"frontiersDefaultTerm\":\"AOF\",\"category\":\"User Role\"},{\"sequenceNumber\":228,\"key\":\"role_id_99_abr\",\"tenantTerm\":\"Projects\",\"frontiersDefaultTerm\":\"Projects\",\"category\":\"User Role\"},{\"sequenceNumber\":229,\"key\":\"role_id_103_abr\",\"tenantTerm\":\"CONFIG\",\"frontiersDefaultTerm\":\"CONFIG\",\"category\":\"User Role\"},{\"sequenceNumber\":230,\"key\":\"role_id_104_abr\",\"tenantTerm\":\"BETA\",\"frontiersDefaultTerm\":\"BETA\",\"category\":\"User Role\"},{\"sequenceNumber\":231,\"key\":\"role_id_106_abr\",\"tenantTerm\":\"WFCONF\",\"frontiersDefaultTerm\":\"WFCONF\",\"category\":\"User Role\"},{\"sequenceNumber\":232,\"key\":\"role_id_107_abr\",\"tenantTerm\":\"RTBETA\",\"frontiersDefaultTerm\":\"RTBETA\",\"category\":\"User Role\"},{\"sequenceNumber\":233,\"key\":\"role_id_108_abr\",\"tenantTerm\":\"DEOBETA\",\"frontiersDefaultTerm\":\"DEOBETA\",\"category\":\"User Role\"},{\"sequenceNumber\":234,\"key\":\"role_id_109_abr\",\"tenantTerm\":\"SEARCHBETA\",\"frontiersDefaultTerm\":\"SEARCHBETA\",\"category\":\"User Role\"},{\"sequenceNumber\":235,\"key\":\"role_id_110_abr\",\"tenantTerm\":\"JM\",\"frontiersDefaultTerm\":\"JM\",\"category\":\"User Role\"},{\"sequenceNumber\":236,\"key\":\"role_id_111_abr\",\"tenantTerm\":\"MFBETA\",\"frontiersDefaultTerm\":\"MFBETA\",\"category\":\"User Role\"},{\"sequenceNumber\":237,\"key\":\"role_id_21_abr\",\"tenantTerm\":\"COPED\",\"frontiersDefaultTerm\":\"COPED\",\"category\":\"User Role\"},{\"sequenceNumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantTerm\":\"editorial board\",\"frontiersDefaultTerm\":\"editorial board\",\"description\":\"This is the label for the review editorial board\",\"category\":\"Label\"},{\"sequenceNumber\":239,\"key\":\"field_chief_editor\",\"tenantTerm\":\"Field Chief Editor\",\"frontiersDefaultTerm\":\"Field Chief Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":240,\"key\":\"field_chief_editors\",\"tenantTerm\":\"Field Chief Editors\",\"frontiersDefaultTerm\":\"Field Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":241,\"key\":\"editor\",\"tenantTerm\":\"editor\",\"frontiersDefaultTerm\":\"editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":242,\"key\":\"editors\",\"tenantTerm\":\"editors\",\"frontiersDefaultTerm\":\"editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":243,\"key\":\"board\",\"tenantTerm\":\"board\",\"frontiersDefaultTerm\":\"board\",\"category\":\"Label\"},{\"sequenceNumber\":244,\"key\":\"boards\",\"tenantTerm\":\"boards\",\"frontiersDefaultTerm\":\"boards\",\"category\":\"Label\"},{\"sequenceNumber\":245,\"key\":\"article_collection\",\"tenantTerm\":\"article collection\",\"frontiersDefaultTerm\":\"article collection\",\"category\":\"Label\"},{\"sequenceNumber\":246,\"key\":\"article_collections\",\"tenantTerm\":\"article collections\",\"frontiersDefaultTerm\":\"article collections\",\"category\":\"Label\"},{\"sequenceNumber\":247,\"key\":\"handling_editor\",\"tenantTerm\":\"handling editor\",\"frontiersDefaultTerm\":\"associate editor\",\"description\":\"This terminology key is for the person assigned to edit a manuscript. It is a label for the temporary handling editor assignment.\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":248,\"key\":\"handling_editors\",\"tenantTerm\":\"handling editors\",\"frontiersDefaultTerm\":\"associate editors\",\"description\":\"This terminology key is for the person assigned to edit a manuscript. It is a label for the temporary handling editor assignment.\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":249,\"key\":\"ae_accept\",\"tenantTerm\":\"recommend acceptance\",\"frontiersDefaultTerm\":\"accept\",\"category\":\"Process\"},{\"sequenceNumber\":250,\"key\":\"rtm\",\"tenantTerm\":\"RTM\",\"frontiersDefaultTerm\":\"RTM\",\"category\":\"Product\"},{\"sequenceNumber\":251,\"key\":\"frontiers_media_sa\",\"tenantTerm\":\"Frontiers Media S.A\",\"frontiersDefaultTerm\":\"Frontiers Media S.A\",\"category\":\"Customer\"},{\"sequenceNumber\":252,\"key\":\"review_editors\",\"tenantTerm\":\"Review Editors\",\"frontiersDefaultTerm\":\"Review Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantTerm\":\"Chief Editor\",\"frontiersDefaultTerm\":\"Chief Editor\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantTerm\":\"Chief Editors\",\"frontiersDefaultTerm\":\"Chief Editors\",\"category\":\"Label (Role)\"},{\"sequenceNumber\":255,\"key\":\"call_for_papers\",\"tenantTerm\":\"Call for papers\",\"frontiersDefaultTerm\":\"Call for papers\",\"category\":\"Label\"},{\"sequenceNumber\":256,\"key\":\"calls_for_papers\",\"tenantTerm\":\"Calls for papers\",\"frontiersDefaultTerm\":\"Calls for papers\",\"category\":\"Label\"},{\"sequenceNumber\":257,\"key\":\"supervising_editor\",\"tenantTerm\":\"Supervising Editor\",\"frontiersDefaultTerm\":\"Supervising Editor\",\"description\":\"A Chief or Assistant Chief editor who is assigned to a manuscript to supervise.\",\"category\":\"Role\",\"externalKey\":\"supervising_editor\"},{\"sequenceNumber\":258,\"key\":\"supervising_editors\",\"tenantTerm\":\"Supervising Editors\",\"frontiersDefaultTerm\":\"Supervising Editors\",\"description\":\"A Chief or Assistant Chief editor who is assigned to a manuscript to supervise.\",\"category\":\"Role\",\"externalKey\":\"supervising_editors\"},{\"sequenceNumber\":259,\"key\":\"reviewer_endorse\",\"tenantTerm\":\"endorse\",\"frontiersDefaultTerm\":\"endorse\",\"category\":\"Label\"},{\"sequenceNumber\":260,\"key\":\"reviewer_endorsed\",\"tenantTerm\":\"endorsed\",\"frontiersDefaultTerm\":\"endorsed\",\"category\":\"Label\"},{\"sequenceNumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantTerm\":\"endorse publication\",\"frontiersDefaultTerm\":\"endorse publication\",\"category\":\"Label\"},{\"sequenceNumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantTerm\":\"endorsed publication\",\"frontiersDefaultTerm\":\"endorsed publication\",\"category\":\"Label\"},{\"sequenceNumber\":263,\"key\":\"editor_role\",\"tenantTerm\":\"editor role\",\"frontiersDefaultTerm\":\"Editor Role\",\"category\":\"Label\"},{\"sequenceNumber\":264,\"key\":\"editor_roles\",\"tenantTerm\":\"editor roles\",\"frontiersDefaultTerm\":\"Editor Roles\",\"category\":\"Label\"},{\"sequenceNumber\":265,\"key\":\"editorial_role\",\"tenantTerm\":\"editorial role\",\"frontiersDefaultTerm\":\"Editorial Role\",\"category\":\"Label\"},{\"sequenceNumber\":266,\"key\":\"editorial_roles\",\"tenantTerm\":\"editorial roles\",\"frontiersDefaultTerm\":\"Editorial Roles\",\"category\":\"Label\"},{\"sequenceNumber\":267,\"key\":\"call_for_paper\",\"tenantTerm\":\"Call for paper\",\"frontiersDefaultTerm\":\"Call for paper\",\"category\":\"Label\"},{\"sequenceNumber\":268,\"key\":\"research_topic_abstract\",\"tenantTerm\":\"manuscript summary\",\"frontiersDefaultTerm\":\"manuscript summary\",\"category\":\"Process\"},{\"sequenceNumber\":269,\"key\":\"research_topic_abstracts\",\"tenantTerm\":\"manuscript summaries\",\"frontiersDefaultTerm\":\"manuscript summaries\",\"category\":\"Process\"},{\"sequenceNumber\":270,\"key\":\"submissions_team_manager\",\"tenantTerm\":\"Journal Manager\",\"frontiersDefaultTerm\":\"Content Manager\",\"category\":\"Process\"},{\"sequenceNumber\":271,\"key\":\"submissions_team\",\"tenantTerm\":\"Journal Team\",\"frontiersDefaultTerm\":\"Content Team\",\"category\":\"Process\"},{\"sequenceNumber\":272,\"key\":\"topic_coordinator\",\"tenantTerm\":\"topic coordinator\",\"frontiersDefaultTerm\":\"topic coordinator\",\"category\":\"Process\"},{\"sequenceNumber\":273,\"key\":\"topic_coordinators\",\"tenantTerm\":\"topic coordinators\",\"frontiersDefaultTerm\":\"topic coordinators\",\"category\":\"Process\"},{\"sequenceNumber\":274,\"key\":\"frontiers_journal_team\",\"tenantTerm\":\"frontiers journal team\",\"frontiersDefaultTerm\":\"frontiers journal team\",\"category\":\"Label (Role)\"}]}'\n",impactGtmId:"GTM-NJF2ML9B",impactGtmAuth:"fYo-7NoDm9w37QgFMs03SA",impactGtmPreview:"env-1",impactGoogleMapsApiKey:"AIzaSyCTEhX2EU8PWfi86GW9FI00FTcyKk6Ifr8",qualtricsV4ToV3:"'{\"enabled\":true,\"interceptId\":\"SI_er0E2ze69Oz8Yn4\",\"projectId\":\"ZN_cLOy77JHkpc8Gai\",\"brandId\":\"frontiersin\"}'\n",qualtricsUmux:"'{\"enabled\":false,\"interceptId\":\"SI_89fPHY3eTxQBwtU\",\"projectId\":\"ZN_cLOy77JHkpc8Gai\",\"brandId\":\"frontiersin\"}'\n",qualtricsContinuousBrand:"'{\"enabled\":true,\"interceptId\":\"SI_9ZuT94UT81FcRh4\",\"projectId\":\"ZN_cLOy77JHkpc8Gai\",\"brandId\":\"frontiersin\"}'\n",defaultArticleTemplate:"v3"},app:{baseURL:"/",buildId:"62e73f28-8eac-441a-a592-b394dc036e30",buildAssetsDir:"ap-2024/_nuxt",cdnURL:""}}</script>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" type="text/javascript" async></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript" async></script>
<script src="https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js" type="text/javascript" async></script>
<script src="https://api.altmetric.com/v1/doi/10.3389/fnins.2017.00062?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15" type="text/javascript" async></script>
<script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js" type="text/javascript" async></script></body></html>